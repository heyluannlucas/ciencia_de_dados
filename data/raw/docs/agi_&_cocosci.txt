GitHub - SHI-Yu-Zhe/awesome-agi-cocosci: An awesome & curated list for Artificial General Intelligence, an emerging inter-discipline field that combines artificial intelligence and computational cognitive sciences. Skip to content Navigation Menu Toggle navigation Sign in Product GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes Discussions Collaborate outside of code Code Search Find more, search less Explore All features Documentation GitHub Skills Blog Solutions By company size Enterprises Small and medium teams Startups Nonprofits By use case DevSecOps DevOps CI/CD View all use cases By industry Healthcare Financial services Manufacturing Government View all industries View all solutions Resources Topics AI DevOps Security Software Development View all Explore Learning Pathways Events & Webinars Ebooks & Whitepapers Customer Stories Partners Executive Insights Open Source GitHub Sponsors Fund open source developers The ReadME Project GitHub community articles Repositories Topics Trending Collections Enterprise Enterprise platform AI-powered developer platform Available add-ons GitHub Advanced Security Enterprise-grade security features Copilot for business Enterprise-grade AI features Premium Support Enterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation. Cancel Create saved search Sign in Sign up Reseting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert SHI-Yu-Zhe / awesome-agi-cocosci Public Notifications You must be signed in to change notification settings Fork 23 Star 317 An awesome & curated list for Artificial General Intelligence, an emerging inter-discipline field that combines artificial intelligence and computational cognitive sciences. License CC0-1.0 license 317 stars 23 forks Branches Tags Activity Star Notifications You must be signed in to change notification settings Code Issues 0 Pull requests 0 Actions Projects 0 Security Insights Additional navigation options Code Issues Pull requests Actions Projects Security Insights SHI-Yu-Zhe/awesome-agi-cocosci masterBranchesTagsGo to fileCodeFolders and filesNameNameLast commit messageLast commit dateLatest commit History2,090 CommitsBibTexBibTex LaTexLaTex assetsassets Contributing.mdContributing.md LICENSELICENSE README.mdREADME.md code-of-conduct.mdcode-of-conduct.md View all filesRepository files navigationREADMECode of conductCC0-1.0 license Awesome Artificial General Intelligence and Computational Cognitive Sciences An awesome & curated list for Artificial General Intelligence, an emerging inter-discipline field that combines artificial intelligence and computational cognitive sciences as majority, alone with probability and statistics, formal logic, cognitive and developmental psychology, computational philosophy, cognitive neuroscience, and computational sociology. We are promoting high-level machine intelligence by getting inspirations from the way that human learns and thinks, while obtaining a deeper understanding of human cognition simultaneously. We believe that this kind of reciprocative research is a potential way towards our big picture: building human-level intelligent systems with capabilities such as abstracting, explaining, learning, planning, and making decisions. And such intelligence may generally help people improve scientific research, engineering, and the arts, which are the hallmarks of human intelligence. Awesome AGI & CoCoSci is an all-in-one collection, consisting of recources from basic courses and tutorials, to papers and books around diverse topics in mutiple perspectives. Both junior and senior researchers, whether learning, working on, or working around AGI and CoCoSci, meet their interest here. Contributing Contributions are greatly welcomed! Please refer to Contribution Guidelines before taking any action. Contents Papers Abduction Explanation Scientific Discovery Rationalization Applications in AI Bayesian Modeling Bayesian Induction Generative Model Nonparametric Model Bayesian Optimization Concepts Theory of Concepts Human Concept Represenataion AI Concept Representation Complexity & Information Theory Theory Dimensionality Reduction Visual Complexity Communications Non-Verbal Communication Pragmatics Language Compositionality Coordination Domain Specific Language Design Theory Design Practises Design Automation Imperative DSL Applications Declarative DSL Applications Logic DSL Applications DSL Program Synthesis Cognitive Foundations Problem Solving Human-Level Problem Solving Planning Intrinsic Motivation Reinforcement Learning Inverse Reinforcement Learning System 1 & System 2 Dual-Coding Theory Neural-Symbolic AI Explainability Trustworthy AI Strong Machine Learning Explainable Deep Learning Embodied Intelligence Evolutionary Intelligence Methodologies for Experiments Quantitative Analysis Scaling Up Behavioral Studies Decision Making Question Answering Human-Machine Comparison Association Test Virtual Reality Meta-Level Considerations Meta Learning Marr's Levels of Analysis Gestalt The Aha! Moment Rationality Cognitive Architecture Science Logology Philosophy of Science Science of Science Literature Mining Scientific Writing Science Education Democratization of Science Laboratory Automation AI Assisted Research Theory of Mind Analogy Causality Commonsense Intuitive Physics AI Commonsense Reasoning Commonsense Knowledgebase Inductive Logic & Program Synthesis Knowledge Representation Cognitive Development Learning in the Open World Learning with Cognitive Plausibility Academic Tools Courses Programming Paper Writing Paper Reading Literature Management Knowledge Management Institute & Researcher MIT Stanford Princeton Harvard UCLA UC Berkeley BNU PKU UCSD NYU JHU SIT People & Book John Hopcroft Ulf Grenander David Marr Michael Tomasello Judea Pearl Susan Carey Daniel Kahneman Karl Popper About Papers Abduction Explanation Abduction - Plato Stanford. A computational philosophy account on Abduction, one of the three thinking patterns besides Induction and Deduction, being unique for its potential to introduce new ideas into current knowledge. Scientific Explanation - Plato Stanford. A computational philosophy account on Scientific Explanation, a canonical application of Abduction. Scientific Reduction - Plato Stanford. A computational philosophy account on Scientific Reduction, which comes with no explicit boundary with Explanation. Non-monotonic Logic - Plato Stanford. A computational philosophy account on Non-monotonic Logic, a family of formal frameworks devised to capture and represent defeasible inference. Philosophical Writings of Peirce - Courier Corporation, 1955. [All Versions]. Original writings by C. S. Peirce, the philosopher who first introduces the concept of Abduction. Inference to the Best Explanation - Routledge, 1991. [All Versions]. Lipton's original paper on Inference to the Best Explanation as a specialized condition of Abduction. Abductive Reasoning and Learning - Springer, 2000. [All Versions]. This book contains leading survey papers on the various aspects of Abduction, both logical and numerical approaches. Abductive Cognition: The Epistemological and Eco-Cognitive Dimensions of Hypothetical Reasoning - Springer, 2009. [All Versions]. Most philosophers of science in the twentieth century have concluded that no logic of creative processes exists and, moreover, that a rational model of discovery is impossible. In short, scientific creative inferences are irrational and there is no “reasoning” to hypotheses. On the other hand, some research in the area of artificial intelligence has shown that methods for discovery could be found that are computationally adequate for rediscovering --- or discovering for the first time --- empirical or theoretical laws and theorems. Explanation and Abductive Inference - The Oxford Handbook of Thinking and Reasoning, 2012. [All Versions]. This chapter reviews evidence from cognitive psychology and cognitive development concerning the structure and function of explanations, with a focus on the role of explanations in learning and inference. The findings highlight the value of understanding explanation and abductive inference both as phenomena in their own right and for the insights they provide concerning foundational aspects of human cognition, such as representation, learning, and inference. Probabilistic models of cognition: Conceptual foundations - Trends in Cognitive Sciences, 2006. [All Versions]. Remarkable progress in the mathematics and computer science of probability has led to a revolution in the scope of probabilistic models. In particular, ‘sophisticated’ probabilistic methods apply to structured relational systems such as graphs and grammars, of immediate relevance to the cognitive sciences. This review outlines progress in this rapidly developing field, which provides a potentially unifying perspective across a wide range of domains and levels of explanation. The structure and function of explanations - Trends in Cognitive Sciences, 2006. [All Versions]. Generating and evaluating explanations is spontaneous, ubiquitous and fundamental to our sense of understanding. Recent evidence suggests that in the course of an individual's reasoning, engaging in explanation can have profound effects on the probability assigned to causal claims, on how properties are generalized and on learning. These effects follow from two properties of the structure of explanations: explanations accommodate novel information in the context of prior beliefs, and do so in a way that fosters generalization. Explanatory Preferences Shape Learning and Inference - Trends in Cognitive Sciences, 2016. [All Versions]. People often learn by seeking explanations, and they assess the viability of hypotheses by considering how well they explain the data. An emerging body of work reveals that both children and adults have strong and systematic intuitions about what constitutes a good explanation, and that these explanatory preferences have a systematic impact on explanation-based processes. In particular, people favor explanations that are simple and broad, with the consequence that engaging in explanation can shape learning and inference by leading people to seek patterns and favor hypotheses that support broad and simple explanations. The Role of Explanatory Considerations in Updating - Cognition, 2015. [All Versions]. This paper investigates experimentally controversy in philosophy about the connection between explanation and inference, of whether judgments of the explanatory goodness of hypotheses do play a role when people revise their degrees of belief in those hypotheses upon the receipt of new evidence. Explanation, updating, and accuracy - Journal of Cognitive Psychology, 2016. [All Versions]. There is evidence that people update their credences partly on the basis of explanatory considerations. Philosophers have recently argued that to minimise the inaccuracy of their credences, people's updates also ought to be partly based on such considerations. However, there are many ways in which explanatory considerations can factor into updating, not all of which minimise inaccuracy. It is an open question whether in their updating, people take explanatory considerations into account in a way that philosophers would deem recommendable. To address this question, the authors re-analyse data from an experiment reported in Douven and Schupbach, “The role of explanatory considerations in updating”. Best, second-best, and good-enough explanations: How they matter to reasoning - Journal of Experimental Psychology, 2018. [All Versions]. There is a wealth of evidence that people’s reasoning is influenced by explanatory considerations. Three experiments investigate the descriptive adequacy of a precise proposal to be found in the philosophical literature, to wit, that we should infer to the best explanation, provided certain additional conditions are met. The main conslusions are that (a) the quality of an explanation is a good predictor of people’s willingness to accept that explanation, and a better predictor than the prior probability of the explanation, and (b) if more than one possible explanation is given, people are the less willing to infer the best explanation the better they deem the second-best explanation. How explanation guides belief change - Trends in Cognitive Sciences, 2021. [All Versions]. Philosophers have argued that people ought to change their graded beliefs via Bayes’ rule. Recent work in psychology indicates that people sometimes violate that rule by attending to explanatory factors. Results from computational modeling suggest that such violations may actually be rational. Use of current explanations in multicausal abductive reasoning - Cognitive Science, 2001. [All Versions]. Kinematic mental simulations in abduction and deduction - Proceedings of the National Academy of Sciences, 2013. [All Versions]. This paper presents a theory, and its computer implementation, of how mental simulations underlie the abductions of informal algorithms and deductions from these algorithms. Three experiments tested the theory’s predictions, using an environment of a single railway track and a siding. The results corroborated the use of a kinematic mental model in creating and testing informal algorithms and showed that individuals differ reliably in the ability to carry out these tasks. Patterns of abduction - Synthese, 2007. [All Versions]. A categorization for Abduction in the account of pure philosophy. Abduction: A categorical characterization - Journal of Applied Logic, 2015. [All Versions]. Defending Abduction - Philosophy of Science, 1999. [All Versions]. On the distinction between Peirce's abduction and Lipton's Inference to the best explanation - Synthese, 2011. [All Versions]. Abduction − the context of discovery + underdetermination = inference to the best explanation - Synthese, 2019. [All Versions]. Towards an Architecture for Cognitive Vision Using Qualitative Spatio-temporal Representations and Abduction - Spatial Cognition, 2002. [All Versions]. Abductive inference within a pragmatic framework - Synthese, 2018. [All Versions]. Disjunctive Abduction - New Generation Computing, 2019. [All Versions]. Probabilistic alternatives to Bayesianism: the case of explanationism - Frontiers in Psychology, 2015. [All Versions]. A non-Bayesian account of Abduction. A Probabilistic Theory of Abductive Reasoning - ICAART, 2021. [All Versions]. A probabilistic perspective for interpreting Abductive Reasoning. The order effect in human abductive reasoning: an empirical and computational study - Journal of Experimental & Theoretical Artificial Intelligence, 2006. [All Versions]. Abduction, Induction, and Analogy - Model-Based Reasoning in Science and Technology, 2010. [All Versions]. The distinctions and relations between Abduction, Induction, and Analogy. Remembrance of inferences past: Amortization in human hypothesis generation - Cognition, 2018. [All Versions]. A rational account of human hypothesis generation. The AHA! Experience: Creativity Through Emergent Binding in Neural Networks - Cognitive Science, 2012. [All Versions]. Explanation-seeking curiosity in childhood - Current Opinion in Behavioral Sciences, 2020. [All Versions]. A piece of developmental pshchological evidence for Abduction in young children. A Grammar of Hypotheses for Visualization, Data, and Analysis - 2022. [All Versions]. This work presents a grammar for expressing hypotheses in visual data analysis to formalize the previously abstract notion of "analysis tasks." Through the lens of this grammar, the authors lay the groundwork for how a user's data analysis questions can be operationalized and automated as a set of hypotheses (a hypothesis space). The authors demonstrate that the grammar-based approach for analysis tasks can provide a systematic method towards unifying three disparate spaces in visualization research: the hypotheses a dataset can express (a data hypothesis space), the hypotheses a user would like to refine or verify through analysis (an analysis hypothesis space), and the hypotheses a visualization design is capable of supporting (a visualization hypothesis space). The authors illustrate how the formalization of these three spaces can inform future research in visualization evaluation, knowledge elicitation, analytic provenance, and visualization recommendation by using a shared language for hypotheses. Finally, the authors compare the proposed grammar-based approach with existing visual analysis models and discuss the potential of a new hypothesis-driven theory of visual analytics. *Back to Top Scientific Discovery Scientific Discovery - Plato Stanford. A computational philosophy account on Scientific Discovery, the process or product of successful scientific inquiry, sometimes an Abduction-like (Explanation) thinking pattern. Models of Discovery: And Other Topics in the Methods of Science - Springer, 1977. [All Versions]. The original book on search as scientific thinking. Scientific discovery: Computational explorations of the creative processes - MIT Press, 1987. [All Versions]. The book is divided into four parts. Part I introduces the subject of discovery, defines the scope of our work, and discusses some of the issues that have surrounded and still surround our topic. Parts II and III contain the main body of our results, largely in the form of accounts of the performance of computer programs that simulate human thought processes to make scientific discoveries. Part II is devoted largely to the processes for inducing quantitative theories from data. Part III is devoted mainly to the processes for inducing qualitative descriptive and structural theories from data. In Part IV, on the basis of our experience, we discuss at a lower level of precision how the programs described in the preceding chapters could be combined into a single, more general discovery system, and we describe a wide range of the other component processes that enter into scientific discovery. Exploring science: The cognition and development of discovery processes - MIT Press, 2000. [All Versions]. In this book, D. Klahr sets out to describe the cognitive and developmental processes that have enabled scientists to make the discoveries that comprise the body of information we call "scientific knowledge." Over the past decade, Klahr and his colleagues have conducted laboratory experiments in which they create discovery contexts, computer-based environments, to evoke the kind of thinking characteristic of scientific discovery in the "real world." In attempting to solve the problems posed by the discovery tasks, experiment participants (from preschoolers to university students) use many of the same higher-order cognitive processes used by practicing scientists. Through his work, Klahr integrates two disparate approaches–the content-based approach and the process-based approach– to present a comprehensive model of the psychology of scientific discovery. Dual Space Search During Scientific Reasoning - Cognitive Science, 1988. [All Versions]. The original paper on the dual space search as scientific thinking theory. Complexity Management in a Discovery Task - CogSci'92, 1992. [All Versions]. Previous psychological research about scientific discovery has often focused on subjects' heuristics for discovering simple concepts with one relevant dimension or a few relevant dimensions with simple two-way interactions. This paper presents results from an experiment in which subjects had to discover a concept involving complex three-way interactions on a multi-valued output by running experiments in a computerized microworld. Twenty-two CMU undergraduates attempted the task, of which sixteen succeeded, in an average of 85 minutes. The analyses focus on three strategies used to regulate task complexity. First, subjects preferred depth-first to breadth-first search, with successful subjects regulating the number of features varied from experiment to experiment most effectively. Second, subjects systematically regulated the length of their experiments. Third, a new explicit search heuristic (Put Upon Stack Heuristic) used by successful subjects is described. A dual-space model of iteratively deepening exploratory learning - International Journal of Human-Computer Studies, 1996. [All Versions]. This paper describes a cognitive model of exploratory learning, which covers both trial-and-error and instruction-taking activities. The model, implemented in Soar, is grounded in empirical data of subjects in a task-oriented, trial-and-error exploratory learning situation. A key empirical finding reflected in the model is the repeated scanning of a subset of the available menu items, with increased attention to items on each successive scan. This is explained in terms of dual search spaces, the external interface and the user's internal knowledge, both of which must be tentatively explored with attention to changing costs and benefits. Heuristics for Scientific Experimentation: A Developmental Study - Cognitive Psychology, 1993. [All Versions]. A piece of evidence on children have basic scientific thinking skills. A 4-Space Model of Scientific Discovery - CogSci'95, 1995. [All Versions]. Extending the dual space search. When to trust the data: Further investigations of system error in a scientific reasoning task - Memory & Cognition, 1996. [All Versions]. A behavioral account on the shift between bottom-up observation and top-down reasoning. Confirmation, disconfirmation, and information in hypothesis testing - Psychological Review, 1987. [All Versions]. A psychological account on hypothesis testing. Hypothesis generation, sparse categories, and the positive test strategy - Psychological Review, 2011. [All Versions]. Children and adults as intuitive scientists - Psychological Review, 1989. [All Versions]. A perspective against search as scientific thinking. Abduction and styles of scientific thinking - Synthese, 2021. [All Versions]. A computational philosophy account connecting Abduction and scientific thinking. *Back to Top Rationalization Imagination and the generation of new ideas - Cognitive Development, 2015. [All Versions]. A variety of theories have been put forth to explain the function of imagination, most notably that imagination engages and develops children's theory of mind and counterfactual reasoning. This work proposes that a primary role for imagination is as a cognitive mechanism for efficiently generating new ideas without observing new evidence. Learners must generate hypotheses before they can assess the truth of these hypotheses. Given infinite possibilities, how do learners constrain the process of hypothesis generation? The authors suggest that learners represent abstract criteria for the solution to a problem and generate solutions that, if true, would solve the problem. As a preliminary test of this idea, the authors show that, in the absence of any fact of the matter (i.e., when neither prior knowledge nor statistical data distinguishes competing hypotheses), 4–6-year-olds (mean: 63 months) systematically converge on solutions to problems, consistent with an ability to imagine the abstract properties of causal problems and their solutions. How We Know What Not To Think - Trends in Cognitive Sciences, 2019. [All Versions]. Humans often represent and reason about unrealized possible actions---the vast infinity of things that were not (or have not yet been) chosen. This capacity is central to the most impressive of human abilities: causal reasoning, planning, linguistic communication, moral judgment, etc. Nevertheless, how do we select possible actions that are worth considering from the infinity of unrealized actions that are better left ignored? This work reviews research across the cognitive sciences, and find that the possible actions considered by default are those that are both likely to occur and generally valuable. This paper then offers a unified theory of why. The authors propose that (i) across diverse cognitive tasks, the possible actions we consider are biased towards those of general practical utility, and (ii) a plausible primary function for this mechanism resides in decision making. Rationalization is rational - Behavioral and Brain Sciences, 2020. [All Versions]. [Preprint]. Rationalization occurs when a person has performed an action and then concocts the beliefs and desires that would have made it rational. Then, people often adjust their own beliefs and desires to match the concocted ones. While many studies demonstrate rationalization, and a few theories describe its underlying cognitive mechanisms, we have little understanding of its function. Why is the mind designed to construct post hoc rationalizations of its behavior, and then to adopt them? This may accomplish an important task: transferring information between the different kinds of processes and representations that influence our behavior. Human decision making does not rely on a single process; it is influenced by reason, habit, instinct, norms, and so on. Several of these influences are not organized according to rational choice (i.e., computing and maximizing expected value). Rationalization extracts implicit information – true beliefs and useful desires – from the influence of these non-rational systems on behavior. Rationalizing constraints on the capacity for cognitive control - Trends in Cognitive Sciences, 2021. [All Versions]. Humans are remarkably limited in: (i) how many control-dependent tasks they can execute simultaneously, and (ii) how intensely they can focus on a single task. These limitations are universal assumptions of most theories of cognition. Yet, a rationale for why humans are subject to these constraints remains elusive. This feature review draws on recent insights from psychology, neuroscience, and machine learning, to suggest that constraints on cognitive control may result from a rational adaptation to fundamental, computational dilemmas in neural architectures. The reviewed literature implies that limitations in multitasking may result from a trade-off between learning efficacy and processing efficiency and that limitations in the intensity of commitment to a single task may reflect a trade-off between cognitive stability and flexibility. Why Imaginary Worlds? The psychological foundations and cultural evolution of fictions with imaginary worlds - Behavioral and Brain Sciences, 2021. [All Versions]. Imaginary worlds are extremely successful. The most popular fictions produced in the last few decades contain such a fictional world. They can be found in all fictional media, from novels (e.g., Lord of The Rings and Harry Potter) to films (e.g., Star Wars and Avatar), video games (e.g., The Legend of Zelda and Final Fantasy), graphic novels (e.g., One Piece and Naruto), and TV series (e.g., Star Trek and Game of Thrones), and they date as far back as ancient literature (e.g., the Cyclops Islands in The Odyssey, 850 BCE). Why such a success? Why so much attention devoted to non-existent worlds? In this paper, the authors propose that imaginary worlds co-opt our preferences for exploration, which have evolved in humans and nonhuman animals alike, to propel individuals toward new environments and new sources of reward. Humans would find imaginary worlds very attractive for the very same reasons, and under the same circumstances, as they are lured by unfamiliar environments in real life. After reviewing research on exploratory preferences in behavioral ecology, environmental esthetics, neuroscience, and evolutionary and developmental psychology, the authors focus on the sources of their variability across time and space, which they argue can account for the variability of the cultural preference for imaginary worlds. This hypothesis can, therefore, explain the way imaginary worlds evolved culturally, their shape and content, their recent striking success, and their distribution across time and populations. Coalescing the Vapors of Human Experience into a Viable and Meaningful Comprehension - CogSci'16, 2016. [All Versions]. Models of concept learning and theory acquisition often invoke a stochastic search process, in which learners generate hypotheses through some structured random process and thenevaluate them on some data measuring their quality or value. To be successful within a reasonable time-frame, these models need ways of generating good candidate hypotheses evenbefore the data are considered. Schulz (2012a) has proposed that studying the origins of new ideas in more everyday contexts, such as how we think up new names for things, can provide insight into the cognitive processes that generate good hypotheses for learning. We propose a simple generative model for how people might draw on their experience to propose new names in everyday domains such as pub names or action movies, and show that it captures surprisingly well the names that people actually imagine. We discuss the role for an analogous hypothesis-generation mechanism in enabling and constraining causal theory learning. *Back to Top Applications in AI Functional genomic hypothesis generation and experimentation by a robot scientist - Nature, 2004. [All Versions]. This paper describes a physically implemented robotic system that applies techniques from artificial intelligence to carry out cycles of scientific experimentation. The system automatically originates hypotheses to explain observations, devises experiments to test these hypotheses, physically runs the experiments using a laboratory robot, interprets the results to falsify hypotheses inconsistent with the data, and then repeats the cycle. The system is applied to the determination of gene function using deletion mutants of yeast (Saccharomyces cerevisiae) and auxotrophic growth experiments. The authors built and tested a detailed logical model (involving genes, proteins and metabolites) of the aromatic amino acid synthesis pathway. Interpretation as abduction - Artificial Intelligence, 1993. [All Versions]. Abduction is inference to the best explanation. The authors have developed an approach to abductive inference, called “weighted abduction”, that has resulted in a significant simplification of how the problem of interpreting texts is conceptualized. The interpretation of a text is the minimal explanation of why the text would be true. More precisely, to interpret a text, one must prove the logical form of the text from what is already mutually known, allowing for coercions, merging redundancies where possible, and making assumptions where necessary. It is shown how such “local pragmatics” problems as reference resolution, the interpretation of compound nominals, the resolution of syntactic ambiguity and metonymy, and schema recognition can be solved in this manner. Moreover, this approach of “interpretation as abduction” can be combined with the older view of “parsing as deduction” to produce an elegant and thorough integration of syntax, semantics, and pragmatics, one that spans the range of linguistic phenomena from phonology to discourse structure. Probabilistic Horn abduction and Bayesian networks - Artificial Intelligence, 1993. [All Versions]. This paper presents a simple framework for Horn-clause abduction, with probabilities associated with hypotheses. The framework incorporates assumptions about the rule base and independence assumptions amongst hypotheses. It is shown how any probabilistic knowledge representable in a discrete Bayesian belief network can be represented in this framework. The main contribution is in finding a relationship between logical and probabilistic notions of evidential reasoning. This provides a useful representation language in its own right, providing a compromise between heuristic and epistemic adequacy. Abductive Inference in Bayesian Networks: A Review - Advances in Bayesian Networks, 2004. [All Versions]. The goal of this paper is to serve as a survey for the problem of abductive inference (or belief revision) in Bayesian networks. Thus, the problem is introduced in its two variants: total abduction (or MPE) and partial abduction (or MAP) . Also, the problem is formulated in its general case, that is, looking for the K best explanations. Then, a (non exhaustive) review of exact and approximate algorithms for dealing with both abductive inference problems is carried out. Finally, the authors collect the main complexity results appeared in the literature for both problems (MPE and MAP). Abductive Logic Programming - Journal of Logic Computation, 1992. [All Versions]. This paper is a survey and critical overview of recent work on the extension of logic programming to perform abductive reasoning (abductive logic programming). The authors outline the general framework of abduction and its applications to knowledge assimilation and default reasoning; and they introduce an argumentation-theoretic approach to the use of abduction as an interpretation for negation as failure. ACLP: Abductive Constraint Logic Programming - The Journal of Logic Programming, 1999. [All Versions]. This paper presents the framework of Abductive Constraint Logic Programming (ACLP), which integrates Abductive Logic Programming (ALP) and Constraint Logic Programming (CLP). In ACLP, the task of abduction is supported and enhanced by its non-trivial integration with constraint solving. This integration of constraint solving into abductive reasoning facilitates a general form of constructive abduction and enables the application of abduction to computationally demanding problems. The paper studies the formal declarative and operational semantics of the ACLP framework together with its application to various problems. Abduction in Logic Programming - Computational Logic, 2002. [All Versions]. [Preprint]. Abduction in Logic Programming started in the late 80s, early 90s, in an attempt to extend logic programming into a framework suitable for a variety of problems in Artificial Intelligence and other areas of Computer Science. This paper aims to chart out the main developments of the field over the last ten years and to take a critical view of these developments from several perspectives: logical, epistemological, computational and suitability to application. The paper attempts to expose some of the challenges and prospects for the further development of the field. Bayesian Abductive Logic Programs: A Probabilistic Logic for Abductive Reasoning - IJCAI'11, 2011. [All Versions]. [Preprint]. This work introduces Bayesian Abductive Logic Programs (BALP), a probabilistic logic that adapts Bayesian Logic Programs (BLPs) for abductive reasoning. Like BLPs, BALPs also combine first-order logic and Bayes nets. However, unlike BLPs, which use deduction to construct Bayes nets, BALPs employ logical abduction. As a result, BALPs are more suited for problems like plan/activity recognition that require abductive reasoning. Abductive Plan Recognition by Extending Bayesian Logic Programs - ECML'11, 2011. [All Versions]. Plan recognition is the task of predicting an agent’s top-level plans based on its observed actions. It is an abductive reasoning task that involves inferring cause from effect. Most existing approaches to plan recognition use either first-order logic or probabilistic graphical models. While the former cannot handle uncertainty, the latter cannot handle structured representations. In order to overcome these limitations, this work develops an approach to plan recognition using Bayesian Logic Programs (BLPs), which combine first-order logic and Bayesian networks. Since BLPs employ logical deduction to construct the networks, they cannot be used effectively for plan recognition. Therefore, the authors extend BLPs to use logical abduction to construct Bayesian networks and call the resulting model Bayesian Abductive Logic Programs (BALPs). The authors learn the parameters in BALPs using the Expectation Maximization algorithm adapted for BLPs. Finally, the authors present an experimental evaluation of BALPs on three benchmark data sets and compare its performance with the state-of-the-art for plan recognition. An Approach to Abductive Reasoning in Equational Logic - IJCAI'13, 2013. [All Versions]. Abduction-Based Explanations for Machine Learning Models - AAAI'19, 2019. [All Versions]. The growing range of applications of Machine Learning (ML) in a multitude of settings motivates the ability of computing small explanations for predictions made. Small explanations are generally accepted as easier for human decision makers to understand. Most earlier work on computing explanations is based on heuristic approaches, providing no guarantees of quality, in terms of how close such solutions are from cardinality- or subset-minimal explanations. This paper develops a constraint-agnostic solution for computing explanations for any ML model. The proposed solution exploits abductive reasoning, and imposes the requirement that the ML model can be represented as sets of constraints using some target constraint reasoning system for which the decision problem can be answered with some oracle. The experimental results, obtained on well-known datasets, validate the scalability of the proposed approach as well as the quality of the computed solutions. Probabilistic Sufficient Explanations - IJCAI'21, 2021. [All Versions]. Understanding the behavior of learned classifiers is an important task, and various black-box explanations, logical reasoning approaches, and model-specific methods have been proposed. This paper introduces probabilistic sufficient explanations, which formulate explaining an instance of classification as choosing the "simplest" subset of features such that only observing those features is "sufficient" to explain the classification. That is, sufficient to give us strong probabilistic guarantees that the model will behave similarly when all features are observed under the data distribution. In addition, the authors leverage tractable probabilistic reasoning tools such as probabilistic circuits and expected predictions to design a scalable algorithm for finding the desired explanations while keeping the guarantees intact. The experiments demonstrate the effectiveness of the algorithm in finding sufficient explanations, and showcase its advantages compared to Anchors and logical explanations. Machine Translation Using Abductive Inference - COLING, 1990. [All Versions]. Many existing approaches to machine translation take for granted that the information presented in the output is found somewhere in the input, and, moreover, that such information should be expressed at a single representational level, say, in terms of the parse trees or of "semantic" assertions. Languages, however, not only express the equivalent information by drastically different linguistic means, but also often disagree in what distinctions should be expressed linguistically at all. For example, in translating from Japanese to English, it is often necessary to supply determiners for noun phrases, and this in general cannot be done without deep understanding of the source text. Similarly, in translating from English to Japanese, politeness considerations, which in English are implicit in the social situation and explicit in very diffuse ways in, for example, the heavy use of hypotheticals, must be realized grammatically in Japanese. Machine translation therefore requires that the appropriate inferences be drawn and that the text be interpreted to some depth. Recently, an elegant approach to inference in discourse interpretation has been developed at a number of sites, all based on the notion of abduction, and the authors have begun to explore its potential application to machine translation. The authors argue that this approach provides the possibility of deep reasoning and of mapping between the languages at a variety of levels. Automated Biodesign Engineering by Abductive Meta-Interpretive Learning - AAAI Spring Symposium Series 2021 on Artificial Intelligence for Synthetic Biology, 2021. [All Versions]. This work proposes an automated biodesign engineering framework empowered by Abductive Meta-Interpretive Learning (MetaAbd), a novel machine learning approach that combines symbolic and sub-symbolic machine learning, to further enhance the design-build-test-learn cycle by enabling the learning machine to 1) exploit domain knowledge and learn human-interpretable models that are expressed by formal languages such as first-order logic; 2) simultaneously optimise the structure and parameters of the models to make accurate numerical predictions; 3) reduce the cost of experiments and effort on data annotation by actively generating hypotheses and examples. Human Comprehensible Active Learning of Genome-Scale Metabolic Networks - AAAI Spring Symposium Series 2023 on Computational Scientific Discovery, 2023. [All Versions]. [Extended Abstract]. [Slides]. This work introduces a novel machine learning framework ILP-iML1515 based on Inductive Logic Programming (ILP) that performs abductive logical reasoning and actively learns from training examples. The ILP-iML1515 framework 1) allows high-throughput simulations and 2) actively selects experiments that reduce the experimental cost of learning gene functions in comparison to randomly selected experiments. *Back to Top Bayesian Modeling Bayesian Induction Bayesian Epistemology - Plato Stanford. A computational philosophy account on the nature of uncertainty modeling in Bayesian Epistemology. Probabilistic machine learning and artificial intelligence - Nature, 2015. [All Versions]. Probabilistic modelling provides a framework for understanding what learning is, and has therefore emerged as one of the principal theoretical and practical approaches for designing machines that learn from data acquired through experience. The probabilistic framework, which describes how to represent and manipulate uncertainty about models and predictions, has a central role in scientific data analysis, machine learning, robotics, cognitive science and artificial intelligence. This Review provides an introduction to this framework, and discusses some of the state-of-the-art advances in the field, namely, probabilistic programming, Bayesian optimization, data compression and automatic model discovery. Generalization, similarity, and Bayesian inference - Behavioral and Brain Sciences, 2001. [All Versions]. [Preprint]. Shepard has argued that a universal law should govern generalization across different domains of perception and cognition, as well as across organisms from different species or even different planets. Starting with some basic assumptions about natural kinds, he derived an exponential decay function as the form of the universal generalization gradient, which accords strikingly well with a wide range of empirical data. However, his original formulation applied only to the ideal case of generalization from a single encountered stimulus to a single novel stimulus, and for stimuli that can be represented as points in a continuous metric psychological space. The authors recast Shepard's theory in a more general Bayesian framework and show how this naturally extends his approach to the more realistic situation of generalizing from multiple consequential stimuli with arbitrary representational structure. This framework also subsumes a version of Tversky's set-theoretic model of similarity, which is conventionally thought of as the primary alternative to Shepard's continuous metric space model of similarity and generalization. Bayesian modeling of human concept learning - NeurIPS'98, 1998. [All Versions]. [Preprint]. This work considers the problem of learning concepts from small numbers of positive examples, a feat which humans perform routinely but which computers are rarely capable of. Bridging machine learning and cognitive science perspectives, this work presents both theoretical analysis and an empirical study with human subjects for the simple task oflearning concepts corresponding to axis-aligned rectangles in a multidimensional feature space. Existing learning models, when applied to this task, cannot explain how subjects generalize from only a few examples of the concept. The author proposes a principled Bayesian model based on the assumption that the examples are a random sample from the concept to be learned. The model gives precise fits to human behavior on this simple task and provides qualitati ve insights into more complex, realistic cases of concept learning. Rules and Similarity in Concept Learning - NeurIPS'99, 1999. [All Versions]. [Preprint]. This paper argues that two apparently distinct modes of generalizing concepts - abstracting rules and computing similarity to exemplars - should both be seen as special cases of a more general Bayesian learning framework. Bayes explains the specific workings of these two modes - which rules are abstracted, how similarity is measured - as well as why generalization should appear rule- or similarity-based in different situations. This analysis also suggests why the rules/similarity distinction, even if not computationally fundamental, may still be useful at the algorithmic level as part of a principled approximation to fully Bayesian learning. Theory-based Bayesian models of inductive learning and reasoning - Trends in Cognitive Sciences, 2006. [All Versions]. [Preprint]. Inductive inference allows humans to make powerful generalizations from sparse data when learning about word meanings, unobserved properties, causal relationships, and many other aspects of the world. Traditional accounts of induction emphasize either the power of statistical learning, or the importance of strong constraints from structured domain knowledge, intuitive theories or schemas. This paper argues that both components are necessary to explain the nature, use and acquisition of human knowledge, and the authors introduce a theory-based Bayesian framework for modeling inductive learning and reasoning as statistical inferences over structured knowledge representations. Word learning as Bayesian inference - Psychological Review, 2007. [All Versions]. [Preprint]. The authors present a Bayesian framework for understanding how adults and children learn the meanings of words. The theory explains how learners can generalize meaningfully from just one or a few positive examples of a novel word's referents, by making rational inductive inferences that integrate prior knowledge about plausible word meanings with the statistical structure of the observed examples. The theory addresses shortcomings of the two best known approaches to modeling word learning, based on deductive hypothesis elimination and associative learning. Three experiments with adults and children test the Bayesian account's predictions in the context of learning words for object categories at multiple levels of a taxonomic hierarchy. Results provide strong support for the Bayesian account over competing accounts, in terms of both quantitative model fits and the ability to explain important qualitative phenomena. Several extensions of the basic theory are discussed, illustrating the broader potential for Bayesian models of word learning. How to Grow a Mind: Statistics, Structure, and Abstraction - Science, 2011. [All Versions]. [Preprint]. This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired? Human-level concept learning through probabilistic program induction - Science, 2015. [All Versions]. [Preprint]. [Supplementary Material]. People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms—for action, imagination, and explanation. This work presents a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world’s alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches. Building Machines That Learn and Think Like People - Behavioral and Brain Sciences, 2017. [All Versions]. [Preprint]. Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. The authors review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, the authors argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. The authors suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models. Building machines that learn and think with people - Nature Human Behavior, 2024. [All Versions]. [Preprint]. This perspective shows how the science of collaborative cognition can be put to work to engineer systems that really can be called ‘thought partners’, systems built to meet humans' expectations and complement humans' limitations. The authors lay out several modes of collaborative thought in which humans and artificial intelligence thought partners can engage, and they propose desiderata for human-compatible thought partnerships. Drawing on motifs from computational cognitive science, this work motivates an alternative scaling path for the design of thought partners and ecosystems around their use through a Bayesian lens, whereby the constructed partners actively build and reason over models of the human and world. The rational basis of representativeness - CogSci'01, 2001. [All Versions]. Testing a Bayesian Measure of Representativeness Using a Large Image Database - NeurIPS'11, 2011. [All Versions]. Constructing a hypothesis space from the Web for large-scale Bayesian word learning - CogSci'12, 2012. [All Versions]. Modeling rules and similarity in colexification - CogSci'21, 2021. [All Versions]. Rule- and similarity-based generalization in colexification. Human-level few-shot concept induction through minimax entropy learning - Science Advances, 2024. [All Versions]. This paper introduces a computational model designed to emulate human inductive reasoning on abstract reasoning tasks, such as those in IQ tests, using a minimax entropy approach. This method combines identifying the most effective constraints on data via minimum entropy with determining the best combination of them via maximum entropy. *Back to Top Generative Model Generative Modeling Explained - Statistical Machine Learning Tutorials, 2022. This tutorial on generative modeling is in part of Statistical Machine Learning Tutorial by Ying Nian Wu at UCLA Statistics. The tutorial goes over the key equations and algorithms for learning recent generative models, including energy-based models, diffusion/score-based models, autoregressive/flow-based models, VAEs, and GANs, and explains the connections between these models. Bayesian Data Analysis - Chapman and Hall/CRC, 1995. [All Versions]. Don Rubin's introductory book on Bayesian models. Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling - International Journal of Computer Vision, 1998. [All Versions]. [Preprint]. This article presents a statistical theory for texture modeling. This theory combines filtering theory and Markov random field modeling through the maximum entropy principle, and interprets and clarifies many previous concepts and methods for texture analysis and synthesis from a unified point of view. The theory characterizes the ensemble of images I with the same texture appearance by a probability distribution f(I) on a random field, and the objective of texture modeling is to make inference about f(I), given a set of observed texture examples. Object Perception as Bayesian Inference - Annual Review of Psychology, 2004. [All Versions]. [Preprint]. We perceive the shapes and material properties of objects quickly and reliably despite the complexity and objective ambiguities of natural images. Typical images are highly complex because they consist of many objects embedded in background clutter. Moreover, the image features of an object are extremely variable and ambiguous owing to the effects of projection, occlusion, background clutter, and illumination. The very success of everyday vision implies neural mechanisms, yet to be understood, that discount irrelevant information and organize ambiguous or noisy local image features into objects and surfaces. Recent work in Bayesian theories of visual perception has shown how complexity may be managed and ambiguity resolved through the task-dependent, probabilistic integration of prior object knowledge with image features. A tale of three probabilistic families: Discriminative, descriptive, and generative models - Quarterly of Applied Mathematics, 2018. [All Versions]. [Preprint]. The pattern theory of Grenander is a mathematical framework where patterns are represented by probability models on random variables of algebraic structures. In this paper, the authors review three families of probability models, namely, the discriminative models, the descriptive models, and the generative models. A discriminative model is in the form of a classifier. It specifies the conditional probability of the class label given the input signal. A descriptive model specifies the probability distribution of the signal, based on an energy function defined on the signal. A generative model assumes that the signal is generated by some latent variables via a transformation. The authors shall review these models within a common framework and explore their connections, and shall also review the recent developments that take advantage of the high approximation capacities of deep neural networks. From information scaling of natural images to regimes of statistical models - Quarterly of Applied Mathematics, 2008. [All Versions]. [Preprint]. One fundamental property of natural image data that distinguishes vision from other sensory tasks such as speech recognition is that scale plays a profound role in image formation and interpretation. Specifically, visual objects can appear at a wide range of scales in the images due to the change of viewing distance as well as camera resolution. The same objects appearing at different scales produce different image data with different statistical properties. In particular, this work shows that the entropy rate of the image data changes over scale. Moreover, the inferential uncertainty changes over scale too. The authors call these changes information scaling. They then examine both empirically and theoretically two prominent and yet largely isolated classes of image models, namely, wavelet sparse coding models and Markov random field models. The results indicate that the two classes of models are appropriate for two different entropy regimes: sparse coding targets low entropy regimes, whereas Markov random fields are appropriate for high entropy regimes. Because information scaling connects different entropy regimes, both sparse coding and Markov random fields are necessary for representing natural image data, and information scaling triggers transitions between these two regimes. A Theory of Generative ConvNet - ICML'16, 2016. [All Versions]. The authors show that a generative random field model, which they call generative ConvNet, can be derived from the commonly used discriminative ConvNet, by assuming a ConvNet for multi-category classification and assuming one of the category is a base category generated by a reference distribution. For a further assumption that the non-linearity in the ConvNet is Rectified Linear Unit (ReLU) and the reference distribution is Gaussian white noise, then a generative ConvNet model that is unique among energy-based models is obtained: The model is piecewise Gaussian, and the means of the Gaussian pieces are defined by an auto-encoder, where the filters in the bottom-up encoding become the basis functions in the top-down decoding, and the binary activation variables detected by the filters in the bottom-up convolution process become the coefficients of the basis functions in the top-down deconvolution process. Cooperative Training of Descriptor and Generator Networks - IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018. [All Versions]. This paper studies the cooperative training of two generative models for image modeling and synthesis. Both models are parametrized by convolutional neural networks (ConvNets). The first model is a deep energy-based model, whose energy function is defined by a bottom-up ConvNet, which maps the observed image to the energy. We call it the descriptor network. The second model is a generator network, which is a non-linear version of factor analysis. It is defined by a top-down ConvNet, which maps the latent factors to the observed image. The maximum likelihood learning algorithms of both models involve MCMC sampling such as Langevin dynamics. This work observes that the two learning algorithms can be seamlessly interwoven into a cooperative learning algorithm that can train both models simultaneously. Specifically, within each iteration of the cooperative learning algorithm, the generator model generates initial synthesized examples to initialize a finite-step MCMC that samples and trains the energy-based descriptor model. After that, the generator model learns from how the MCMC changes its synthesized examples. That is, the descriptor model teaches the generator model by MCMC, so that the generator model accumulates the MCMC transitions and reproduces them by direct ancestral sampling. Learning Latent Space Energy-Based Prior Model - NeurIPS'20, 2020. [All Versions]. [Project]. [Code]. A milestone paper on Latent Energy-Based Model. Learning Energy-Based Models by Diffusion Recovery Likelihood - ICLR'21, 2021. [All Versions]. [Code]. Score-Based Generative Modeling through Stochastic Differential Equations - ICLR'21, 2021. [All Versions]. Latent Space Factorisation and Manipulation via Matrix Subspace Projection - ICML'20, 2020. [All Versions]. Minimax entropy principle and its application to texture modeling - Neural Computing, 1997. [All Versions]. [Preprint]. This article proposes a general theory and methodology, called the minimax entropy principle, for building statistical models for images (or signals) in a variety of applications. This principle consists of two parts. The first is the maximum entropy principle for feature binding (or fusion): for a given set of observed feature statistics, a distribution can be built to bind these feature statistics together by maximizing the entropy over all distributions that reproduce them. The second part is the minimum entropy principle for feature selection: among all plausible sets of feature statistics, we choose the set whose maximum entropy distribution has the minimum entropy. Computational and inferential issues in both parts are addressed; in particular, a feature pursuit procedure is proposed for approximately selecting the optimal set of features. The minimax entropy principle is then corrected by considering the sample variation in the observed feature statistics, and an information criterion for feature pursuit is derived. The minimax entropy principle is applied to texture modeling, where a novel Markov random field (MRF) model, called FRAME (filter, random field, and minimax entropy), is derived, and encouraging results are obtained in experiments on a variety of texture images. Parameter Expansion for Data Augmentation - Journal of the American Statistical Association, 1999. [All Versions]. [Preprint]. Viewing the observed data of a statistical model as incomplete and augmenting its missing parts are useful for clarifying concepts and central to the invention of two well-known statistical algorithms: expectation-maximization (EM) and data augmentation. Recently, the authors demonstrated that expanding the parameter space along with augmenting the missing data is useful for accelerating iterative computation in an EM algorithm. The main purpose of this article is to rigorously define a parameter expanded data augmentation (PX-DA) algorithm and to study its theoretical properties. The PX-DA is a special way of using auxiliary variables to accelerate Gibbs sampling algorithms and is closely related to reparameterization techniques. Image segmentation by data-driven markov chain monte carlo - IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002. [All Versions]. [Preprint]. This paper presents a computational paradigm called Data-Driven Markov Chain Monte Carlo (DDMCMC) for image segmentation in the Bayesian statistical framework. The paper contributes to image segmentation in four aspects. First, it designs efficient and well-balanced Markov Chain dynamics to explore the complex solution space and, thus, achieves a nearly global optimal solution independent of initial segmentations. Second, it presents a mathematical principle and a K-adventurers algorithm for computing multiple distinct solutions from the Markov chain sequence and, thus, it incorporates intrinsic ambiguities in image segmentation. Third, it utilizes data-driven (bottom-up) techniques, such as clustering and edge detection, to compute importance proposal probabilities, which drive the Markov chain dynamics and achieve tremendous speedup in comparison to the traditional jump-diffusion methods. Fourth, the DDMCMC paradigm provides a unifying framework in which the role of many existing segmentation algorithms, such as, edge detection, clustering, region growing, split-merge, snake/balloon, and region competition, are revealed as either realizing Markov chain dynamics or computing importance proposal probabilities. Thus, the DDMCMC paradigm combines and generalizes these segmentation methods in a principled way. Efficient Learning of Sparse Representations with an Energy-Based Model - NeurIPS'06, 2006. [All Versions]. A Tutorial on Energy-Based Learning - Predicting Structured Data, MIT Press, 2006. [All Versiosn]. Yann LeCun's tutorial on energy-based learning. Unsupervised Representaton Learning with Deep Convolutional Generative Adversarial Networks - ICLR'16, 2016. [All Versions]. Analysis of Langevin Monte Carlo via Convex Optimization - Journal of Machine Learning Research, 2019. [All Versions]. This paper provides new insights on the Unadjusted Langevin Algorithm. The authors show that this method can be formulated as the first order optimization algorithm for an objective functional defined on the Wasserstein space of order $2$. Using this interpretation and techniques borrowed from convex optimization, the authors give a non-asymptotic analysis of this method to sample from log-concave smooth target distribution on $\mathbb{R}^d$. Based on this interpretation, the authors propose two new methods for sampling from a non-smooth target distribution. These new algorithms are natural extensions of the Stochastic Gradient Langevin Dynamics (SGLD) algorithm, which is a popular extension of the Unadjusted Langevin Algorithm for largescale Bayesian inference. Using the optimization perspective, the authors provide non-asymptotic convergence analysis for the newly proposed methods. A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs - Science, 2017. [All Versions]. [Preprint]. Learning from a few examples and generalizing to markedly different situations are capabilities of human visual intelligence that are yet to be matched by leading machine learning models. By drawing inspiration from systems neuroscience, this work introduces a probabilistic generative model for vision in which message-passing–based inference handles recognition, segmentation, and reasoning in a unified way. The model demonstrates excellent generalization and occlusion-reasoning capabilities and outperforms deep neural networks on a challenging scene text recognition benchmark while being 300-fold more data efficient. In addition, the model fundamentally breaks the defense of modern text-based CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) by generatively segmenting characters without CAPTCHA-specific heuristics. Where do hypotheses come from? - Cognitive Psychology, 2017. [All Versions]. [Preprint]. Why are human inferences sometimes remarkably close to the Bayesian ideal and other times systematically biased? In particular, why do humans make near-rational inferences in some natural domains where the candidate hypotheses are explicitly available, whereas tasks in similar domains requiring the self-generation of hypotheses produce systematic deviations from rational inference. This work proposes that these deviations arise from algorithmic processes approximating Bayes’ rule. Specifically in our account, hypotheses are generated stochastically from a sampling process, such that the sampled hypotheses form a Monte Carlo approximation of the posterior. *Back to Top Nonparametric Model A Bayesian Analysis of Some Non-parametric Problems - The Annals of Statistics, 1973. [All Versions]. [Preprint]. A classic review on non-parametric problems. Mixtures of Dirichlet Process with Applications to Bayesian Nonparametric Problems - The Annals of Statistics, 1974. [All Versions]. The original paper on Dirichlet Process modeling for non-parametric problems. Latent Semantic Indexing: A Probabilistic Analysis - Journal of Computer and System Sciences, 2000. [All Versions]. The original paper on hierarchical topic model. Nonparametric Bayesian Data Analysis - Statistical Science, 2004. [All Versions]. This paper reviews the current state of nonparametric Bayesian inference. The discussion follows a list of important statistical inference problems, including density estimation, regression, survival analysis, hierarchical models and model validation. For each inference problem the authors review relevant nonparametric Bayesian models and approaches including Dirichlet process (DP) models and variations, Pólya trees, wavelet based models, neural network models, spline regression, CART, dependent DP models and model validation with DP and Pólya tree extensions of parametric models. Finding scientific topics - Proceedings of the National Academy of Sciences, 2004. [All Versions]. A first step in identifying the content of a document is determining which topics that document addresses. This paper describes a generative model for documents, in which each document is generated by choosing a distribution over topics and then choosing each word in the document from a topic selected according to this distribution. The authors then present a Markov chain Monte Carlo algorithm for inference in this model. The authors use this algorithm to analyze abstracts from PNAS by using Bayesian model selection to establish the number of topics. This work shows that the extracted topics capture meaningful structure in the data, consistent with the class designations provided by the authors of the articles, and outline further applications of this analysis, including identifying “hot topics” by examining temporal dynamics and tagging abstracts to illustrate semantic content. Hierarchical topic models and the nested Chinese restaurant process - NeurIPS'03, 2003. [All Versions]. The original paper for nested Chinese restaurant process. Learning Systems of Concepts with an Infinite Relational Model - AAAI'06, 2006. [All Versions]. The nested chinese restaurant process and bayesian nonparametric inference of topic hierarchies - Journal of the ACM, 2010. [All Versions]. Infinite Latent Feature Models and the Indian Buffet Process - Gatsby Computational Neuroscience Unit Technical Report 2005-001, 2005. [All Versions]. The Indian Buffet Process: An Introduction and Review - Journal of Machine Learning Research, 2011. [All Versions]. The Indian buffet process is a stochastic process defining a probability distribution over equivalence classes of sparse binary matrices with a finite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially infinite array of features, or that involve bipartite graphs in which the size of at least one class of nodes is unknown. This work gives a detailed derivation of this distribution, and illustrate its use as a prior in an infinite latent feature model. The authors then review recent applications of the Indian buffet process in machine learning, discuss its extensions, and summarize its connections to other stochastic processes. Nonparametric Bayesian Logic - UAI'05, 2005. [All Versions]. [Preprint]. The Bayesian Logic (BLOG) language was recently developed for defining first-order probability models over worlds with unknown numbers of objects. It handles important problems in AI, including data association and population estimation. This paper extends BLOG by adopting generative processes over function spaces — known as nonparametrics in the Bayesian literature. This work introduces syntax for reasoning about arbitrary collections of objects, and their properties, in an intuitive manner. By exploiting exchangeability, distributions over unknown objects and their attributes are cast as Dirichlet processes, which resolve difficulties in model selection and inference caused by varying numbers of objects. Infinite Hidden Relational Models - UAI'06, 2006. [All Versions]. [Preprint]. Relational learning analyzes the probabilistic constraints between the attributes of entities and relationships. This work extends the expressiveness of relational models by introducing for each entity (or object) an infinite-dimensional latent variable as part of a Dirichlet process (DP) mixture model. This work discusses inference in the model, which is based on a DP Gibbs sampler, i.e., the Chinese restaurant process. The authors extended the Chinese restaurant process to be applicable to relational modeling. Statistical Predicate Invention - ICML'07, 2007. [All Versions]. This work proposes statistical predicate invention as a key problem for statistical relational learning. SPI is the problem of discovering new concepts, properties and relations in structured data, and generalizes hidden variable discovery in statistical models and predicate invention in ILP. This work proposes an initial model for SPI based on second-order Markov logic, in which predicates as well as arguments can be variables, and the domain of discourse is not fully known in advance. The proposed approach iteratively refines clusters of symbols based on the clusters of symbols they appear in atoms with (e.g., it clusters relations by the clusters of the objects they relate). *Back to Top Bayesian Optimization Taking the Human Out of the Loop: A Review of Bayesian Optimization - Proceedings of the IEEE, 2015. [All Versions]. [Preprint]. Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications. Practical Bayesian Optimization of Machine Learning Algorithms - NeurIPS'12, 2012. [All Versions]. The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a “black art” requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. This work considers this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). The authors show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expert-level performance. The authors describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. These proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including Latent Dirichlet Allocation, Structured SVMs and convolutional neural networks. A Tutorial on Bayesian Optimization - 2018. [All Versions]. Bayesian optimization is an approach to optimizing objective functions that take a long time (minutes or hours) to evaluate. It is best-suited for optimization over continuous domains of less than 20 dimensions, and tolerates stochastic noise in function evaluations. It builds a surrogate for the objective and quantifies the uncertainty in that surrogate using a Bayesian machine learning technique, Gaussian process regression, and then uses an acquisition function defined from this surrogate to decide where to sample. This tutorial describes how Bayesian optimization works, including Gaussian process regression and three common acquisition functions: expected improvement, entropy search, and knowledge gradient. The authors then discuss more advanced techniques, including running multiple function evaluations in parallel, multi-fidelity and multi-information source optimization, expensive-to-evaluate constraints, random environmental conditions, multi-task Bayesian optimization, and the inclusion of derivative information. The authors conclude with a discussion of Bayesian optimization software and future research directions in the field. This tutorial provides a generalization of expected improvement to noisy evaluations, beyond the noise-free setting where it is more commonly applied. This generalization is justified by a formal decision-theoretic argument, standing in contrast to previous ad hoc modifications. *Back to Top Concepts Theory of Concepts Concepts - Plato Stanford. A collection of the computational philosophical debates about the concepts. Theory-theory - Wikipedia. Wikipedia for the Theory theory, a perspective that contextualizes concepts in theoretical (or empirical) systems. Conceptual Change in Childhood - MIT Press, 1985. [All Versions]. Susan Carey's book on the theory theory of concepts in child development. Words, thoughts, and theories - MIT Press, 1997. [All Versions]. Alison Gopnik's book that articulates and defends the "theory theory" of cognitive and semantic development, the idea that infants and young children, like scientists, learn about the world by forming and revising theories-a view of the origins of knowledge and meaning that has broad implications for cognitive science. The Theory Theory - Mapping the mind: Domain specificity in cognition and culture, Cambridge University Press, 1994. [All Versions]. Alison Gopnik's original paper on the theory theory. The Origin of Concepts - Oxford University Press, 2009. [All Versions]. Susan Carey's extended book on the theory theory of concepts in child development. What we mean when we say semantic: A Consensus statement on the nomenclature of semantic memory - 2023. [All Versions]. The aim of this multidisciplinary workgroup was to establish consensus definitions for some of the major recurring constructs in semantic research (e.g., concept, amodal, abstract). These efforts yielded a glossary consisting of succinct definitions, agreement, subjective confidence ratings, relevant theoretical background, and principled dissenting views. These core definitions will potentially yield benchmarks for aligning perspectives and improving cross-disciplinary communication in semantic research. Reconstructing constructivism: Causal models, Bayesian learning mechanisms, and the theory theory - Psychological Bulletin, 2012. [All Versions]. Alison Gopnik's review on the constructivism idea of developmental research, including the theory theory of concepts. Similarity involving attributes and relations: Judgments of similarity and difference are not inverses - Psychological Science, 1990. [All Versions]. Theory on similarity judgement by attributes and relations. *Back to Top Human Concept Representation Organizing conceptual knowledge in humans with a gridlike code - Science, 2016. [All Versions]. [Preprint]. It has been hypothesized that the brain organizes concepts into a mental map, allowing conceptual relationships to be navigated in a manner similar to that of space. Grid cells use a hexagonally symmetric code to organize spatial representations and are the likely source of a precise hexagonal symmetry in the functional magnetic resonance imaging signal. Humans navigating conceptual two-dimensional knowledge showed the same hexagonal signal in a set of brain regions markedly similar to those activated during spatial navigation. This gridlike signal is consistent across sessions acquired within an hour and more than a week apart. This work's findings suggest that global relational codes may be used to organize nonspatial conceptual representations and that these codes may have a hexagonal gridlike pattern when conceptual knowledge is laid out in two continuous dimensions. Navigating cognition: Spatial codes for human thinking - Science, 2018. [All Versions]. [Preprint]. The hippocampal formation has long been suggested to underlie both memory formation and spatial navigation. This work discusses how neural mechanisms identified in spatial navigation research operate across information domains to support a wide spectrum of cognitive functions. In the proposed framework, place and grid cell population codes provide a representational format to map variable dimensions of cognitive spaces. This highly dynamic mapping system enables rapid reorganization of codes through remapping between orthogonal representations across behavioral contexts, yielding a multitude of stable cognitive spaces at different resolutions and hierarchical levels. Action sequences result in trajectories through cognitive space, which can be simulated via sequential coding in the hippocampus. In this way, the spatial representational format of the hippocampal formation has the capacity to support flexible cognition and behavior. Structuring Knowledge with Cognitive Maps and Cognitive Graphs - Trends in Cognitive Sciences, 2021. [All Versions]. [Preprint]. Humans and animals use mental representations of the spatial structure of the world to navigate. The classical view is that these representations take the form of Euclidean cognitive maps, but alternative theories suggest that they are cognitive graphs consisting of locations connected by paths. The authors review evidence suggesting that both map-like and graph-like representations exist in the mind/brain that rely on partially overlapping neural systems. Maps and graphs can operate simultaneously or separately, and they may be applied to both spatial and nonspatial knowledge. By providing structural frameworks for complex information, cognitive maps and cognitive graphs may provide fundamental organizing schemata that allow us to navigate in physical, social, and conceptual spaces. Natural speech reveals the semantic maps that tile human cerebral cortex - Nature, 2016. [All Versions]. [Preprint]. [Code & Tutorial]. The meaning of language is represented in regions of the cerebral cortex collectively known as the ‘semantic system’. However, little of the semantic system has been mapped comprehensively, and the semantic selectivity of most regions is unknown. This work systematically maps semantic selectivity across the cortex using voxel-wise modelling of functional MRI (fMRI) data collected while subjects listened to hours of narrative stories. This work shows that the semantic system is organized into intricate patterns that seem to be consistent across individuals. The authors then use a novel generative model to create a detailed semantic atlas. The results suggest that most areas within the semantic system represent information about specific semantic domains, or groups of related concepts, and the atlas shows which domains are represented in each area. This study demonstrates that data-driven methods---commonplace in studies of human neuroanatomy and functional connectivity---provide a powerful and efficient means for mapping functional representations in the brain. Idiosyncratic Tower of Babel: Individual differences in word-meaning representation increase as word abstractness increases - Psychological Science, 2021. [All Versions]. [All Versions]. Humans primarily rely on language to communicate, on the basis of a shared understanding of the basic building blocks of communication: words. Do we mean the same things when we use the same words? Although cognitive neural research on semantics has revealed the common principles of word-meaning representation, the factors underlying the potential individual variations in word meanings are unknown. This work empirically characterized the intersubject consistency of 90 words across 20 adult subjects (10 female) using both behavioral measures (rating-based semantic-relationship patterns) and neuroimaging measures (word-evoked brain activity patterns). Across both the behavioral and neuroimaging experiments, this work showed that the magnitude of individual disagreements on word meanings could be modeled on the basis of how much language or sensory experience is associated with a word and that this variation increases with word abstractness. Uncovering the cognitive and neural origins of word-meaning disagreements across individuals has implications for potential mechanisms to modulate such disagreements. Semantic projection recovers rich human knowledge of multiple object features from word embeddings - Nature Human Behavior, 2022. [All Versions]. [Preprint]. How is knowledge about word meaning represented in the mental lexicon? Current computational models infer word meanings from lexical co-occurrence patterns. They learn to represent words as vectors in a multidimensional space, wherein words that are used in more similar linguistic contexts—that is, are more semantically related—are located closer together. However, whereas inter-word proximity captures only overall relatedness, human judgements are highly context dependent. For example, dolphins and alligators are similar in size but differ in dangerousness. This work proposes a domain-general method to extract context-dependent relationships from word embeddings: ‘semantic projection’ of word-vectors onto lines that represent features such as size (the line connecting the words ‘small’ and ‘big’) or danger (‘safe’ to ‘dangerous’), analogous to ‘mental scales’. This method recovers human judgements across various object categories and properties. Thus, the geometry of word embeddings explicitly represents a wealth of context-dependent world knowledge. Using a high-dimensional graph of semantic space to model relationships among words - Frontiers in Psychology, 2014. [All Versions]. The GOLD model (Graph Of Language Distribution) is a network model constructed based on co-occurrence in a large corpus of natural language that may be used to explore what information may be present in a graph-structured model of language, and what information may be extracted through theoretically-driven algorithms as well as standard graph analysis methods. The present study will employ GOLD to examine two types of relationship between words: semantic similarity and associative relatedness. Semantic similarity refers to the degree of overlap in meaning between words, while associative relatedness refers to the degree to which two words occur in the same schematic context. It is expected that a graph structured model of language constructed based on co-occurrence should easily capture associative relatedness, because this type of relationship is thought to be present directly in lexical co-occurrence. However, it is hypothesized that semantic similarity may be extracted from the intersection of the set of first-order connections, because two words that are semantically similar may occupy similar thematic or syntactic roles across contexts and thus would co-occur lexically with the same set of nodes. Two versions the GOLD model that differed in terms of the co-occurence window, bigGOLD at the paragraph level and smallGOLD at the adjacent word level, were directly compared to the performance of a well-established distributional model, Latent Semantic Analysis (LSA). The superior performance of the GOLD models (big and small) suggest that a single acquisition and storage mechanism, namely co-occurrence, can account for associative and conceptual relationships between words and is more psychologically plausible than models using singular value decomposition (SVD). Simple shape feature computation across modalities: convergence and divergence between the ventral and dorsal visual streams - Cerebral Cortex, 2023. [All Versions]. [Preprints]. Shape processing, whether by seeing or touching, is pivotal to object recognition and manipulation. Although the low-level signals are initially processed by different modality-specific neural circuits, multimodal responses to object shapes have been reported along both ventral and dorsal visual pathways. To understand this transitional process, the authors conducted visual and haptic shape perception fMRI experiments to test basic shape features (i.e. curvature and rectilinear) across the visual pathways. Using a combination of region-of-interest-based support vector machine decoding analysis and voxel selection method, the authors found that the top visual-discriminative voxels in the left occipital cortex (OC) could also classify haptic shape features, and the top haptic-discriminative voxels in the left posterior parietal cortex (PPC) could also classify visual shape features. Furthermore, these voxels could decode shape features in a cross-modal manner, suggesting shared neural computation across visual and haptic modalities. In the univariate analysis, the top haptic-discriminative voxels in the left PPC showed haptic rectilinear feature preference, whereas the top visual-discriminative voxels in the left OC showed no significant shape feature preference in either of the two modalities. Together, these results suggest that mid-level shape features are represented in a modality-independent manner in both the ventral and dorsal streams. The Database of Cross-Linguistic Colexifications, reproducible analysis of cross-linguistic polysemies - Scientific Data, 2020. [All Versions]. [Project]. Advances in computer-assisted linguistic research have been greatly influential in reshaping linguistic research. With the increasing availability of interconnected datasets created and curated by researchers, more and more interwoven questions can now be investigated. Such advances, however, are bringing high requirements in terms of rigorousness for preparing and curating datasets. This work presents CLICS, a Database of Cross-Linguistic Colexifications (CLICS). CLICS tackles interconnected interdisciplinary research questions about the colexifcation of words across semantic categories in the world’s languages, and show-cases best practices for preparing data for cross-linguistic research. Locating what comes to mind in empirically derived representational spaces - Cognition, 2023. [All Versions]. An evidence-based study concluding that people call category members to mind according to their location in representational space, specifically based on the predicted usefulness of considering category members with particular features. Why concepts are (probably) vectors - Trends in Cognitive Sciences, 2024. [All Versions]. For decades, cognitive scientists have debated what kind of representation might characterize human concepts. Whatever the format of the representation, it must allow for the computation of varied properties, including similarities, features, categories, definitions, and relations. It must also support the development of theories, ad hoc categories, and knowledge of procedures. Here, the authors discuss why vector-based representations provide a compelling account that can meet all these needs while being plausibly encoded into neural architectures. This view has become especially promising with recent advances in both large language models and vector symbolic architectures. These innovations show how vectors can handle many properties traditionally thought to be out of reach for neural models, including compositionality, definitions, structures, and symbolic computational processes. *Back to Top AI Concept Representation A principal odor map unifies diverse tasks in olfactory perception - Science, 2023. [All Versions]. [Code]. [Data (Reproduced)]. [Preprint]. [GoodScents Database]. [Leffingwell Database]. Mapping molecular structure to odor perception is a key challenge in olfaction. This work used graph neural networks to generate a principal odor map (POM) that preserves perceptual relationships and enables odor quality prediction for previously uncharacterized odorants. The model was as reliable as a human in describing odor quality: On a prospective validation set of 400 out-of-sample odorants, the model-generated odor profile more closely matched the trained panel mean than did the median panelist. By applying simple, interpretable, theoretically rooted transformations, the POM outperformed chemoinformatic models on several other odor prediction tasks, indicating that the POM successfully encoded a generalized map of structure-odor relationships. This approach broadly enables odor prediction and paves the way toward digitizing odors. Metabolic activity organizes olfactory representations - eLife, 2023. [All Versions]. [Code & Data]. Odorous compounds with similar POM representations are more likely to co-occur within a substance and be metabolically closely related; metabolic reaction sequences also follow smooth paths in POM despite large jumps in molecular structure. A Review of Tactile Information: Perception and Action Through Touch - IEEE Transactions on Robotics, 2020. [All Versions]. [Preprint]. Tactile sensing is a key sensor modality for robots interacting with their surroundings. These sensors provide a rich and diverse set of data signals that contain detailed information collected from contacts between the robot and its environment. The data are however not limited to individual contacts and can be used to extract a wide range of information about the objects in the environment as well as the actions of the robot during the interactions. This article provides an overview of tactile information and its applications in robotics. The authors present a hierarchy consisting of raw, contact, object, and action levels to structure the tactile information, with higher-level information often building upon lower-level information. The authors discuss different types of information that can be extracted at each level of the hierarchy. The article also includes an overview of different types of robot applications and the types of tactile information that they employ. Finally the article ends with a discussion for future tactile applications which are still beyond the current capabilities of robots. ImageBind: One Embedding Space To Bind Them All - CVPR'23, 2023. [All Versions]. [Project]. This work presents ImageBind, an approach to learn a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data. The authors show that all combinations of paired data are not necessary to train such a joint embedding, and only image-paired data is sufficient to bind the modalities together. ImageBind can leverage recent large scale vision-language models, and extends their zero-shot capabilities to new modalities just by using their natural pairing with images. It enables novel emergent applications 'out-of-the-box' including cross-modal retrieval, composing modalities with arithmetic, cross-modal detection and generation. The emergent capabilities improve with the strength of the image encoder and this work sets a new state-of-the-art on emergent zero-shot recognition tasks across modalities, outperforming specialist supervised models. Finally, the authors show strong few-shot recognition results outperforming prior work, and that ImageBind serves as a new way to evaluate vision models for visual and non-visual tasks. Semantic features of object concepts generated with GPT-3 - CogSci'22, 2022. [All Versions]. Semantic features have been playing a central role in investigating the nature of our conceptual representations. Yet the enormous time and effort required to empirically sample and norm features from human raters has restricted their use to a limited set of manually curated concepts. Given recent promising developments with transformer-based language models, here the authors asked whether it was possible to use such models to automatically generate meaningful lists of properties for arbitrary object concepts and whether these models would produce features similar to those found in humans. To this end, the authors probed a GPT-3 model to generate semantic features for 1,854 objects and compared automatically-generated features to existing human feature norms. GPT-3 generated many more features than humans, yet showed a similar distribution in the types of generated features. Generated feature norms rivaled human norms in predicting similarity, relatedness, and category membership, while variance partitioning demonstrated that these predictions were driven by similar variance in humans and GPT-3. Together, these results highlight the potential of large language models to capture important facets of human knowledge and yield a new approach for automatically generating interpretable feature sets, thus drastically expanding the potential use of semantic features in psychological and linguistic studies. Connecting Touch and Vision via Cross-Modal Prediction - CVPR'19, 2019. [All Versions]. [Project]. Humans perceive the world using multi-modal sensory inputs such as vision, audition, and touch. This work investigates the cross-modal connection between vision and touch. The main challenge in this cross-domain modeling task lies in the significant scale discrepancy between the two: while our eyes perceive an entire visual scene at once, humans can only feel a small region of an object at any given moment. To connect vision and touch, this work introduces new tasks of synthesizing plausible tactile signals from visual inputs as well as imagining how we interact with objects given tactile data as input. To accomplish the goals, the authors first equip robots with both visual and tactile sensors and collect a large-scale dataset of corresponding vision and tactile image sequences. To close the scale gap, the authors present a new conditional adversarial model that incorporates the scale and location information of the touch. Human perceptual studies demonstrate that the model can produce realistic visual images from tactile data and vice versa. Unit Testing for Concepts in Neural Networks - Transactions of the Association for Computational Linguistics, 2022. [All Versions]. Testing the concept representation by neural networks through Fodor's theory of concepts. Do Llamas Work in English? On the Latent Language of Multilingual Transformers - ACL'24, 2024. [All Versions]. A preliminary work empirically showing that the intermediate embeddings of multilingual Transformers (1) start far away from output token embeddings; (2) already allow for decoding a semantically correct next token in the middle layers, but give higher probability to its version in English than in the input language; (3) finally move into an input-language-specific region of the embedding space. Also, the embedding of abstract concept space lies closer to English than to other languages. From task structures to world models: what do LLMs know? - Trends in Cognitive Sciences, 2024. [All Versions]. [Preprint]. In what sense does a large language model (LLM) have knowledge? The authors answer by granting LLMs ‘instrumental knowledge’: knowledge gained by using next-word generation as an instrument. The authors then ask how instrumental knowledge is related to the ordinary, ‘worldly knowledge’ exhibited by humans, and explore this question in terms of the degree to which instrumental knowledge can be said to incorporate the structured world models of cognitive science. The authors discuss ways LLMs could recover degrees of worldly knowledge and suggest that such recovery will be governed by an implicit, resource-rational tradeoff between world models and tasks. The authors' answer to this question extends beyond the capabilities of a particular AI system and challenges assumptions about the nature of knowledge and intelligence. *Back to Top Complexity & Information Theory Theory A Mathematical Theory of Communication - The Bell System Technical Journal, 1948. [All Versions]. Shannon's original paper on Information Theory. An introduction to Kolmogorov complexity and its applications - Springer, 2008. [All Versions]. The introductory book for Algorithmic Information Theory, especially the Kolmogorov complexity theory. Complexity and the representation of patterned sequences of symbols - Psychological Review, 1972. [All Versions]. Herbert Simon's review on subjective complexity. Visual Pattern Discrimination - IRE Transactions on Information Theory, 1962. [All Versions]. Algorithmic Information Theory - IBM Journal of Research and Development, 1977. [All Versions]. Chaitin's original paper on Algorithmic Information Theory. From Algorithmic to Subjective Randomness - NeurIPS'03, 2003. [All Versions]. On the Complexity of Bayesian Generalization - ICML'23, 2023. [All Versions]. [Project]. [Models]. This work examines concept generalization at a large scale in the natural visual spectrum. Established computational modes (i.e., rule-based or similarity-based) are primarily studied isolated, focusing on confined and abstract problem spaces. This work studies these two modes when the problem space scales up and when the complexity of concepts becomes diverse. At the representational level, the authors investigate how the complexity varies when a visual concept is mapped to the representation space. Prior literature has shown that two types of complexities build an inverted-U relation. Leveraging Representativeness of Attribute (RoA), the authors computationally confirm: Models use attributes with high RoA to describe visual concepts, and the description length falls in an inverted-U relation with the increment in visual complexity. At the computational level, the authors examine how the complexity of representation affects the shift between the rule- and similarity-based generalization. The authors hypothesize that category-conditioned visual modeling estimates the co-occurrence frequency between visual and categorical attributes, thus potentially serving as the prior for the natural visual world. Experimental results show that representations with relatively high subjective complexity outperform those with relatively low subjective complexity in rule-based generalization, while the trend is the opposite in similarity-based generalization. *Back to Top Dimensionality Reduction A global geometric framework for nonlinear dimensionality reduction - Science, 2000. [All Versions]. The original paper on spectrum clustering. Reducing the dimensionality of data with neural networks - Science, 2006. [All Versions]. The original paper on Variational Autoencoder. Representation Learning: A Review and New Perspectives - IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013. [All Versions]. Yoshua Bengio's review on representation learning. Representation Learning: A Statistical Perspective - Annual Review of Statistics and Its Application, 2020. [All Versions]. Song-Chun Zhu and Ying Nian Wu's review on representation learning, in an account of statistics. Deep Learning and the Information Bottleneck Principle - IEEE Information Theory Workshop'15, 2015. [All Versions]. The first paper identifying the problem of information bottleneck in representation learning. On the information bottleneck theory of deep learning - Journal of Statistical Mechanics: Theory and Experiment, 2019. [All Versions]. *Back to Top Visual Complexity Visual complexity: a review - Psychological Bulletin, 2006. [All Versions]. [APA]. A psychological account on visual complexity. Compressed File Length Predicts Search Time and Errors on Visual Displays - Displays, 2005. [All Versions]. Compressed file size, an objective, easily obtained measure of display complexity, predicts both subjective complexity judgments and objective search performance. It is analogous to algorithmic complexity, a theoretical but impractical measure of bit string complexity. The data suggest that it may be possible to use the compressed file size measure to predict display performance in applied tasks. Image complexity and spatial information - International Workshop on Quality of Multimedia Experience, 2013. [All Versions]. Seeing and speaking: How verbal “description length” encodes visual complexity - Journal of Experimental Psychology, 2022. [All Versions]. [APA]. Empirical evidencs showing the relation between visual complexity and description length. How variability shapes learning and generalization - Trends in Cognitive Sciences, 2022. [All Versions]. A comprehensive review on the trade-off between variability and generalization ability. Identifying concept libraries from language about object structure - CogSci'22, 2022. [All Versions]. Show or tell? Exploring when (and why) teaching with language outperforms demonstration - Cognition, 2023. [All Versions]. The findings of this paper suggest that language communicates complex concepts by directly transmitting abstract rules. In contrast, demonstrations transmit examples, requiring the learner to infer the rules. *Back to Top Communications Non-Verbal Communication The Interactive Evolution of Human Communication Systems - Cognitive Science, 2010. [All Versions]. Nicolas Fay's original paper on iconicity. Iconicity: From sign to system in human communication and language - Pragmatics & Cognition, 2014. [All Versions]. This paper explores the role of iconicity in spoken language and other human communication systems. The Picture Exchange Communication System - Behavior Modification, 1994. [All Versions]. Graphical Language Games: Interactional Constraints on Representational Form - Cognitive Science, 2007. [All Versions]. The first paper introducing the graphical language game. A multimodal discourse theory of visual narrative - Journal of Pragmatics, 2014. [All Versions]. Pixelor: A Competitive Sketching AI Agent. So you think you can beat me? - ACM SIGGRAPH'20, 2020. [All Versions]. [Project]. Rationality in feature sketching. Pragmatic Inference and Visual Abstraction Enable Contextual Flexibility During Visual Communication - Computational Brain & Behavior, 2020. [All Versions]. A computational account on the rational behavior in graphical language games. Emergent Graphical Conventions in a Visual Communication Game - NeurIPS, 2022. [All Versions]. A computational account on the emergence of iconic language. AI Nüshu: An Exploration of Language Emergence in Sisterhood Through the Lens of Computational Linguistics - ACM SIGGRAPH Asia'23, 2023. [All Versions]. By continually observing their environment and communicating, AI agents trained in the Chinese dictionary and the Nüshu corpus collaborate towards creating a standard writing system to encode Chinese. Communicating artificial neural networks develop efficient color-naming systems - Proceedings of the National Academy of Sciences, 2021. [All Versions]. Simulating the emergence of code as the communication bottleneck in color learning task. Bridging cultural and cognitive perspectives on similarity reasoning - CogSci'22, 2022. [All Versions]. Twelve-month-olds communicate helpfully and appropriately for knowledgeable and ignorant partners - Cognition, 2008. [All Versions]. The original paper on child pointing. 12- and 18-Month-Olds Point to Provide Information for Others - Journal of Cognition and Development, 2009. [All Versions]. Toward understanding the importance of gesture in distributed scientific collaboration - Knowledge and Information Systems, 2006. [All Versions]. *Back to Top Pragmatics Pragmatics - Plato Stanford. A computational philosophy account of Pragmatics, whilch studies utterances in specific contexts. Predicting Pragmatic Reasoning in Language Games - Science, 2012. [All Versions]. [Preprint]. One of the most astonishing features of human language is its capacity to convey information efficiently in context. Many theories provide informal accounts of communicative inference, yet there have been few successes in making precise, quantitative predictions about pragmatic reasoning. This work examined judgments about simple referential communication games, modeling behavior in these games by assuming that speakers attempt to be informative and that listeners use Bayesian inference to recover speakers’ intended referents. The model provides a close, parameter-free fit to human judgments, suggesting that the use of information-theoretic tools to predict pragmatic reasoning may lead to more effective formal models of communication. Pragmatic Language Interpretation as Probabilistic Inference - Trends in Cognitive Sciences, 2016. [All Versions]. Understanding language requires more than the use of fixed conventions and more than decoding combinatorial structure. Instead, comprehenders make exquisitely sensitive inferences about what utterances mean given their knowledge of the speaker, language, and context. Building on developments in game theory and probabilistic modeling, the authors describe the rational speech act (RSA) framework for pragmatic reasoning. RSA models provide a principled way to formalize inferences about meaning in context; they have been used to make successful quantitative predictions about human behavior in a variety of different tasks and situations, and they explain why complex phenomena, such as hyperbole and vagueness, occur. More generally, they provide a computational framework for integrating linguistic structure, world knowledge, and context in pragmatic language understanding. Pragmatic Reasoning through Semantic Inference - Semantics & Pragmatics, 2016. [All Versions]. Processing gradable adjectives in context: A visual world study - Semantics and Linguistic Theory, 2016. [All Versions]. Adjective understanding as a rational inference in the context. Colors in Context: A Pragmatic Neural Model for Grounded Language Understanding - Transactions of the Association for Computational Linguistics, 2017. [All Versions]. Social Pragmatics: Preschoolers Rely on Commonsense Psychology to Resolve Referential Underspecification - Child Development, 2019. [All Versions]. A piece of evidence for children's capability on social pragmatics. Pragmatically Informative Image Captioning with Character-Level Inference - NAACL'18, 2018. [All Versions]. Pragmatic Issue-Sensitive Image Captioning - EMNLP Findings'20, 2020. [All Versions]. Application of Rational Speech Act to Image Captioning. Disentangling contributions of visual information and interaction history in the formation of graphical conventions - CogSci'19, 2019. [All Versions]. How young children integrate information sources to infer the meaning of words - Nature Human Behavior, 2021. [All Versions]. Before formal education begins, children typically acquire a vocabulary of thousands of words. This learning process requires the use of many different information sources in their social environment, including their current state of knowledge and the context in which they hear words used. This paper specifies a developmental model according to which children consider information sources in an age-specific way and integrate them via Bayesian inference. This work presents a developmental theory of information integration during language learning and illustrates how formal models can be used to make a quantitative test of the predictive and explanatory power of competing theories. Information Structure in Discourse: Towards an Integrated Formal Theory of Pragmatics - Semantics and Pragmatics, 1998. [All Versions]. When Lingens meets Frege: communication without common ground - Philosophical Studies, 2021. [All Versions]. The SocialAI School: Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents - ICML'23 Workshop on Theory-of-Mind, 2023. [All Versions]. [Project]. Language as shaped by the environment: linguistic construal in a collaborative spatial task - Humanities and Social Sciences Communications, 2020. [All Versions]. [Code & Data]. [Dialogue Experimental Toolkit(DiET)]. The present study sets out to experimentally investigate how environmental factors come to shape the emergence of linguistic conventions. To this end, the authors adapt the classical Maze Game task to test the hypothesis that participants routinise different linguistic strategies to communicate positions in the maze contingent on particular environmental affordances (i.e. structure of the mazes). The results confirm that subtle environmental motivations drive the emergence of different communicative conventions in an otherwise identical task, suggesting that linguistic adaptations are highly sensitive to factors of the shared task environment. Exploring Urban Form Through Openstreetmap Data: A Visual Introduction - Urban Experience and Design: Contemporary Perspectives on Improving the Public Realm, 2020. [All Versions]. [OSMnx Tool]. [OpenStreetMap Website]. Saying what you mean in dialogue: A study in conceptual and semantic co-ordination - Cognition, 1987. [All Versions]. Conversation, co-ordination and convention: an empirical investigation of how groups establish linguistic conventions - Cognition, 1994. [All Versions]. *Back to Top Language Compositionality Compositionality - Plato Stanford. A computational philosophy account on compositionality, one of the distinctive feature of language. Language is primarily a tool for communication rather than thought - Nature, 2024. [All Versions]. This perspective brings recent evidence from neuroscience and allied disciplines to argue that in modern humans, language is a tool for communication, contrary to a prominent view that we use language for thinking. The authors begins by introducing the brain network that supports linguistic ability in humans. They then review evidence for a double dissociation between language and thought, and discuss several properties of language that suggest that it is optimized for communication. This perspective concludes that although the emergence of language has unquestionably transformed human culture, language does not appear to be a prerequisite for complex thought, including symbolic thought. Instead, language is a powerful tool for the transmission of cultural knowledge; it plausibly co-evolved with humans' thinking and reasoning capacities, and only reflects, rather than gives rise to, the signature sophistication of human cognition. The Principle of Semantic Compositionality - Topoi, 1994. [All Versions]. The original paper on the principle of semantic compositionality. On The Emergence Of Compositionality - Proceedings of the Evolution of Language Conference'06, 2006. [All Versions]. The original paper on the emergence of compositionality. Multi-Agent Cooperation and the Emergence of (Natural) Language - ICLR'17, 2017. [All Versions]. The original paper on the emergence of language in multi-agent reinforcement learning. Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols - NeurIPS'18, 2018. [All Versions]. Emergent communication through negotiation - ICLR'18, 2018. [All Versions]. The language of generalization - Psychological Review, 2019. [All Versions]. Compositionality and Generalization in Emergent Languages - ACL'20, 2020. [All Versions]. Word formation supports efficient communication: The case of compounds - CogSci'22, 2022. [All Versions]. War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars - 2023. [All Versions]. *Back to Top Coordination In situ bidirectional human-robot value alignment - Science Robotics, 2022. [All Versions]. [Preprint]. This paper proposes an explainable artificial intelligence (XAI) system in which a group of robots predicts users’ values by taking in situ feedback into consideration while communicating their decision processes to users through explanations. To learn from human feedback, the XAI system integrates a cooperative communication model for inferring human values associated with multiple desirable goals. To be interpretable to humans, it simulates human mental dynamics and predicts optimal explanations using graphical models. From Explicit Communication to Tacit Cooperation: A Novel Paradigm for Cooperative MARL - AAMAS'24, 2024. [All Versions]. Drawing inspiration from human team cooperative learning, this paper proposes a novel paradigm that facilitates a gradual shift from explicit communication to tacit cooperation. *Back to Top Domain Specific Language Design Theory Domain-Specific Language - Wikipedia. Wikipedia encyclopedia entry on Domain Specific Languages. Domain Engineering - Wikipedia. Wikipedia encyclopedia entry on Domain Engineering. Domain-Specific Languages - Pearson Education, 2010. [All Versions]. [Domain-Specific Languages Guide]. When carefully selected and used, Domain-Specific Languages (DSLs) may simplify complex code, promote effective communication with customers, improve productivity, and unclog development bottlenecks. In Domain-Specific Languages, noted software development expert Martin Fowler first provides the information software professionals need to decide if and when to utilize DSLs. Then, where DSLs prove suitable, Fowler presents effective techniques for building them, and guides software engineers in choosing the right approaches for their applications. Comparison of multi-paradigm programming languages - Wikipedia. Programming languages may support multiple programming paradigms. This Wikipedia encyclopedia entry lists a concise reference for the programming paradigms. Epigrams on programming - ACM SIGPLAN Notices, 1982. [All Versions]. The complete guide to (external) Domain Specific Languages. An introduction to Domain Specific Languages (DSL) based on 19 DSL cases. When and How to Develop Domain-Specific Languages - ACM Computing Surveys, 2005. [All Versions]. [Preprint]. Domain-specific languages (DSLs) are languages tailored to a specific application domain. They offer substantial gains in expressiveness and ease of use compared with general-purpose programming languages in their domain of application. DSL development is hard, requiring both domain knowledge and language development expertise. Few people have both. Not surprisingly, the decision to develop a DSL is often postponed indefinitely, if considered at all, and most DSLs never get beyond the application library stage. Although many articles have been written on the development of particular DSLs, there is very limited literature on DSL development methodologies and many questions remain regarding when and how to develop a DSL. To aid the DSL developer, this survey paper identifies patterns in the decision, analysis, design, and implementation phases of DSL development. These patterns improve and extend earlier work on DSL design patterns. Design Guidelines for Domain Specific Languages - OOPSLA Workshop on Domain-Specific Modeling (DSM' 09), 2009. [All Versions]. Designing a new domain specific language is as any other complex task sometimes error-prone and usually time consuming, especially if the language shall be of high-quality and comfortably usable. Existing tool support focuses on the simplification of technical aspects but lacks support for an enforcement of principles for a good language design. In this paper we investigate guidelines that are useful for designing domain specific languages, largely based on our experience in developing languages as well as relying on existing guidelines on general purpose (GPLs) and modeling languages. This work defined Guidelines to support a DSL developer to achieve better quality of the language design and a better acceptance among its users. Domain-specific languages: an annotated bibliography - ACM SIGPLAN Notices, 2000. [All Versions]. A survey on the topic of domain-specific languages as used for the construction and maintenance of software systems. The survey lists a selection of 75 key publications in the area, and provides a summary for each of the papers. Moreover, the survey discusses terminology, risks and benefits, example domain-specific languages, design methodologies, and implementation techniques. Usability Evaluation of Domain-Specific Languages - ICQICT'12, 2012. [All Versions]. [Preprint]. The purpose of this proposal is to contribute to the systematic activity of Software Language Engineering by focusing on the issue of the Usability evaluation of DSLs. Usability evaluation is often skipped, relaxed, or at least omitted from papers reporting development of DSLs. The authors argue that a systematic approach based on User Interface experimental validation techniques should be used to assess the impact of new DSLs. For that purpose, the authors propose to merge common Usability evaluation processes with the DSL development process. Domain-Specific Modeling Languages: Requirements Analysis and Design Guidelines - Domain Engineering: Product Lines, Languages, and Conceptual Models, 2013. [All Versions]. In recent years, the development of domain-specific modeling languages has gained remarkable attention. This is for good reasons. A domain-specific modeling language incorporates concepts that represent domain-level knowledge. Hence, systems analysts are not forced to reconstruct these concepts from scratch. At the same time, domain-specific modeling languages contribute to model integrity, because they include already constraints that would otherwise have to be added manually. Even though there has been a considerable amount of research on developing and using domain-specific modeling languages, there is still lack of comprehensive methods to guide the design of these languages. With respect to the complexity and risk related to developing a domain-specific modeling language, this is a serious shortfall. This chapter is aimed at a contribution to filling the gap. At first, it presents guidelines for selecting a metamodeling language. Its main focus is on supporting the process from analyzing requirements to specifying and evaluating a domain-specific modeling language. *Back to Top Design Practises No Grammar to Rule Them All: A Survey of JSON-style DSLs for Visualization - IEEE Transactions on Visualization and Computer Graphics, 2022. [All Versions]. There has been substantial growth in the use of JSON-based grammars, as well as other standard data serialization languages, to create visualizations. Each of these grammars serves a purpose: some focus on particular computational tasks (such as animation), some are concerned with certain chart types (such as maps), and some target specific data domains (such as ML). Despite the prominence of this interface form, there has been little detailed analysis of the characteristics of these languages. This study surveys and analyzes the design and implementation of 57 JSON-style DSLs for visualization. The authors analyze these languages supported by a collected corpus of examples for each DSL (consisting of 4395 instances) across a variety of axes organized into concerns related to domain, conceptual model, language relationships, affordances, and general practicalities. The authors identify tensions throughout these areas, such as between formal and colloquial specifications, among types of users, and within the composition of languages. Through this work, the authors seek to support language implementers by elucidating the choices, opportunities, and tradeoffs in visualization DSL design. Quantifying usability of domain-specific languages: An empirical study on software maintenance - Journal of Systems and Software, 2015. [All Versions]. A DSL aims to support software development by offering abstractions to a particular domain. It is expected that DSLs improve the maintainability of artifacts otherwise produced with general-purpose languages. However, the maintainability of the DSL artifacts and, hence, their adoption in mainstream development, is largely dependent on the usability of the language itself. Unfortunately, it is often hard to identify their usability strengths and weaknesses early, as there is no guidance on how to objectively reveal them. Usability is a multi-faceted quality characteristic, which is challenging to quantify beforehand by DSL stakeholders. There is even less support on how to quantitatively evaluate the usability of DSLs used in maintenance tasks. In this context, this paper reports a study to compare the usability of textual DSLs under the perspective of software maintenance. A usability measurement framework was developed based on the cognitive dimensions of notations. The framework was evaluated both qualitatively and quantitatively using two DSLs in the context of two evolving object-oriented systems. The results suggested that the proposed metrics were useful: (1) to early identify DSL usability limitations, (2) to reveal specific DSL features favoring maintenance tasks, and (3) to successfully analyze eight critical DSL usability dimensions. How Domain Experts Use an Embedded DSL - OOPSLA'23, 2023. [All Versions]. Programming tools are increasingly integral to research and analysis in myriad domains, including specialized areas with no formal relation to computer science. Embedded domain-specific languages (eDSLs) have the potential to serve these programmers while placing relatively light implementation burdens on language designers. However, barriers to eDSL use reduce their practical value and adoption. This work aims to deepen the understanding of how programmers use eDSLs and identify user needs to inform future eDSL designs. The authors performed a contextual inquiry (9 participants) with domain experts using Mimi, an eDSL for climate change economics modeling. A thematic analysis identified five key themes, including: the interaction between the eDSL and the host language has significant and sometimes unexpected impacts on eDSL user experience, and users preferentially engage with domain-specific communities and code templates rather than host language resources. Abstract Hardware Grounding Towards the Automated Design of Automation Systems - ICIRA'24, 2024. [All Versions]. Crafting automation systems tailored for specific domains requires aligning the space of human experts’ semantics with the space of robot executable actions, and scheduling the required resources and system layout accordingly. Regrettably, there are three major gaps, fine-grained domain-specific knowledge injection, heterogeneity between human knowledge and robot instructions, and diversity of users’ preferences, resulting automation system design a case-by-case and labour-intensive effort, thus hindering the democratization of automation. This work refers to this challenging alignment as the abstract hardware grounding problem, where the authors firstly regard the procedural operations in humans’ semantics space as the abstraction of hardware requirements, then the authors ground such abstractions to instantiated hardware devices, subject to constraints and preferences in the real world—optimizing this problem is essentially standardizing and automating the design of automation systems. On this basis, this work develops an automated design framework in a hybrid data-driven and principle-derived fashion. Results on designing self-driving laboratories for enhancing experiment-driven scientific discovery suggest the proposed framework’s potential to produce compact systems that fully satisfy domain-specific and user-customized requirements with no redundancy. Constraint Representation Towards Precise Data-Driven Storytelling - VIS-Gen4DS'24, 2024. [All Versions]. A position paper on DSL for data-driven storytelling. Data-driven storytelling serves as a crucial bridge for communicating ideas in a persuasive way. However, the manual creation of data stories is a multifaceted, labor-intensive, and case-specific effort, limiting their broader application. As a result, automating the creation of data stories has emerged as a significant research thrust. Despite advances in Artificial Intelligence, the systematic generation of data stories remains challenging due to their hybrid nature: they must frame a perspective based on a seed idea in a top-down manner, similar to traditional storytelling, while coherently grounding insights of given evidence in a bottom-up fashion, akin to data analysis. These dual requirements necessitate precise constraints on the permissible space of a data story. This viewpoint proposes integrating constraints into the data story generation process. Defined upon the hierarchies of interpretation and articulation, constraints shape both narrations and illustrations to align with seed ideas and contextualized evidence. The authors identify the taxonomy and required functionalities of these constraints. Although constraints can be heterogeneous and latent, this position paper explores the potential to represent them in a computation-friendly fashion via Domain-Specific Languages. The authors believe that leveraging constraints will facilitate both artistic and scientific aspects of data story generation. *Back to Top Design Automation AutoDSL: Automated domain-specific language design for structural representation of procedures with constraints - ACL'24, 2024. [All Versions]. [Preprint]. [Project]. The original paper on the automated design of DSLs, referred to as AutoDSL. Accurate representation of procedures in restricted scenarios, such as non-standardized scientific experiments, requires precise depiction of constraints. Unfortunately, Domain-Specific Language (DSL), as an effective tool to express constraints structurally, often requires case-by-case hand-crafting, necessitating customized, labor-intensive efforts. To overcome this challenge, this paper introduces the AutoDSL framework to automate DSL-based constraint design across various domains. Utilizing domain specified experimental protocol corpora, AutoDSL optimizes syntactic constraints and abstracts semantic constraints. Quantitative and qualitative analyses of the DSLs designed by AutoDSL across five distinct domains highlight its potential as an auxiliary module for language models, aiming to improve procedural planning and execution. *Back to Top Imperative DSL Applications Biocoder: A programming language for standardizing and automating biology protocols - Journal of Biological Engineering, 2010. [All Versions]. [Project]. [Microsoft Page] This paper introduces BioCoder, a C++ library that enables biologists to express the exact steps needed to execute a protocol. In addition to being suitable for automation, BioCoder converts the code into a readable, English-language description for use by biologists. Universal chemical programming language for robotic synthesis repeatability - Nature Synthesis, 2024. [All Versions]. [Preprint]. This paper presents an approach that uses a universal chemical programming language (χDL) to encode and execute synthesis procedures for a variety of chemical reactions, including reductive amination, ring formation, esterification, carbon–carbon bond formation and amide coupling on four different hardware systems in two laboratories. With around 50 lines of code per reaction, the approach uses abstraction to efficiently compress chemical protocols. Building an Open Representation for Biological Protocols - ACM Journal on Emerging Technologies in Computing Systems, 2023. [All Versions]. There is currently no available protocol representation that is unambiguous enough for precise interpretation and automation, yet simultaneously “human friendly” and abstract enough to enable reuse and adaptation. The Laboratory Open Protocol language (LabOP) is a free and open protocol representation aiming to address this gap, building on a foundation of UML, Autoprotocol, Aquarium, SBOL RDF, and the Provenance Ontology. LabOP provides a linked-data representation both for protocols and for records of their execution and the resulting data, as well as a framework for exporting from LabOP for execution by either humans or laboratory automation. KnitScript: A Domain-Specific Scripting Language for Advanced Machine Knitting - UIST'23, 2023. [All Versions]. [Project]. This paper presents KnitScript, a domain-specific machine knitting scripting language that supports computationally driven knitting designs. KnitScript provides a comprehensive virtual model of knitting machines, giving access to machine-level capabilities as they are needed while automating a variety of tedious and error-prone details. A domain‑specifc language framework for farm management information systems in precision agriculture - Precision Agriculture, 2020. [All Versions]. This paper proposes a domain-specific language framework for the design and development of precision-agriculture FMISs, which copes with challenges on supporting the understandability, enhancing communication and analysis of the design decisions, and the communication among stakeholders. Infinite Photorealistic Worlds Using Procedural Generation - CVPR'23, 2023. [All Versions]. [Website]. [Supplementary Text]. This paper introduces Infinigen, a procedural generator of photorealistic 3D scenes of the natural world. Infinigen is entirely procedural: every asset, from shape to texture, is generated from scratch via randomized mathematical rules, using no external source and allowing infinite variation and composition. Corel: A DSL for Cooking Recipes - 2021. [All Versions]. [Corel recipe page]. [International Network of Food Data Systems (INFOODS)]. The Corel DSL for cooking recipes enables understanding of and computation with ingredients, and can construct a nutrition label for the recipe. *Back to Top Declarative DSL Applications The BioPAX community standard for pathway data sharing - Nature Biotechnology, 2010. [All Versions]. [Preprint]. Biological Pathway Exchange (BioPAX) is a standard language to represent biological pathways at the molecular and cellular level and to facilitate the exchange of pathway data. BioPAX can represent metabolic and signaling pathways, molecular and genetic interactions and gene regulation networks. Learning the language of viral evolution and escape - Science, 2021. [All Versions]. Natural language processing with two components: grammar (or syntax) and meaning (or semantics) for predicting which viral mutations may lead to viral escape. A high-level programming language for generative protein design - 2022. [All Versions]. A high-level programming language based on modular building blocks that allows a designer to easily compose a set of desired properties. Along with the programming language, there is an energy-based generative model, built on atomic resolution structure prediction with a language model, that realizes all-atom structure designs that have the programmed properties. OpenLaw - OpenLaw.io. It is now possible to model all or parts of legal agreements using code (smart contracts), decreasing the cost and friction of creating, securing, and generating binding legal agreements. Lawyers lack basic tools to build these dynamic, “smart” contracts in a way that is enforceable and understandable to a legal professional. OpenLaw is a technology stack to help power next generation "smart" legal agreements, with a domain-specific markup language, a integration framework, and a series of general applications. Scenic: a language for scenario specification and data generation - Machine Learning, 2022. [All Versions]. This paper proposes a domain-specific language, Scenic, for describing scenarios that are distributions over scenes and the behaviors of their agents over time. Scenic combines concise, readable syntax for spatiotemporal relationships with the ability to declaratively impose hard and soft constraints over the scenario. Domain Specific Language for Smart Contract Development - ICBC'20, 2020. [All Versions]. [Preprint]. This research addresses the understanding hardness raised from the conceptual discrepancy between contractual clauses and corresponding code of the Solidity programming language, by the design and study of a domain-specific smart contract language based on higher level of abstraction that can be automatically transformed to an implementation. iContractML 2.0: A domain-specific language for modeling and deploying smart contracts onto multiple blockchain platforms - Information and Software Technology, 2022. [All Versions]. Smart contracts play a vital role in many fields. Despite being called smart, the development of smart contracts is a tedious task beyond defining a set of contractual rules. In addition to business knowledge, coding a smart contract requires strong technical knowledge in a multiplex of new and rapidly changing domain-specific languages and blockchain platforms. The goal of this paper is to assist developers in building smart contracts independently from the language or the target blockchain platform. In which, this paper presents the second-generation smart contract language iContractML 2.0. iContractML 2.0 is an extensible framework that empowers developers to model and generate functional smart contract code that can be deployed onto multiple blockchain platforms. PClean: Bayesian Data Cleaning at Scale with Domain-Specific Probabilistic Programming - ICML'21, 2021. [All Versions]. This work presents PClean, a probabilistic programming language (PPL) for leveraging dataset-specific knowledge to automate Bayesian cleaning, automating Bayesian approaches given the diversity of real-world error patterns and the hardness of inference. A Language for Counterfactual Generative Models - ICML'21, 2021. [All Versions]. [Project]. This paper presents Omega, a probabilistic programming language with support for counterfactual inference. This feature is accomplished by introducing a new operator to probabilistic programming akin to Pearl’s do. Product Line Engineering Using Domain-Specific Languages - ISPLC'11, 2011. [All Versions]. [Preprint]. This paper investigates the application of domain-specific languages in product line engineering (PLE). It starts by analyzing the limits of expressivity of feature models. Feature models correspond to context-free grammars without recursion, which prevents the expression of multiple instances and references. The authors then show how domain-specific languages (DSLs) can serve as a middle ground between feature modeling and programming. They can be used in cases where feature models are too limited, while keeping the separation between problem space and solution space provided by feature models. This work then categorizes useful combinations between configuration with feature model and construction with DSLs and provide an integration of DSLs into the conceptual framework of PLE. Finally the authors show how use of a consistent, unified formalism for models, code, and configuration can yield important benefits for managing variability and trace ability. A Domain-Specific Language for Product-Process-Resource Modeling - ETFA'21, 2021. [All Versions]. This paper presents the design of the PPR-DSL to effectively and efficiently represent Product-Process-Resource (PPR) aspects and evaluate constraints defined for modeling PPR views in the Formalized Process Description standard (VDI 3682). The Scene Language: Representing Scenes with Programs, Words, and Embeddings - 2024. [All Versions]. [Project]. This paper introduces the Scene Language, a visual scene representation that concisely and precisely describes the structure, semantics, and identity of visual scenes. It represents a scene with three key components: a program that specifies the hierarchical and relational structure of entities in the scene, words in natural language that summarize the semantic class of each entity, and embeddings that capture the visual identity of each entity. This representation can be inferred from pre-trained language models via a training-free inference technique, given text or image inputs. *Back to Top Logic DSL Applications Situation Calculus - Wikipedia. Wikipedia on Situation Calculus, a logic formalism designed for representing and reasoning about dynamical domains. What is Answer Set Programming? - Springer, 2008. [All Versions]. [Tutorial on AAAI]. Answer set programming (ASP) is a form of declarative programming oriented towards difficult search problems. As an outgrowth of research on the use of nonmonotonic reasoning in knowledge representation, it is particularly useful in knowledge-intensive applications. ASP programs consist of rules that look like Prolog rules, but the computational mechanisms used in ASP are different: they are based on the ideas that have led to the creation of fast satisfiability solvers for propositional logic. Answer Set Programming - ICLPNR'99, 1999. [All Versions]. [Preprint]. The original paper on Answer Set Programming (ASP), a form of declarative programming oriented towards difficult search problems, on the use of nonmonotonic reasoning in knowledge representation. In ASP solutions to a problem are represented by answer sets (known also as stable models), and not by answer substitutions produced in response to a query, as in conventional logic programming. Action Languages, Answer Sets, and Planning - The Logic Programming Paradigms, 1999. [All Versions]. [Preprint]. This is a discussion of some of the achievements and challenges related to representing actions and the design of planners from the perspective of logic programming. The authors talk about recent work on action languages and translating them into logic programming, on representing possible histories of an action domain by answer sets, on efficient implementations of the answer set semantics and their use for generating plans, and on causal logic and its relation to planning algorithms. Recent progress in these areas may lead to the creation of planners which are based on the ideas of logic programming and combine the use of expressive action description languages with efficient computational procedures. Qualitative Simulation - Artificial Intelligence, 1986. [All Versions]. [Preprint]. This paper presents a precise definition of qualitative structure and behavior descriptions as abstractions of differential equations and continuously differentiable functions. The authors present a new algorithm for qualitative simulation that generalizes the best features of existing algorithms, and allows direct comparisons among alternate approaches. Starting with a set of constraints abstracted from a differential equation, this work proves that the QSIM algorithm is guaranteed to produce a qualitative behavior corresponding to any solution to the original equation. The paper also shows that any qualitative simulation algorithm will sometimes produce spurious qualitative behaviors: ones which do not correspond to any mechanism satisfying the given constraints. These observations suggest specific types of care that must be taken in designing applications of qualitative causal reasoning systems, and in constructing and validating a knowledge base of mechanism descriptions. Qualitative Reasoning: Modeling and Simulation with Incomplete Knowledge - MIT Press, 1994. [All Versions]. This book presents, within a conceptually unified theoretical framework, a body of methods that have been developed over the past fifteen years for building and simulating qualitative models of physical systems - bathtubs, tea kettles, automobiles, the physiology of the body, chemical processing plants, control systems, electrical systems - where knowledge of that system is incomplete. The primary tool for this work is the author's QSIM algorithm, which is discussed in detail. Qualitative models are better able than traditional models to express states of incomplete knowledge about continuous mechanisms. Qualitative simulation guarantees to find all possible behaviors consistent with the knowledge in the model. This expressive power and coverage is important in problem solving for diagnosis, design, monitoring, explanation, and other applications of artificial intelligence. Qualitative and quantitative simulation: bridging the gap - Artificial Intelligence, 1997. [All Versions]. Shortcomings of qualitative simulation and of quantitative simulation motivate combining them to do simulations exhibiting strengths of both. The resulting class of techniques is called semiquantitative simulation. One approach to semi-quantitative simulation is to use numeric intervals to represent incomplete quantitative information. This research demonstrates semi-quantitative simulation using intervals in an implemented semi-quantitative simulator called Q3. Q3 progressively refines a qualitative simulation, providing increasingly specific quantitative predictions which can converge to a numerical simulation in the limit while retaining important correctness guarantees from qualitative and interval simulation techniques. A Logic Programming Language for Computational Nucleic Acid Devices - ACS Synthetic Biology, 2018. [All Versions]. This paper presents a logic programming language that allows a broad range of computational nucleic acid systems to be designed and analyzed. The language extends standard logic programming with a novel equational theory to express nucleic acid molecular motifs. It automatically identifies matching motifs present in the full system, in order to apply a specified transformation expressed as a logical rule. *Back to Top DSL Program Synthesis pix2code: Generating Code from a Graphical User Interface Screenshot - ACM SIGCHI Symposium on Engineering Interactive Computing Systems, 2018. [All Versions]. [Code]. [Website]. This paper shows that deep learning methods can be leveraged to train a model end-to-end to automatically reverse engineer user interfaces and generate code from a single input image with over 77% of accuracy for three different platforms (i.e. iOS, Android and web-based technologies). Learning to Infer Graphics Programs from Hand-Drawn Images - NeurIPS'18, 2018. [All Versions]. The method learns a model that uses program synthesis techniques to recover a graphics program from drawing primitives. These programs have constructs like variable bindings, iterative loops, or simple kinds of conditionals. With a graphics program in hand, we can correct errors made by the deep network and extrapolate drawings. babble: Learning Better Abstractions with E-Graphs and Anti-unification - POPL'23, 2023. [All Versions]. This paper proposes library learning modulo theory (LLMT), a new library learning algorithm that additionally takes as input an equational theory for a given problem domain. LLMT uses e-graphs and equality saturation to compactly represent the space of programs equivalent modulo the theory, and uses a novel e-graph anti-unification technique to find common patterns in the corpus more directly and efficiently. Top-Down Synthesis for Library Learning - POPL'23, 2023. [All Versions]. This paper introduces corpus-guided top-down synthesis as a mechanism for synthesizing library functions that capture common functionality from a corpus of programs in a domain specific language (DSL). The algorithm builds abstractions directly from initial DSL primitives, using syntactic pattern matching of intermediate abstractions to intelligently prune the search space and guide the algorithm towards abstractions that maximally capture shared structures in the corpus. DreamCoder: growing generalizable, interpretable knowledge with wake–sleep Bayesian program learning - Philosophical Transactions of the Royal Society A, 2023. [All Versions]. [Preprint]. This paper presents DreamCoder, a system that learns to solve problems by writing programs. It builds expertise by creating domain-specific programming languages for expressing domain concepts, together with neural networks to guide the search for programs within these languages. A ‘wake–sleep’ learning algorithm alternately extends the language with new symbolic abstractions and trains the neural network on imagined and replayed problems. DreamCoder solves both classic inductive programming tasks and creative tasks such as drawing pictures and building scenes. Grammar Prompting for Domain-Specific Language Generation with Large Language Models - NeurIPS'23, 2023. [All Versions]. Grammar prompting is a simple approach to enable LLMs to use external knowledge and domain-specific constraints expressed through a grammar in Backus--Naur Form (BNF) during in-context learning. Grammar prompting augments each demonstration example with a specialized grammar that is minimally sufficient for generating the particular output example, where the specialized grammar is a subset of the full DSL grammar. For inference, the LLM first predicts a BNF grammar given a test input, and then generates the output according to the rules of the grammar. Experiments demonstrate that grammar prompting can enable LLMs to perform competitively on a diverse set of DSL generation tasks, including semantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and SMILES-based molecule generation. Errors are Useful Prompts: Instruction Guided Task Programming with Verifier-Assisted Iterative Prompting - 2023. [All Versions]. [Project]. [Website]. This paper proposes CLAIRIFY, an approach that combines automatic iterative prompting with program verification to ensure programs written in data-scarce domain-specific language are syntactically valid and incorporate environment constraints. PhotoScout: Synthesis-Powered Multi-Modal Image Search - ACM SIGCHI'24, 2024. [All Versions]. This paper explores a new multi-modal image search approach that allows users to conveniently specify and perform semantic image search tasks. With the tool, PhotoScout, the user interactively provides natural language descriptions, positive and negative examples, and object tags to specify their search tasks. Under the hood, PhotoScout is powered by a program synthesis engine that generates visual queries in a domain-specific language and executes the synthesized program to retrieve the desired images. Expert-level protocol translation for self-driving labs - NeurIPS'24, 2024. [All Versions]. [Project]. Recent development in Artificial Intelligence (AI) models has propelled their application in scientific discovery, but the validation and exploration of these discoveries require subsequent empirical experimentation. The concept of self-driving laboratories promises to automate and thus boost the experimental process following AI-driven discoveries. However, the transition of experimental protocols, originally crafted for human comprehension, into formats interpretable by machines presents significant challenges, which, within the context of specific expert domain, encompass the necessity for structured as opposed to natural language, the imperative for explicit rather than tacit knowledge, and the preservation of causality and consistency throughout protocol steps. Presently, the task of protocol translation predominantly requires the manual and labor-intensive involvement of domain experts and information technology specialists, rendering the process time-intensive. To address these issues, this work proposes a framework that automates the protocol translation process through a three-stage workflow, which incrementally constructs Protocol Dependence Graphs (PDGs) that approach structured on the syntax level, completed on the semantics level, and linked on the execution level. Quantitative and qualitative evaluations have demonstrated its performance at par with that of human experts, underscoring its potential to significantly expedite and democratize the process of scientific discovery by elevating the automation capabilities within self-driving laboratories. *Back to Top Cognitive Foundations The Child as Hacker - Trends in Cognitive Sciences, 2020. [All Versions]. The scope of human learning and development poses a radical challenge for cognitive science. The authors propose that developmental theories can address this challenge by adopting perspectives from computer science. Many of our best models treat learning as analogous to computer programming because symbolic programs provide the most compelling account of sophisticated mental representations. The authors specifically propose that children’s learning is analogous to a particular style of programming called hacking, making code better along many dimensions through an open-ended set of goals and activities. By contrast to existing theories, which depend primarily on local search and simple metrics, this view highlights the many features of good mental representations and the multiple complementary processes children use to create them. Communicating Natural Programs to Humans and Machines - NeurIPS'22, 2022. [All Versions]. While humans readily generate and interpret instructions in a general language, computer systems are shackled to a narrow domain-specific language that they can precisely execute. This makes building intelligent systems that can generalize to novel situations such as ARC difficult. Human-generated instructions are referred as “natural programs”. While they resemble computer programs, they are distinct in two ways: First, they contain a wide range of primitives; Second, they frequently leverage communicative strategies beyond directly executable codes. Symbolic metaprogram search improves learning efficiency and explains rule learning in humans - Nature Communications, 2024. [All Versions]. Symbolic models based on program learning successfully explain rule-learning in many domains, but performance degrades quickly as program complexity increases. It remains unclear how to scale symbolic rule-learning methods to model human performance in challenging domains. This work shows that symbolic search over the space of metaprograms—programs that revise programs—dramatically improves learning efficiency. On a behavioral benchmark of 100 algorithmically rich rules, this approach fits human learning more accurately than alternative models while also using orders of magnitude less search. The computation required to match median human performance is consistent with conservative estimates of human thinking time. The results suggest that metaprogram-like representations may help human learners to efficiently acquire rules. *Back to Top Problem Solving Human-Level Problem Solving Elements of a theory of human problem solving - Psychological Review, 1958. [All Versions]. Herbert Simon's original idea on human problem solving. Human Problem Solving - Englewood Cliffs, NJ: Prentice-hall, 1972. [All Versions]. Herbert Simon's classic idea of human problem solving as search. Learning to Solve Problems: A Handbook for Designing Problem-Solving Learning Environments - Taylorfrancis, 2010. [All Versions]. Judgment under Uncertainty: Heuristics and Biases: Biases in judgments reveal some heuristics of thinking under uncertainty - Science, 1974. [All Versions]. Daniel Kahneman's classic idea of prospective theory. Computational evidence for hierarchically structured reinforcement learning in humans - Proceedings of the National Academy of Sciences, 2020. [All Versions]. A piece of evidence on hierarchical human planning. Hierarchical reasoning by neural circuits in the frontal cortex - Science, 2019. [All Versions]. Neuroscience evidence supporting rule switch. The importance of mixed selectivity in complex cognitive tasks - Nature, 2013. [All Versions]. The original paper introducing mixed selectivity with high-dimensional neural representations. People construct simplified mental representations to plan - Nature, 2022. [All Versions]. A computational account on rational problem representation in human planning. Goals, usefulness and abstraction in value-based choice - Trends in Cognitive Sciences, 2023. [All Versions]. A review that outlines the computational and biological principles that enable the brain to compute the usefulness of an option or action by creating abstractions that flexibly adapt to changing goals. Value signals guide abstraction during learning - eLife, 2022. [All Versions]. Learning to perceive and act by trial and error - Machine Learning, 1991. [All Versions]. Representations in distributed cognitive tasks - Cognitive Science, 1994. [All Versions]. The nature of external representations in problem solving - Cognitive Science, 1997. [All Versions]. Rapid trail-and-error learning with simulation supports flexible tool use and physical reasoning. - Proceedings of the National Academy of Sciences, 2020. [All Versions]. [Project]. [Appendix]. A computational account on rapid trail-and-error problem solving with a noisy prior model. Abstract strategy learning underlies flexible transfer in physical problem solving - CogSci'20, 2020. [All Versions]. Physion: Evaluating Physical Prediction from Vision in Humans and Machines - NeurIPS'21, 2021. [All Versions]. Exploration: from machines to humans - Current Opinion in Behavioral Sciences, 2020. [All Versions]. Balancing exploration and exploitation with information and randomization - Current Opinion in Behavioral Sciences, 2021. [All Versions]. Hippocampal neurons construct a map of an abstract value space - Cell, 2021. [All Versions]. Insightful problem solving and creative tool modification by captive nontool-using rooks - Proceedings of the National Academy of Sciences, 2009. [All Versions]. [Supplementary Material]. A piece of evidence on creative tool use in intelligent animals. Learning to act by integrating mental simulations and physical experiments - CogSci'18, 2018. [All Versions]. [Code]. The successor representation in human reinforcement learning - Nature Human Behavior, 2017. [All Versions]. *Back to Top Planning From Skills to Symbols: Learning Symbolic Representations for Abstract High-Level Planning - Journal of Artificial Intelligence Research, 2018. [All Versions]. Leslie Kaelbling's review on hierarchical Task-and-Motion-Planning (hierarchical TAMP). Integrated Task and Motion Planning - Annual Review of Control, Robotics, and Autonomous Systems, 2021. [All Versions]. Leslie Kaelbling's review on Task-and-Motion-Planning (TAMP). Differentiable Physics and Stable Modes for Tool-Use and Manipulation Planning - Robotics: Science and Systems, 2018. [All Versions]. Learning to act by integrating mental simulations and physical experiments - CogSci'21, 2018. [All Versions]. What Is the Model in Model-Based Planning? - Cognitive Science, 2021. [All Versions]. Discovering State and Action Abstractions for Generalized Task and Motion Planning - AAAI'22, 2022. [All Versions]. *Back to Top Intrinsic Motivation Intrinsically Motivated Reinforcement Learning - NeurIPS'04, 2004. [All Versions]. A comprehensive review on intrinsic reward functions in classic reinforcement learning. What is intrinsic motivation? A typology of computational approaches - Frontiers in Neurorobotics, 2009. [All Versions]. Adapting Behavior via Intrinsic Reward: A Survey and Empirical Study - Journal of Artificial Intelligence Research, 2020. [All Versions]. Curiosity-driven Exploration by Self-supervised Prediction - ICML'17, 2017. [All Versions]. The original paper on curiosity as intrinsic motivation. UCB Exploration via Q-Ensembles - 2017. [All Versions]. Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning - ICML'21, 2021. [All Versions]. Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning - NeurIPS'15, 2015. [All Versions]. The original paper on empowerment as intrinsic motivation. Intrinsic Exploration as Empowerment in a Richly Structured Online Game - 2022. [All Versions]. Multi-task reinforcement learning in humans - Nature Human Behavior, 2021. [All Versions]. JARVIS-1: Open-World Multi-Task Agents With Memory-Augmented Multimodal Language Models - IEEE Transactions on Pattern Analysis and Machine Intelligence. [All Versions]. Achieving human-like planning and control with multimodal observations in an open world is a key milestone for more functional generalist agents. Existing approaches can handle certain long-horizon tasks in an open world. However, they still struggle when the number of open-world tasks could potentially be infinite and lack the capability to progressively enhance task completion as game time progresses. This work introduces JARVIS-1, an open-world agent that can perceive multimodal input (visual observations and human instructions), generate sophisticated plans, and perform embodied control, all within the popular yet challenging open-world Minecraft universe. Specifically, the authors develop JARVIS-1 on top of pre-trained multimodal language models, which map visual observations and textual instructions to plans. The plans will be ultimately dispatched to the goal-conditioned controllers. JARVIS-1 is outfitted with a multimodal memory, which facilitates planning using both pre-trained knowledge and its actual game survival experiences. JARVIS-1 is the existing most general agent in Minecraft, capable of completing over 200 different tasks using control and observation space similar to humans. *Back to Top Reinforcement Learning Reinforcement learning: An introduction - MIT Press, 2018. [All Versions]. Richard Sutton's comprehensive book on reinforcement learning. Reinforcement learning: A survey - Journal of Artificial Intelligence Research, 1996. [All Versions]. Leslie Kaelbling's review on reinforcement learning. An overview of multi-agent reinforcement learning from game theoretical perspective - 2020. [All Versions]. Yaodong Yang's review on multi-agent reinforcement learning from the perspective of game theory. Human-level control through deep reinforcement learning - Nature, 2015. [All Versions]. The original paper on solving Atari games via Deep Q-Network. Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning - Artificial Intelligence, 1999. [All Versions]. The original paper on operation reinforcement learning. On Monte Carlo Tree Search and Reinforcement Learning - Journal of Artificial Intelligence Research, 2017. [All Versions]. Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review - 2018. [All Versions]. [Slides]. Sergey Levine's tutorial on treating reinforcement learning probabilisticly. A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation - NeurIPS'19, 2019. [All Versions]. Solving Compositional Reinforcement Learning Problems via Task Reduction - ICLR'21, 2021. [All Versions]. Neural Task Programming: Learning to Generalize Across Hierarchical Tasks - ICRA'18, 2018. [All Versions]. Learning to act: qualitative learning of deterministic action models - Journal of Logic and Computation, 2017. [All Versions]. Learning to Act and Observe in Partially Observable Domains - 2021. [All Versions]. Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability - NeurIPS'21, 2021. [All Versions]. A formal treatment on the generalization problem in reinforcement learning. Learning to Perform Physics Experiments via Deep Reinforcement Learning - ICLR'17, 2017. [All Versions]. Data-Efficient Learning for Complex and Real-Time Physical Problem Solving Using Augmented Simulation - Robotics and Automation Letters, 2021. [All Versions]. A Survey of Preference-Based Reinforcement Learning Methods - Journal of Machine Learning Research, 2017. [All Versions]. On the Expressivity of Markov Reward - NeurIPS'21, 2021. [All Versions]. A formal treatment of tasks and rewards in reinforcement learning modeling. Trust Region Policy Optimization - ICML'15, 2015. [All Versions]. The original paper introducing TRPO, a method for optimizing control policies, with guaranteed monotonic improvement. Constrained Policy Optimization - ICML'17, 2017. [All Versions]. The original paper on constrained reinforcement learning (safe reinforcement learning). When to Trust Your Model: Model-Based Policy Optimization - NeurIPS'19, 2019. [All Versions]. [Post]. SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning - ICML'21, 2021. [All Versions]. [Code]. The Quest for a Common Model of the Intelligent Decision Maker - Multi-disciplinary Conference on Reinforcement Learning and Decision Making'22, 2022. [All Versions]. Richard Sutton's perspective on the future directions of reinforcement learning research. Automatic curriculum learning for deep RL: a short survey - IJCAI'20, 2020. [All Versions]. TeachMyAgent: a Benchmark for Automatic Curriculum Learning in Deep RL - ICML'21, 2021. [All Versions]. [Project]. *Back to Top Inverse Reinforcement Learning Apprenticeship Learning via Inverse Reinforcement Learning - ICML'04, 2004. [All Versions]. Pieter Abbeel and Andrew Ng's original paper on inverse reinforcement learning (IRL). Bayesian Inverse Reinforcement Learning - IJCAI'07, 2007. [All Versions]. A Bayesian account on classic inverse reinforcement learning. From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following - ICLR'19, 2019. [All Versions]. Few-shot Bayesian imitation learning with logical program policies. - AAAI'20, 2020. [All Versions]. Generalized Inverse Planning: Learning Lifted non-Markovian Utility for Generalizable Task Representation - 2020. [All Versions]. Inverse Constrained Reinforcement Learning - ICML'21, 2021. [All Versions]. *Back to Top System 1 & System 2 Dual-Coding Theory Mental Representations: A Dual Coding Approach - Oxford University Press, 1990. [All Versions]. The original book on dual coding theory, in the neuroscience account of mental representation. Dual coding of knowledge in the human brain - Trends in Cognitive Sciences, 2021. [All Versions]. Yanchao Bi's review on neuroscience experiments on dual coding theory. Two Forms of Knowledge Representations in the Human Brain - Neuron, 2020. [All Versions]. Illustrating language-derived and sensory-derived knowledge. Organizational Principles of Abstract Words in the Human Brain - Cerebral Cortex, 2018. [All Versions]. Different computational relations in language are captured by distinct brain systems - Cerebral Cortex, 2022. [All Versions]. The Deese-Roediger-McDermott (DRM) task: A simple cognitive paradigm to investigate false memories in the laboratory - Journal of Visualized Experiments, 2017. [All Versions]. A continuous semantic space describes the representation of thousands of object and action categories across the human brain - Neuron, 2012. [All Versions]. Rational arbitration between statistics and rules in human sequence processing - Nature Human Behavior, 2022. [All Versions]. *Back to Top Neural-Symbolic AI Regression Analysis for Interval-Valued Data - Data Analysis, Classification, and Related Methods, 2000. [All Versions]. The original paper on symbolic regression. Symbolic data analysis: what is it? - Proceedings in Computational Statistics, 2006. [All Versions]. DeepProbLog: Neural Probabilistic Logic Programming - NeurIPS'18, 2018. [All Versions]. The original paper on neuro-symbolic probabilistic programming. Learning Explanatory Rules from Noisy Data - Journal of Artificial Intelligence Research, 2018. [All Versions]. The original paper for differential Inductive Logic Programming. Combining Logical Abduction and Statistical Induction: Discovering Written Primitives with Human Knowledge - AAAI'17, 2017. [All Versions]. Neural Logic Reinforcement Learning - ICML'19, 2019. [All Versions]. Bridging Machine Learning and Logical Reasoning by Abductive Learning. - NeurIPS'19, 2019. [All Versions]. [Slides]. [Code]. The original paper on Abductive Learning, a derivative-free approach for neuro-symbolic learning. Abductive learning: towards bridging machine learning and logical reasoning - Science China Information Sciences, 2019. [All Versions]. Abductive Knowledge Induction From Raw Data - IJCAI'21, 2021. [All Versions]. Fast Abductive Learning by Similarity-based Consistency Optimization - NeurIPS'21, 2021. [All Versions]. An approach for accelerating the convergence of Abductive Learning. Learning by Abstraction: The Neural State Machine - NeurIPS'19, 2019. [All Versions]. Making sense of sensory input - Artificial Intelligence, 2021. [All Versions]. Abstract Spatial-Temporal Reasoning via Probabilistic Abduction and Execution - CVPR'21, 2021. [All Versions]. Learn to explain efﬁciently via neural logic inductive learning - ICLR'20, 2020. [All Versions]. [Project]. Closed Loop Neural-Symbolic Learning via Integrating Neural Perception, Grammar Parsing, and Symbolic Reasoning - ICML'20, 2020. [All Versions]. Generating new concepts with hybrid neuro-symbolic models. - CogSci'20, 2020. [All Versions]. Learning Task-General Representations with Generative Neuro-Symbolic Modeling - ICLR'21, 2021. [All Versions]. Hybrid computing using a neural network with dynamic external memory - Nature, 2016. [All Versions]. AI Feynman: A physics-inspired method for symbolic regression - Science Advances, 2019. [All Versions]. A general approach for neuro-symbolic formula synthesis. Classification-by-Components: Probabilistic Modeling of Reasoning over a Set of Components - NeurIPS'19, 2019. [All Versions]. Neuro-Symbolic Visual Reasoning: Disentangling “Visual” from “Reasoning” - ICML'20, 2020. [All Versions]. Understanding Deep Architectures with Reasoning Layer - NeurIPS'20, 2020. [All Versions]. An Explicitly Relational Neural Network Architecture - ICML'20, 2020. [All Versions]. Neural Production Systems - ICML'21, 2021. [All Versions]. Yoshua Bengio's perspective on slot attention model as a general production system. Compositional Generalization via Neural-Symbolic Stack Machines - NeurIPS'20, 2020. [All Versions]. Stochastic Optimization of Sorting Networks via Continuous Relaxations - ICLR'19, 2019. [All Versions]. Program Guided Agent - ICLR'20, 2020. [All Versions]. Learning Compositional Rules via Neural Program Synthesis - NeurIPS'20, 2020. [All Versions]. Discovering Symbolic Models from Deep Learning with Inductive Biases - NeurIPS'20, 2020. [All Versions]. Neural Logic Machines - ICLR'19, 2019. [All Versions]. The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision - ICLR'19, 2019. [All Versions]. Visual Concept-Metaconcept Learning - NeurIPS'19, 2019. [All Versions]. Grounding Physical Concepts of Objects and Events Through Dynamic Visual Reasoning - ICLR'21, 2021. [All Versions]. Temporal and Object Quantification Networks - IJCAI'21, 2021. [All Versions]. Grounded Language Learning Fast and Slow - ICLR'21, 2021. [All Versions]. [Project]. Detect, Understand, Act: A Neuro-symbolic Hierarchical Reinforcement Learning Framework - Machine Learning, 2022. [All Versions]. A neuro-symbolic framework that integrates meta-policy learning in inductive logic programming. Visual Programming: Compositional Visual Reasoning Without Training - CVPR'23, 2023. [All Versions]. VISPROG, a neuro-symbolic approach to solving complex and compositional visual tasks given natural language instructions, using the in-context learning ability of large language models to generate python-like modular programs, which are then executed to get both the solution and a comprehensive and interpretable rationale. *Back to Top Explainability Trustworthy AI Bayesian modeling of human–AI complementarity - Proceedings of the National Academy of Sciences, 2022. [All Versions]. A Bayesian framework for combining the predictions and different types of confidence scores from humans and machines. A tale of two explanations: Enhancing human trust by explaining robot behavior - Science Robotics, 2019. [All Versions]. The original paper on human believable robot, a result of the DAPAR-XAI. X-ToM: Explaining with Theory-of-Mind for Gaining Justified Human Trust - 2019. [All Versions]. Introducing the idea of AI estimating human users' knowledge in to explainable AI. CoCoX: Generating Conceptual and Counterfactual Explanations via Fault-Lines - AAAI'20, 2020. [All Versions]. CX-ToM: Counterfactual explanations with theory-of-mind for enhancing human trust in image recognition models - iScience, 2022. [All Versions]. *Back to Top Strong Machine Learning Ultra-Strong Machine Learning: comprehensibility of programs learned with ILP - Machine Learning, 2018. [All Versions]. Stephen Muggleton's account of ultra-strong machine learning, which not only learns human understandable knowledge, but also improves human performance on the corresponding tasks. Beneficial and harmful explanatory machine learning - Machine Learning, 2021. [All Versions]. Deep Forest: Towards An Alternative to Deep Neural Networks - IJCAI'17, 2017. [All Versions]. [Project]. NBDT: Neural-Backed Decision Trees - NeurIPS'20, 2020. [All Versions]. [Code]. Expliciting the decision process of a decision tree through neural networks. *Back to Top Explainable Deep Learning pytorch-grad-cam - 2021. Class Activation Map methods implemented in Pytorch, with many elegant features. Network dissection: Quantifying interpretability of deep visual representations - CVPR'17, 2017. [All Versions]. [Project]. [Dataset: Places365]. The original paper on visualizing the class activation maps to explain convolutional neural networks. Understanding the role of Individual Units in a Deep Neural Network - Proceedings of the National Academy of Sciences, 2020. [All Versions]. David Bau's review on network dissection for discriminative and generative models. Zoom In: An Introduction to Circuits - Distill, 2020. [All Versions]. A perspective on treating neural networks as circuits. Compositional Explanations of Neurons - NeurIPS'20, 2020. [All Versions]. [Project]. A concept-composition version of network dissection. This Looks Like That: Deep Learning for Interpretable Image Recognition - NeurIPS'19, 2019. [All Versions]. Unsupervised learning by competing hidden units - Proceedings of the National Academy of Sciences, 2019. [All Versions]. Noise or Signal: The Role of Backgrounds in Image Classification - ICLR'21, 2021. [All Versions]. [Code & Data]. [Project]. A perspective on image background provides strong clue for foreground classification. Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation - NeurIPS'18, 2018. [All Versions]. Maching the learned pattern of neurons in different neural networks. Individual differences among deep neural network models - Nature Communications, 2020. [All Versions]. *Back to Top Embodied Intelligence Embodied Cognition - Plato Stanford. A computational philosophy account on Embodied Cognition, which emphasizes the significance of an agent's physical body in cognitive abilities. Externalism About the Mind - Plato Stanford. A computational philosophy account on mind externalism, a long-term debate about the boundary of embodied intelligence. Cognitive engineering: Human problem solving with tools - Human Factors, 1988. [All Versions]. The original idea of investigating huamn tool use in problem solving. Tools, language and cognition in human evolution - Cambridge University Press, 1993. [All Versions]. A classic perspective correlating human tool use with the evolution of civilization. The Extended Mind - Analysis, 1998. [All Versions]. The original paper on the debate of mind externalism. The neural bases of complex tool use in humans - Trends in Cognitive Sciences, 2004. [All Versions]. A neuroscience account of human tool use. Spontaneous Metatool Use by New Caledonian Crows - Current Biology, 2007. [All Versions]. A piece of evidence that intelligent animals can take advantage of matatools to make tools for problem solving. Rapid Assimilation of External Objects Into the Body Schema - Psychological Science, 2010. [All Versions]. The cognitive bases of human tool use - Behavioral and Brain Sciences, 2012. [All Versions]. The embodied mind extended: using words as social tools - Frontiers in Psychology, 2013. [All Versions]. Tool use as adaptation - Philosophical Transactions of the Royal Society B: Biological Sciences, 2013. [All Versions]. Intensive tool-practice and skillfulness facilitate the extension of body representations in humans - Neuropsychologia, 2014. [All Versions]. Tool use and affordance: Manipulation-based versus reasoning-based approaches - Psychological Review, 2016. [All Versions]. A classic review on human tool use and affordance. Meta-strategy learning in physical problem-solving: the effect of embodied experience - CogSci'21, 2021. [All Versions]. Understanding Tools: Task-Oriented Object Modeling, Learning and Recognition - CVPR'15, 2015. [All Versions]. [Project]. The original paper introducing affordance and physically-grounded tool use into computer vision. Robotic hand augmentation drives changes in neural body representation - Science Robotics, 2021. [All Versions]. Expert Tool Users Show Increased Differentiation between Visual Representations of Hands and Tools - Journal of Neuroscience, 2021. [All Versions]. Visual scoping operations for physical assembly - CogSci'21, 2021. [All Versions]. Behavior-grounded representation of tool affordances - ICRA'05, 2005. [All Versions]. A Relational Approach to Tool-Use Learning in Robots - ILP'12, 2012. [All Versions]. Relational affordances for multiple-object manipulation - Autonomous Robots, 2017. [All Versions]. Improvisation through Physical Understanding: Using Novel Objects as Tools with Visual Foresight - RSS'19, 2019. [All Versions]. Meta-strategy learning in physical problem-solving: the effect of embodied experience - CogSci'21, 2021. [All Versions]. [Preprint]. This paper focuses on how natural embodied experience affects what kinds of abstract physical problem-solving strategies people use in a virtual task. The findings suggest that differences in embodied experience drive the acquisition of different meta-strategies for balancing acting with thinking, deciding what kinds of actions to try, and deciding how persistent to be with a current action plan. 3D dynamic scene graphs: Actionable spatial perception with places, objects, and humans - RSS'20, 2020. [All Versions]. A system for modeling 3D dynamic scene graphs on multiple levels (metric-semantic mesh, objects and agents, places and structures, rooms, and buildings). *Back to Top Evolutionary Intelligence Evolutionary trade-offs, Pareto optimality, and the geometry of phenotype space - Science, 2012. [All Versions]. A classic paper correlating biological trade-offs with the evolution of pareto optimality. Pareto optimality in multiobjective problems - Applied Mathematics and Optimization, 1977. [All Versions]. The original paper on the pareto optimality in multiobjective problems. Pareto-Based Multiobjective Machine Learning: An Overview and Case Studies - IEEE Transactions on Systems, Man, and Cybernetics, 2008. [All Versions]. A comprehensive review on the application of pareto optimality to multiobjective machine learning. Phylogenetic evidence for Sino-Tibetan origin in northern China in the Late Neolithic - Nature, 2019. [All Versions]. A Bayesian phylogenetic analysis on two competing hypotheses of the origin of the Sino-Tibetan language family suggests that the initial expansion of Sino-Tibetan languages occurred approximately 4,000–6,000 years before present (BP; taken as AD 1950) in the Yellow River basin of northern China, and that this expansion is associated with the development of the Yangshao and/or Majiayao Neolithic cultures. Triangulation supports agricultural spread of the Transeurasian languages - Nature, 2021. [All Versions]. [Nature News]. A triangulation of linguistic, archaeological and genetic data suggests that the Transeurasian language family originated in a population of grain farmers in China around 9,000 years ago, and that agriculture underpinned its spread. From language development to language evolution: A unified view of human lexical creativity - Science, 2023. [All Versions]. [Preprint]. This work supports a unified foundation for human lexical creativity underlying both the fleeting products of individual ontogeny and the evolutionary products of phylogeny across languages. *Back to Top Methodologies for Experiments Quantitative Analysis Identification of Causal Effects Using Instrumental Variables - Journal of the American Statistical Association, 1996. [All Versions]. The original paper on Instrumental Variables for natural sociology studies. Experiments with More Than One Random Factor: Designs, Analytic Models, and Statistical Power - Annual Review of Psychology, 2017. [All Versions]. A comprehensive review of the quantitative analysis techniques for behavioral studies. With or Without U? The Appropriate Test for a U-Shaped Relationship - Oxford Bulletin of Economics and Statistics, 2010. [All Versions]. The original method for testing U-shape relation from the data, which is distinctive from the quadratic regression test. Two lines: A valid alternative to the invalid testing of U-shaped relationships with quadratic regressions - Advances in Methods and Practices in Psychological Science, 2018. [All Versions]. An alternative method to test the statistical significance of U-shaped relationships. *Back to Top Scaling Up Behavioral Studies Scaling up experimental social, behavioral, and economic science - Open Science Foundation Preprints. [All Versions]. A white paper on scaling up social, behavioral, and econimic experiments. The weirdest people in the world? - Brain and Behavioral Sciences, 2010. [All Versions]. The original paper on rethinking and tackling the sample bias in behaivoral studies, where most subjects are drawn from Western, Educated, Industrialized, Rich, and Democratic (WEIRD) societies. Scaling up psychology via Scientific Regret Minimization - Proceedings of the National Academy of Sciences, 2020. [All Versions]. The statistical and ecological basis for scaling up behavioral studies. Machine-generated theories of human decision-making - Science, 2021. [All Versions]. Using large-scale experiments and machine learning to discover theories of human decision-making - Science, 2021. [All Versions]. A piece of evidence for the merits brought by large-scale behavioral studies in social science. Integrating explanation and prediction in computational social science - Nature, 2021. [All Versions]. Exploring human cognition using large image databases - Topics in Cognitive Sciences, 2016. [All Versions]. Visual Search at Pinterest - KDD'15, 2015. [All Versions]. Large scale user study in the development of the recommendations system by Pinterest. *Back to Top Decision Making A computational process-tracing method for measuring people’s planning strategies and how they change over time - Behavior Research Methods, 2022. [All Versions]. Model-based strategy identification. *Back to Top Question Answering Searching large hypothesis spaces by asking questions - CogSci'16, 2016. [All Versions]. A behavioral study for the 20 questions game. Asking and evaluating natural language questions - CogSci'16, 2016. [All Versions]. A behavioral study for the battleship game. Do People Ask Good Questions? - Computational Brain & Behavior, 2018. [All Versions]. Asking goal-oriented questions and learning from answers - CogSci'19, 2019. [All Versions]. *Back to Top Human-Machine Comparison Elimination by aspects: A theory of choice - Psychological Review, 1972. [All Versions]. Herbert Simon's early experiments on computer aided behavioral studies. Problem Solving and Rule Induction: A Unified View - Knowledge and cognition, 1974. [All Versions]. Evidence integration in model-based tree search - Proceedings of the National Academy of Sciences, 2015. [All Versions]. People Infer Recursive Visual Concepts from Just a Few Examples - Computational Brain & Behavior, 2020. [All Versions]. One-shot learning of generative speech concepts - CogSci'14, 2014. [All Versions]. Human few-shot learning of compositional instructions - CogSci'19, 2019. [All Versions]. Fast and flexible: Human program induction in abstract reasoning tasks - CogSci'21, 2021. [All Versions]. Investigating Human Priors for Playing Video Games - ICML'18, 2018. [All Versions]. Tasks for aligning human and machine planning - Current Opinion in Behavioral Sciences, 2019. [All Versions]. Humans can decipher adversarial images - Nature Communications. 2019. [All Versions]. Shared computational principles for language processing in humans and deep language models - Nature Neuroscience, 2022. [All Versions]. *Back to Top Association Test Implicit Association Test - Wikipedia. Wikipedia on the Implicit Association Test, a controversial assessment intended to detect subconscious associations between mental representations of objects (concepts) in memory. Measuring Individual Differences in Implicit Cognition: The Implicit Association Test - Journal of Personality and Social Psychology, 1998. [All Versions]. The original paper introducing the Implicit Association Test. Health of the Implicit Association Test at age 3 - Zeitschrift für Experimentelle Psychologie, 2001. [All Versions]. The 3rd year review for the IAT. The Implicit Association Test at Age 7: A Methodological and Conceptual Review - Social psychology and the unconscious: The automaticity of higher mental processes (pp. 265–292), Psychology Press, 2007. [All Versions]. The 7th year review for the IAT. A Meta-Analysis on the Correlation Between the Implicit Association Test and Explicit Self-Report Measures - Personality and Social Psychology Bulletin, 2005. [All Versions]. *Back to Top Virtual Reality Virtual reality in behavioral neuroscience and beyond - Nature Neuroscience, 2002. [All Versions]. A classic review on the early applications of Virtual Reality to behavioral studies. Virtual reality: A survival guide for the social scientist - Journal of Media Psychology, 2009. [All Versions]. The psychology of virtual reality - The psychology of technology: Social science research in the age of Big Data (pp. 155–193), American Psychological Association, 2022. [All Versions]. Jeremy Bailenson's review on the applications of Virtual Reality to behavioral studies. How Immersive Is Enough? A Meta-Analysis of the Effect of Immersive Technology on User Presence - Media Psychology, 2016. [All Versions]. A meta-analysis on the extent to which technologies need to be immersive in order to generate a sense of presence. Towards an Understanding of Distributed Asymmetric Collaborative Visualization on Problem-solving - VR'23, 2023. [All Versions]. Agent: automatic generation of experimental protocol runtime - VRST'17, 2017. [All Versions]. This paper proposes the use of Domain-Specific Languages (DSLs) to ease the description and generation of VR experiments, thus letting experiment designers focus on their core tasks: designing, conducting, and reporting experiments. What's the Game, then? Opportunities and Challenges for Runtime Behavior Generation - UIST'24, 2024. [All Versions]. Procedural content generation (PCG), the process of algorithmically creating game components instead of manually, has been a common tool of game development for decades. Recent advances in large language models (LLMs) enable the generation of game behaviors based on player input at runtime. Such code generation brings with it the possibility of entirely new gameplay interactions that may be difficult to integrate with typical game development workflows. This work explores these implications through GROMIT, a novel LLM-based runtime behavior generation system for Unity. When triggered by a player action, GROMIT generates a relevant behavior which is compiled without developer intervention and incorporated into the game. *Back to Top Meta-Level Considerations Meta Learning Automated Reinforcement Learning (AutoRL): A Survey and Open Problems - 2022. [All Versions]. A comprehensive review on AutoRL. Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks - ICML'17, 2017. [All Versions]. [Post]. Chelsea Finn's original paper on Model-Agnostic Meta-Learning (MAML). Bayesian Model-Agnostic Meta-Learning - NeurIPS'18, 2018. [All Versions]. A Bayesian account on MAML. Meta-Q-Learning - ICLR'20, 2020. [All Versions]. The milestone paper on context Meta-RL. Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables - ICML'19, 2019. [All Versions]. Balancing Constraints and Rewards with Meta-Gradient D4PG - ICLR'21, 2021. [All Versions]. Metacontrol for Adaptive Imagination-Based Optimization - ICLR'17, 2017. [All Versions]. On Effective Scheduling of Model-based Reinforcement Learning - NeurIPS'21, 2021. [All Versions]. *Back to Top Marr's Levels of Analysis Vision: A Computational Investigation into the Human Representation and Processing of Visual Information - MIT Press, 1982. [All Versions]. David Marr's original book on the levels of analysis. From understanding computation to understanding neural circuitry - Neuroscience Research Program Bulletin, 1979. [All Versions]. Bridging Levels of Analysis for Probabilistic Models of Cognition - Current Directions in Psychological Science, 2012. [All Versions]. A Marr's paradigm account on probabilistic models. Levels of Analysis in Computational Social Science - CogSci'18, 2018. [All Versions]. A Marr's paradigm account on computational social science. Levels of Analysis for Machine Learning - ICLR'20 Bridging AI and Cognitive Science Workshop, 2020. [All Versions]. A Marr's paradigm account on machine learning. *Back to Top Gestalt Gestalt theory - A source book of Gestalt psychology, 1938. [All Versions]. The original book on Gestalt psychology. Gestalt Psychology - Psychologische Forschung, 1967. [All Versions]. Wolfgang Köhler's review on Gestalt psychology. Restructuring revisited I. Summary and critique of the Gestalt theory of problem solving - Scandinavian Journal of Psychology, 1984. [All Versions]. Restructuring revisited II. An information processing theory of restructuring and insight - Scandinavian Journal of Psychology, 1984. [All Versions]. Thoughts beyond words: When language overshadows insight - Journal of Experimental Psychology, 1993. [All Versions]. Deep Learning: How the Mind Overrides Experience - Cambridge University Press, 2011. [All Versions]. *Back to Top The Aha! Moment Eureka Effect - Wikipedia. Wikipedia on Eureka effect (a.k.a. Aha! moment, insight, and epiphany), the common human experience of suddenly understanding a previously incomprehensible problem or concept. Insight - Wikipedia. Wikipedia on insight. Epiphany - Wikipedia. Wikipedia on epiphany, the "feeling" when the Aha! moment comes. A computational model of scientific insight - The nature of creativity: Contemporary psychological perspectives, 1988. [All Versions]. A computational account on insights for scientific discovery. What Makes an Insight Problem? The Roles of Heuristics, Goal Conception, and Solution Recoding in Knowledge-Lean Problems - Journal of Experimental Psychology, 2004. [All Versions]. [APA]. Constraint relaxation and chunk decomposition in insight problem solving - Journal of Experimental Psychology, 1999. [All Versions]. [APA]. Dynamics and constraints in insight problem solving - Journal of Experimental Psychology, 2002. [All Versions]. [APA]. Insight solutions are correct more often than analytic solutions - Thinking & Reasoning, 2016. [All Versions]. Human Performance on Insight Problem Solving: A Review - The Journal of Problem Solving, 2011. [All Versions]. Insight Is Not in the Problem: Investigating Insight in Problem Solving across Task Types - Frontiers in Psychology, 2016. [All Versions]. Multiple Causes of Difficulty in Insight: The Case of the Nine-Dot Problem - Journal of Experimental Psychology, 2004. [All Versions]. [APA]. Investigating the effect of Mental Set on Insight Problem Solving - Experimental Psychology, 2008. [All Versions]. *Back to Top Rationality Bounded Rationality - Plato Stanford. A computational philosophy account on Bounded Rationality, an elementary hypothesis of human intelligence in psychology and ecology. Instrumental Rationality - Plato Stanford. A computational philosophy account on Instrumental Rationality, a dabate on whether an agent's decision is made intentionally or out of rational coherence. A Study of Thinking - Routledge, 1956. [All Versions]. This book is a pioneering account of how human beings achieve a measure of rationality in spite of the constraints imposed by time and ignorance. The Adaptive Nature of Human Categorization Behavior - Psychological Review, 1991. [All Versions]. The original paper that relates cognitive resource limitation with Bayesian rational analysis, in the case of categorization behavior. Task switching - Trends in Cognitive Sciences, 2003. [All Versions]. [Preprint]. The original paper on ``switch cost'', where subjects' responses are substantially slower and, usually, more error-prone immediately after a task switch. Computational Rationality: Linking Mechanism and Behavior Through Bounded Utility Maximization - Topics in Cognitive Science, 2014. [All Versions]. Introducing the computational rationality framework for including information-processing bounds in rational analyses, which emphasizes the incorporation of computational mechanism into the definition of rational action. Computational rationality: A converging paradigm for intelligence in brains, minds, and machines - Science, 2015. [All Versions]. A comprehensive review on the rationality of Bayesian computational models. Resource-rational analysis: Understanding human cognition as the optimal use of limited computational resources - Behavioral and Brain Sciences, 2020. [All Versions]. A resource-rational account on interpreting human intelligence. Rational Use of Cognitive Resources: Levels of Analysis Between the Computational and the Algorithmic - Topics in Cognitive Science, 2015. [All Versions]. An earlier version of the paper above. Understanding Human Intelligence through Human Limitations - Trends in Cognitive Sciences, 2020. [All Versions]. [Preprint]. Recent progress in artificial intelligence provides the opportunity to ask the question of what is unique about human intelligence, but with a new comparison class. The author argues that we can understand human intelligence, and the ways in which it may differ from artificial intelligence, by considering the characteristics of the kind of computational problems that human minds have to solve. The author claims that these problems acquire their structure from three fundamental limitations that apply to human beings: limited time, limited computation, and limited communication. From these limitations we can derive many of the properties we associate with human intelligence, such as rapid learning, the ability to break down problems into parts, and the capacity for cumulative cultural evolution. Foundations of intuitive power analyses in children and adults - Nature Human Behavior, 2022. [All Versions]. Evidences support that people have some of the foundations for 'intuitive power analyses', which help people use intuitive statistical reasoning and metacognitive strategies to estimate how much information they might need to solve different discrimination problems. Cognitive Science as a Source of Forward and Inverse Models of Human Decisions for Robotics and Control - Annual Review of Control, Robotics, and Autonomous Systems, 2022. [All Versions]. The review focuses on how cognitive science can provide forward models of human decision-making and inverse models of how humans think about others’ decision-making. The authors highlight relevant recent developments, including approaches that synthesize black box and theory-driven modeling, accounts that recast heuristics and biases as forms of bounded optimality, and models that characterize human theory of mind and communication in decision-theoretic terms. *Back to Top Cognitive Architecture Epistemology - Plato Stanford. The secret life of predictive brains: what's spontaneous activity for? - Trends in Cognitive Sciences, 2021. [All Versions]. A neuroscience account on brain as a generative model. SOAR: An architecture for general intelligence - Artificial Intelligence, 1987. [All Versions]. Is human cognition adaptive? - Behavioral and Brain Sciences, 1991. [All Versions]. The original paper introducing the adaptation perspective of human intelligence, the theoretical basis of the ACT cognitive architecture. Metacognition in computation: A selected research review - Artificial Intelligence, 2005. [All Versions]. Basic functional trade-offs in cognition: An integrative framework - Cognition, 2018. [All Versions]. What is consciousness, and could machines have it? - Science, 2017. [All Versions]. A perspective on the two levels of consciousness in machine intelligence. A Theoretical Computer Science Perspective on Consciousness - Journal of Artificial Intelligence and Consciousness, 2020. [All Versions]. *Back to Top Science Logology Philosophy of Science The structure of scientific revolutions - University of Chicago Press: Chicago, 1970. [All Versions]. Thomas Kuhn's original book on the emergence and the shift of scientific paradigms. The Meaning of "Theory" - Sociological Theory, 2008. [All Versions]. A philosophical account on the definition of "theory" in social science (also can be generalized to natural science). The blind men and the elephant: A metaphor to illuminate the role of researchers and reviewers in social science - Methodological Innovations Online, 2013. [All Versions]. A Computational Inflection for Scientific Discovery - Communications of the ACM, 2023. [All Versions]. *Back to Top Science of Science Metascience - Wikipedia. Science of Science - Science, 2018. [All Versions]. A comprehensive large-scale review on the science of science. Finding Scientific Topics - Proceedings of the National Academy of Sciences, 2004. [All Versions]. Thomas L. Griffiths's analysis of scientific topics using Bayesian model. Meta-assessment of Bias in Science - Proceedings of the National Academy of Sciences, 2017. [All Verisions]. An analysis of bias patterns and risk factors in science. Slowed Canonical Progress in Large Fields of Science - Proceedings of the National Academy of Sciences, 2021. [All Verisions]. An analysis of why too many papers published each year in a field can lead to stagnation rather than advance. HCI Research as Problem-Solving - ACM SIGCHI'16, 2016. [All Versions]. This essay contributes a meta-scientific account of human-computer interaction (HCI) research as problem-solving. We build on the philosophy of Larry Laudan, who develops problem and solution as the foundational concepts of science. We argue that most HCI research is about three main types of problem: empirical, conceptual, and constructive. *Back to Top Literature Mining Structured information extraction from scientific text with large language models - Nature Communications, 2024. [All Versions]. This paper presents a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models can be fine-tuned to extract useful records of complex scientific knowledge. The authors test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks, and general composition/phase/morphology/application information extraction. Automated extraction of chemical synthesis actions from experimental procedures - Nature Communications, 2020. [All Versions]. This paper presents a method to convert unstructured experimental procedures written in English to structured synthetic steps (action sequences) reflecting all the operations needed to successfully conduct the corresponding chemical reactions. Inferring experimental procedures from text-based representations of chemical reactions - Nature Communications, 2021. [All Versions]. This paper presents data-driven models for predicting the entire sequence of synthesis steps starting from a textual representation of a chemical equation, for application in batch organic chemistry. Language models and protocol standardization guidelines for accelerating synthesis planning in heterogeneous catalysis - Nature Communications, 2023. [All Versions]. This paper introduces a transformer model for automated synthesis protocol analysis in catalyst discovery, exemplified using single-atom heterogeneous catalysts (SACs), a rapidly expanding catalyst family. The model adeptly converts SAC protocols into action sequences, and this output is used to facilitate statistical inference of their synthesis trends and applications, potentially expediting literature review and analysis. Galactica: A Large Language Model for Science - Meta AI, 2022. [All Versions]. A large language model trained on large-scale scientific corpus. CORWA: A Citation-Oriented Related Work Annotation Dataset - NAACL'22, 2022. [All Versions]. ESRA: Explainable Scientific Research Assistant - ACL'21 Demo Track, 2021. [All Versions]. A tool for constructing and visualizing the knowledge graph of a query keyword in literature retrieving. cite2vec: Citation-Driven Document Exploration via Word Embeddings - IEEE Transactions on Visualization and Computer Graphics, 2016. [All Versions]. Galex: Exploring the evolution and intersection of disciplines - IEEE Transactions on Visualization and Computer Graphics, 2019. [All Versions]. *Back to Top Scientific Writing The uses of argument - Cambridge University Press, 1958. [All Versions]. Stephen Toulmin's introduction to the Toulmin argument pattern, which is generally consist of a claim, a justification, and a rebuttal. A tagmemic approach to paragraph analysis - College Composition and Communication, 1965. [All Versions]. The original paper on analyzing the structure of expository paragraphs, with the two patterns---the Topic-Restriction-Illustration pattern and the Problem-Solution pattern. The uses and complexity of argument structures in expert and student persuasive writing - Written Communication, 1998. [All Versions]. A behaviorial study revealing the argument structures exploited by people in argumentative writing. Towards an argument interchange format - The Knowledge Engineering Review, 2006. [All Versions]. The original paper introducing the Argument Interchange Format (AIF) framework for argumentation analysis. Speech Acts of Argumentation: Inference Anchors and Peripheral Cues in Dialogue - AAAI'12, 2012. [All Versions]. The original paper introducing the Information Anchoring Theory (IAT) as an alternate for AIF. *Back to Top Science Education Cognitive Science and Science Education - American Psychologist, 1986. [All Versions]. Susan Carey's review on cognitive-science-based methodologies for science education research. PersLEARN: Research Training through the Lens of Perspective Cultivation - ACL'23, 2023. [All Versions]. Scientific research is inherently shaped by its authors’ perspectives, influenced by various factors such as their personality, community, or society. Junior researchers often face challenges in identifying the perspectives reflected in the existing literature and struggle to develop their own viewpoints. To address the problem, this paper introduces PersLEARN, a tool designed to facilitate the cultivation of scientific perspectives, starting from a basic seed idea and progressing to a well-articulated framework. *Back to Top Democratization of Science Reproducibility - Science, 2014. [All Versions]. Bridging the information gap in organic chemical reactions - Nature Chemistry, 2024. [All Versions]. This perspective article formulates eight principles to improve data management in scientific publications relating to data standardization, reproducibility and evaluation, and encourage scientists to go beyond current publication standards. A manifesto for reproducible science - Nature Human Behavior, 2017. [All Versions]. 1,500 scientists lift the lid on reproducibility - Nature, 2016. [All Versions]. How to Make More Published Research True - PLoS Medicine, 2014. [All Versions]. Six factors affecting reproducibility in life science research and how to handle them - Nature Advertisement. Five keys to writing a reproducible lab protocol - Nature, 2021. [All Versions]. This interviewing paper introduces five ways to increase the reproducibility of experimental protocols: (i) documenting protocols as the experiment goes; (ii) providing video illustrations in addition to written protocols; (iii) using electronic lab notebooks (ELNs) for managing experimental resources digitally; (iv) depositing and documenting reagents with understanding the rationale behind every step; and (v) exploiting online platforms to share tips, extensions, methods, and data among researchers. The Experimental Design Assistant - PLoS Biology, 2017. [All Versions]. [Nature Methods Correspondence]. [EDA Website]. The EDA is a web-based tool that guides the in vivo researcher through the experimental design and analysis process, providing automated feedback on the proposed design and generating a graphical summary that aids communication with colleagues, funders, regulatory authorities, and the wider scientific community. *Back to Top Laboratory Automation Reconfigurable system for automated optimization of diverse chemical reactions - Science, 2018. [All Versions]. [Preprint]. This paper describes a plug-and-play, continuous-flow chemical synthesis system that mitigates this challenge with an integrated combination of hardware, software, and analytics. The system software controls the user-selected reagents and unit operations (reactors and separators), processes reaction analytics (high-performance liquid chromatography, mass spectrometry, vibrational spectroscopy), and conducts automated optimizations. Organic synthesis in a modular robotic system driven by a chemical programming language - Science, 2019. [All Versions]. [Preprint]. [Perspective: Democratizing synthesis by automation]. This paper develops an autonomous compiler and robotic laboratory platform to synthesize organic compounds on the basis of standardized methods descriptions. The platform comprises conventional equipment such as round-bottom flasks, separatory funnels, and a rotary evaporator to maximize its compatibility with extant literature. The authors showcase the system with short syntheses of three common pharmaceuticals that proceeded comparably to manual synthesis. A universal system for digitization and automatic execution of the chemical synthesis literature - Science, 2020. [All Versions]. [Preprint]. [XDL Documentation]. [XDL Schema Database]. This paper reports a software platform that uses natural language processing to translate the organic chemistry literature directly into editable code, which in turn can be compiled to drive automated synthesis of the compound in the laboratory. Digitization and validation of a chemical synthesis literature database in the ChemPU - Science, 2022. [All Versions]. [Preprint]. This paper presents an automatically executable chemical reaction database of 100 molecules representative of the range of reactions found in contemporary organic synthesis. The chemical reaction codes or χDLs for the reactions have been stored in a database for version control, validation, collaboration, and data mining. Of these syntheses, more than 50 entries from the database have been downloaded and robotically run in seven modular chemputers with yields and purities comparable to those achieved by an expert chemist. Chemputation and the Standardization of Chemical Informatics - Journal of the American Chemical Society (Au), 2021. [All Versions]. This paper describes a standard hardware (the chemical processing programming architecture --- the ChemPU) to encompass all chemical synthesis, an approach which unifies all chemistry automation strategies, from solid-phase peptide synthesis, to HTE flow chemistry platforms, while at the same time establishing a publication standard so that researchers can exchange chemical code (χDL) to ensure reproducibility and interoperability. Convergence of multiple synthetic paradigms in a universally programmable chemical synthesis machine - Nature Chemistry, 2020. [All Versions]. [Preprint]. This paper shows how the Chemputer synthesis robot can be programmed to perform many different reactions, including solid-phase peptide synthesis, iterative cross-coupling and accessing reactive, unstable diazirines in a single, unified system with high yields and purity. An autonomous portable platform for universal chemical synthesis - Nature Chemistry, 2022. [All Versions]. [Preprint]. This paper presents a portable suitcase-sized chemical synthesis platform containing all the modules required for synthesis and purification. The system uses a chemical programming language coupled to a digital reactor generator to produce reactors and executable protocols based on text-based literature syntheses. Simultaneously, the platform generates a reaction pressure fingerprint, used to monitor processes within the reactors and remotely perform a protocol quality control. An integrated self-optimizing programmable chemical synthesis and reaction engine - Nature Communications, 2024. [All Versions]. This paper presents a dynamically programmable system capable of making, optimizing, and discovering new molecules which utilizes seven sensors that continuously monitor the reaction. By developing a dynamic programming language, the work demonstrates the 10-fold scale-up of a highly exothermic oxidation reaction, end point detection, as well as detecting critical hardware failures. A mobile robotic chemist - Nature, 2020. [All Versions]. [Preprint]. This work uses a mobile robot to search for improved photocatalysts for hydrogen production from water. The robot operated autonomously over eight days, performing 688 experiments within a ten-variable experimental space, driven by a batched Bayesian search algorithm. This autonomous search identified photocatalyst mixtures that were six times more active than the initial formulations, selecting beneficial components and deselecting negative ones. An autonomous laboratory for the accelerated synthesis of novel materials - Nature, 2023. [All Versions]. This paper introduces the A-Lab, an autonomous laboratory for the solid-state synthesis of inorganic powders. This platform uses computations, historical data from the literature, machine learning (ML) and active learning to plan and interpret the outcomes of experiments performed using robotics. Over 17 days of continuous operation, the A-Lab realized 41 novel compounds from a set of 58 targets including a variety of oxides and phosphates that were identified using large-scale ab initio phase-stability data from the Materials Project and Google DeepMind. The Internet of Things comes to the lab - Nature, 2017. [All Versions]. The emergence of connected instruments and equipment promises to untether researchers from the laboratory --- letting them fine-tune experiments and analyse data remotely. A dynamic knowledge graph approach to distributed self-driving laboratories - Nature Communications, 2024. [All Versions]. This work employs ontologies to capture data and material flows in design-make-test-analyse cycles, utilising autonomous agents as executable knowledge components to carry out the experimentation workflow. Data provenance is recorded to ensure its findability, accessibility, interoperability, and reusability. The architecture is built upon the World Avatar project, which seeks to create an all-encompassing digital twin based on a dynamic knowledge graph. Automation isn't automatic - Chemical Science, 2021. [All Versions]. This perspective provides an overview of the current state of automation of synthetic chemistry at the benchtop scale with a particular emphasis on core considerations and the ensuing challenges of deploying a system. The authors aim to reframe automation as decidedly not automatic but rather an iterative process that involves a series of careful decisions (both human and computational) and constant adjustment. Balancing act: when to flex and when to stay fixed - Trends in Chemistry, 2023. [All Versions]. This perspective article provides essential insights into the decision-making process for choosing automation platforms, highlighting the suitability of fixed automation for standardized tasks and the strategic use of flexible automation in dynamic research settings. What is a minimal working example for a self-driving laboratory? - Matter, 2022. [All Versions]. This paper proposes SDL-Demo: a low-cost “Hello, World!” for self-driving laboratories that combines “Hello, World!” tasks from electronics, physics-based simulations, and optimization. SDL-Demo is modular and extensible, making it an ideal candidate for low-cost teaching and prototyping of self-driving laboratory concepts. Robotic search for optimal cell culture in regenerative medicine - eLife, 2022. [All Versions]. This paper develops a robotic AI system with a batch Bayesian optimization algorithm that autonomously induces the differentiation of induced pluripotent stem cell-derived retinal pigment epithelial (iPSC-RPE) cells. From 200 million possible parameter combinations, the system performed cell culture in 143 different conditions in 111 days, resulting in 88% better iPSC-RPE production than that obtained by the pre-optimized culture in terms of the pigmentation scores. Cell Culture: Implementing robotics and artificial intelligence - eLife, 2022. [All Versions]. *Back to Top AI Assisted Research Scientific discovery in the age of artificial intelligence - Nature, 2023. [All Versions]. A review article that examines breakthroughs over the past decade that include self-supervised learning, which allows models to be trained on vast amounts of unlabelled data, and geometric deep learning, which leverages knowledge about the structure of scientific data to enhance model accuracy and efficiency. The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4 - Microsoft Research AI4Science, 2023. [All Versions]. [Project]. A survey on the performance of LLMs within the context of scientific discovery, focusing on GPT-4. Highly accurate protein structure prediction with AlphaFold - Nature, 2021. [All Versions]. This paper provides the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. This approach is a canonical application of observation- and explanation- based method for protein structure prediction instead of first-principle-based methods. Human–machine collaboration for improving semiconductor process development - Nature, 2023. [All Versions]. [Nature News]. This work studies Bayesian optimization algorithms to investigate how artificial intelligence (AI) might decrease the cost of developing complex semiconductor chip processes. In particular, this work create a controlled virtual process game to systematically benchmark the performance of humans and computers for the design of a semiconductor fabrication process. The authors find that human engineers excel in the early stages of development, whereas the algorithms are far more cost-efficient near the tight tolerances of the target. A foundation model for generalizable disease detection from retinal images - Nature, 2023. [All Versions]. This paper presents RETFound, a foundation model for retinal images that learns generalizable representations from unlabelled retinal images and provides a basis for label-efficient model adaptation in several applications. Specifically, RETFound is trained on 1.6 million unlabelled retinal images by means of self-supervised learning and then adapted to disease detection tasks with explicit labels. Accurate medium-range global weather forecasting with 3D neural networks - Nature, 2023. [All Versions]. This paer introduces an artificial-intelligence-based method for accurate, medium-range global weather forecasting. It shows that three-dimensional deep networks equipped with Earth-specific priors are effective at dealing with complex patterns in weather data, and that a hierarchical temporal aggregation strategy reduces accumulation errors in medium-range forecasting. Trained on 39 years of global data, the program, Pangu-Weather, obtains stronger deterministic forecast results on reanalysis data in all tested variables when compared with the world’s best NWP system, the operational integrated forecasting system of the European Centre for Medium-Range Weather Forecasts. Learning skillful medium-range global weather forecasting - Science, 2023. [All Versions]. Skilful nowcasting of extreme precipitation with NowcastNet - Nature, 2023. [All Versions]. Autonomous chemical research with large language models - Nature, 2023. [All Versions]. An artificial intelligence system driven by GPT-4 that autonomously designs, plans and performs complex experiments by incorporating large language models empowered by tools such as internet and documentation search, code execution and experimental automation. Augmenting large language models with chemistry tools - Nature Machine Intelligence, 2023. [All Versions]. [Preprint]. This paper introduces ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery and materials design. By integrating 18 expert-designed tools and using GPT-4 as the LLM, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. The agent autonomously planned and executed the syntheses of an insect repellent and three organocatalysts and guided the discovery of a novel chromophore. BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology - EMNLP'23, 2023. [All Versions]. This paper presents an automatic evaluation framework for the task of planning experimental protocols, and introduces BioProt: a dataset of biology protocols with corresponding pseudocode representations. A human-machine interface for automatic exploration of chemical reaction networks - Nature Communications, 2024. [All Versions]. Autonomous reaction network exploration algorithms offer a systematic approach to explore mechanisms of complex chemical processes. However, the resulting reaction networks are so vast that an exploration of all potentially accessible intermediates is computationally too demanding. This paper introduces a STEERING WHEEL to guide an otherwise unbiased automated exploration. The STEERING WHEEL algorithm is intuitive, generally applicable, and enables one to focus on specific regions of an emerging network. It also allows for guiding automated data generation in the context of mechanism exploration, catalyst design, and other chemical optimization challenges. PatCID: an open-access dataset of chemical structures in patent documents - Nature Communications, 2024. [All Versions]. The automatic analysis of patent publications has potential to accelerate research across various domains, including drug discovery and material science. Within patent documents, crucial information often resides in visual depictions of molecule structures. PatCID (Patent-extracted Chemical-structure Images database for Discovery) allows to access such information at scale. It enables users to search which molecules are displayed in which documents. PatCID contains 81M chemical-structure images and 14M unique chemical structures. This work compares PatCID with state-of-the-art chemical patent-databases. On a random set, PatCID retrieves 56.0% of molecules, which is higher than automatically-created databases, Google Patents (41.5%) and SureChEMBL (23.5%), as well as manually-created databases, Reaxys (53.5%) and SciFinder (49.5%). Leveraging state-of-the-art methods of document understanding, PatCID high-quality data outperforms currently available automatically-generated patent-databases. PatCID even competes with proprietary manually-created patent-databases. This enables promising applications for automatic literature review and learning-based molecular generation methods. ChipNeMo: Domain-Adapted LLMs for Chip Design - 2023. [All Versions]. Single-atom alloy catalysts designed by first-principles calculations and artificial intelligence - Nature Communications, 2021. [All Versions]. This paper addresses the problem of new Single-atom-alloy catalysts (SAACs) discovery by applying a compressed-sensing data-analytics approach parameterized with density-functional inputs. Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences - Proceedings of the National Academy of Sciences, 2021. [All Versions]. Comparability of automated human induced pluripotent stem cell culture: a pilot study - Bioprocess and Biosystems Engineering, 2016. [All Versions]. Artificial Intelligence for Retrosynthetic Planning Needs Both Data and Expert Knowledge - Journal of the American Chemical Society, 2024. [All Versions]. The development of AI synthesis planners trained solely on reaction-example-data has stagnated and is not on par with the performance of “hybrid” algorithms combining AI with expert knowledge. This Perspective examines possible causes of these shortcomings, extending beyond the established reasoning of insufficient quantities of reaction data. The authors advocate augmenting the unique capabilities of AI with the knowledge base and the reasoning strategies of domain experts. Virtual and augmented reality for biomedical applications - Cell Reports Medicine, 2021. [All Versions]. 3D visualization technologies such as virtual reality (VR), augmented reality (AR), and mixed reality (MR) have gained popularity in the recent decade. Digital extended reality (XR) technologies have been adopted in various domains ranging from entertainment to education because of their accessibility and affordability. XR modalities create an immersive experience, enabling 3D visualization of the content without a conventional 2D display constraint. This paper provides a perspective on XR in current biomedical applications and demonstrate case studies using cell biology concepts, multiplexed proteomics images, surgical data for heart operations, and cardiac 3D models. Emerging challenges associated with XR technologies in the context of adverse health effects and a cost comparison of distinct platforms are discussed. The presented XR platforms will be useful for biomedical education, medical training, surgical guidance, and molecular data visualization to enhance trainees’ and students’ learning, medical operation accuracy, and the comprehensibility of complex biological systems. An augmented reality microscope with real-time artificial intelligence integration for cancer diagnosis - Nature Medicine, 2019. [All Versions]. The microscopic assessment of tissue samples is instrumental for the diagnosis and staging of cancer, and thus guides therapy. However, these assessments demonstrate considerable variability and many regions of the world lack access to trained pathologists. Though artificial intelligence (AI) promises to improve the access and quality of healthcare, the costs of image digitization in pathology and difficulties in deploying AI solutions remain as barriers to real-world use. This work proposes a cost-effective solution: the augmented reality microscope (ARM). The ARM overlays AI-based information onto the current view of the sample in real time, enabling seamless integration of AI into routine workflows. Optimizing Spaced Repetition Schedule by Capturing the Dynamics of Memory - IEEE Transactions on Knowledge and Data Engineering, 2023. [All Versions]. LEGAL-BERT: The Muppets straight out of Law School - EMNLP'20, 2020. [All Versions]. Generating answers to legal questions, analyze contracts, and summarizing legal documents, making legal knowledge more accessible to non-experts. BioBERT: a pre-trained biomedical language representation model for biomedical text mining - Bioinformatics, 2020. [All Versions]. Answering medical questions, identifying relevant clinical trials, and diagnosing diseases based on symptoms, making medical information more accessible to the general public. Finbert: A pre-trained financial language representation model for financial text mining - IJCAI'20, 2020. [All Versions]. Predicting stock market trends, analyzing financial documents, and generating summaries of economic news articles, helping to disseminate financial knowledge. SciBERT: A Pretrained Language Model for Scientific Text - EMNLP'19, 2019. [All Versions]. Searching and synthesizing scientific literature, aiding researchers in hypothesis generation, and assisting with experimental design, making scientific knowledge more accessible. CodeBERT: A Pre-Trained Model for Programming and Natural Languages - EMNLP'20, 2020. [All Versions]. Completing code, generating programming documentation, and providing technical support, making programming knowledge more accessible to non-experts. *Back to Top Theory of Mind Theory of Mind - Wikipedia. Wikipedia on Theory of Mind (ToM), a cognitive capability that estimating others' goal, belief, and desire. Intentionality - Plato Stanford. Mental Imagery - Plato Stanford. The naïve utility calculus: Computational principles underlying commonsense psychology - Trends in Cognitive Sciences, 2016. [All Versions]. [Preprint]. This review article proposes that human social cognition is structured around a basic understanding of ourselves and others as intuitive utility maximizers: from a young age, humans implicitly assume that agents choose goals and actions to maximize the rewards they expect to obtain relative to the costs they expect to incur. This ‘naïve utility calculus’ allows both children and adults observe the behavior of others and infer their beliefs and desires, their longer-term knowledge and preferences, and even their character: who is knowledgeable or competent, who is praiseworthy or blameworthy, who is friendly, indifferent, or an enemy. Planning with theory of mind - Trends in Cognitive Sciences, 2022. [All Versions]. [Preprint]. A perspective on understanding Theory of Mind through planning that consists of abstract structured causal representations and supports efficient search and selection from innumerable possible actions. Planning requires that Theory of Mind consists of abstract structured causal representations and supports efficient search and selection from innumerable possible actions. Theory of Mind contrasts with less cognitively demanding alternatives: statistical predictive models of other people’s actions, or model-free reinforcement of actions by their effects on other people. Theory of Mind is likely used to plan novel interventions and predict their effects, for example, in pedagogy, emotion regulation, and impression management. Action Understanding as Inverse Planning - Cognition, 2009. [All Versions]. [Appendix]. The original paper on Inverse Planning, a computational implementation of Theory of Mind. Humans are adept at inferring the mental states underlying other agents’ actions, such as goals, beliefs, desires, emotions and other thoughts. This paper proposes a computational framework based on Bayesian inverse planning for modeling human action understanding. The framework represents an intuitive theory of intentional agents’ behavior based on the principle of rationality: the expectation that agents will plan approximately rationally to achieve their goals, given their beliefs about the world. The mental states that caused an agent's behavior are inferred by inverting this model of rational planning using Bayesian inference, integrating the likelihood of the observed actions with the prior over mental states. Bayesian Theory of Mind: Modeling Joint Belief-Desire Attribution - CogSci'11, 2011. [All Versions]. [Preprint]. This paper presents a computational framework for understanding Theory of Mind (ToM): the human capacity for reasoning about agents’ mental states such as beliefs and desires. The proposed Bayesian model of ToM (or BToM) expresses the predictive model of belief- and desire-dependent action at the heart of ToM as a partially observable Markov decision process (POMDP), and reconstructs an agent’s joint belief state and reward function using Bayesian inference, conditioned on observations of the agent’s behavior in some environmental context. The Signature of All Things: Children Infer Knowledge States from Static Images - CogSci'20, 2020. [All Versions]. Bayesian Brains without Probabilities - Trends in Cognitive Sciences, 2016. [All Versions]. A perspective on human probabilistic modeling without explicit probabilistic computation. Rational quantitative attribution of beliefs, desires and percepts in human mentalizing - Nature Human Behavior, 2017. [All Versions]. [Preprint]. This paper presents a model of core mentalizing computations: inferring jointly an actor’s beliefs, desires and percepts from how they move in the local spatial environment. The proposed Bayesian theory of mind (BToM) model is based on probabilistically inverting artificial-intelligence approaches to rational planning and state estimation, which extend classical expected-utility agent models to sequential actions in complex, partially observable domains. Machine theory of mind - ICML'18, 2018. [All Versions]. Theory of mind (ToM) broadly refers to humans’ ability to represent the mental states of others, including their desires, beliefs, and intentions. This work proposes a Theory of Mind neural network --- a ToMnet --- which uses meta-learning to build such models of the agents it encounters. The ToMnet learns a strong prior model for agents’ future behaviour, and, using only a small number of behavioural observations, can bootstrap to richer predictions about agents’ characteristics and mental states. Theory of mind as inverse reinforcement learning - Current Opinion in Behavioral Sciences, 2019. [All Versions]. This paper reviews the idea that Theory of Mind --- humans' ability to reason about other people's mental states --- can be formalized as inverse reinforcement learning. Under this framework, expectations about how mental states produce behavior are captured in a reinforcement learning (RL) model. Predicting other people’s actions is achieved by simulating a RL model with the hypothesized beliefs and desires, while mental-state inference is achieved by inverting this model. Although many advances in inverse reinforcement learning (IRL) did not have human Theory of Mind in mind, this paper focuses on what they reveal when conceptualized as cognitive theories. Computational Models of Emotion Inference in Theory of Mind: A Review and Roadmap - Topics in Cognitive Science, 2019. [All Versions]. This paper proposes an intuitive theory framework to studying affective cognition—how humans reason about emotions—and derive a taxonomy of inferences within affective cognition. Using this taxonomy, the authors review formal computational modeling work on such inferences, including causal reasoning about how others react to events, reasoning about unseen causes of emotions, reasoning with multiple cues, as well as reasoning from emotions to other mental states. This framework proposes unifying these various types of reasoning as Bayesian inference within a common “intuitive Theory of Emotion.” The Naïve Utility Calculus as a unified, quantitative framework for action understanding - Cognitive Psychology, 2021. [All Versions]. [Project]. This paper presents a formal theory of the Naïve Utility Calculus as a probabilistic generative model, which highlights the role of cost and reward tradeoffs in a Bayesian framework for action-understanding. The model predicts with quantitative accuracy how people infer agents’ subjective costs and rewards based on their observable actions. By distinguishing between desires, goals, and intentions, the model extends to complex action scenarios unfolding over space and time in scenes with multiple objects and multiple action episodes. AGENT: A Benchmark for Core Psychological Reasoning - ICML'21, 2021. [All Versions]. Inspired by cognitive development studies on intuitive psychology, this paper presents a benchmark consisting of a large dataset of procedurally generated 3D animations, AGENT (Action, Goal, Efficiency, coNstraint, uTility), structured around four scenarios (goal preferences, action efficiency, unobserved constraints, and cost-reward trade-offs) that probe key concepts of core intuitive psychology. The results suggest that to pass the designed tests of core intuitive psychology at human levels, a model must acquire or have built-in representations of how agents plan, combining utility computations and core knowledge of objects and physics. Experimental Games and Social Decision Making - Annual Review of Psychology, 2021. [All Versions]. Experimental games model situations in which the future outcomes of individuals and groups depend on their own choices and on those of other (groups of) individuals. Games are a powerful tool to identify the neural and psychological mechanisms underlying interpersonal and group cooperation and coordination. This review article discusses recent developments in how experimental games are used and adapted, with an increased focus on repeated interactions, partner control through sanctioning, and partner (de)selection for future interactions. Theory of Minds: Understanding Behavior in Groups through Inverse Planning - AAAI'19, 2019. [All Versions]. Towards the goal of building machine-learning algorithms with human-like social intelligence, this paper develops a generative model of multiagent action understanding based on a novel representation for these latent relationships called Composable Team Hierarchies (CTH). This representation is grounded in the formalism of stochastic games and multi-agent reinforcement learning. This work uses CTH as a target for Bayesian inference yielding a new algorithm for understanding behavior in groups that can both infer hidden relationships as well as predict future actions for multiple agents interacting together. Leveraging Facial Expressions and Contextual Information to Investigate Opaque Representations of Emotion - Emotion, 2019. [All Versions]. Waiting and weighting: Information sampling is a balance between efficiency and error-reduction - Cognition, 2013. [All Versions]. Natural scene statistics account for the representation of scene categories in human visual cortex - Neuron, 2013. [All Versions]. Using human brain activity to guide machine learning - Scientific Report, 2018. [All Versions]. Unit of visual working memory: A Boolean map provides a better account than an object does - Journal of Experimental Psychology, 2020. [All Versions]. The logic of universalization guides moral judgment - Proceedings of the National Academy of Sciences, 2020. [All Versions]. Learning Triadic Belief Dynamics in Nonverbal Communication from Videos - CVPR'21, 2021. [All Versions]. [Preprint]. This paper incorporates different nonverbal communication cues (e.g., gaze, human poses, and gestures) to represent, model, learn, and infer agents' mental states from pure visual inputs. Crucially, such a mental representation takes the agent's belief into account so that it represents what the true world state is and infers the beliefs in each agent's mental state, which may differ from the true world states. By aggregating different beliefs and true world states, the model essentially forms "five minds" during the interactions between two agents. This "five minds" model differs from prior works that infer beliefs in an infinite recursion; instead, agents' beliefs are converged into a "common mind". Based on this representation, this work further devises a hierarchical energy-based model that jointly tracks and predicts all five minds. From this new perspective, a social event is interpreted by a series of nonverbal communication and belief dynamics, which transcends the classic keyframe video summary. Ten-month-old infants infer the value of goals from the costs of actions - Science, 2017. [All Versions]. A piece of evidence for children's capability on ToM. Origins of the concepts cause, cost, and goal in prereaching infants - Proceedings of the National Academy of Sciences, 2019. [All Versions]. Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and actions of others - NeurIPS'21, 2021. [All Versions]. Intentonomy: a Dataset and Study towards Human Intent Understanding - CVPR'21, 2021. [All Versions]. A large-scale database on human intentionally-posted images on social media. Adventures in Flatland: Perceiving Social Interactions Under Physical Dynamics - CogSci'20, 2020. [All Versions]. PHASE: PHysically-grounded Abstract Social Events for Machine Social Perception - AAAI'21, 2021. [All Versions]. [Project]. Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration - ICLR'21, 2021. [All Versions]. Evaluating and Modeling Social Intelligence: A Comparative Study of Human and AI Capabilities - CogSci'24, 2024. [All Versions]. This work eveloped a comprehensive theoretical framework for social dynamics and introduced two evaluation tasks: Inverse Reasoning (IR) and Inverse Inverse Planning (IIP). The approach also encompassed a computational model based on recursive Bayesian inference, adept at elucidating diverse human behavioral patterns. Extensive experiments and detailed analyses revealed that humans surpassed the latest GPT models in overall performance, zero-shot learning, one-shot generalization, and adaptability to multi-modalities. *Back to Top Analogy Metaphor - Plato Stanford. A computational philosophy account on Metaphor, a poetically or rhetorically ambitious use of words, a figurative as opposed to literal use. Analogy and Analogical Reasoning - Plato Stanford. A computational philosophy account on Analogy, a comparison between two objects, or systems of objects, that highlights respects in which they are thought to be similar. A Cognitive Theory of Metaphor - MIT Press, 1985. [All Versions]. A cognitive account on Metaphor. The structure-mapping engine: Algorithm and examples - Artificial Intelligence, 1989. [All Versions]. A computational implementation of analogy. Structure mapping in analogy and similarity - American Psychologist, 1997. [All Versions]. A perspective unifying analogy and similarity judgement. A theory of relation learning and cross-domain generalization - Psychological Review, 2022. [All Versions]. A comprehensive review on the perspective of treating analogy as cross-domain generalization. Emergence of analogy from relation learning - Proceedings of the National Academy of Sciences, 2019. [All Versions]. Analogy feature in language models. Analogies Explained: Towards Understanding Word Embeddings - ICML'19, 2019. [All Versions]. Explaining the analogy capability in word embeddings. Skip-Gram − Zipf + Uniform = Vector Additivity - ACL'17, 2017. [All Versions]. Generalize and Blend: Concept Blending Based on Generalization, Analogy, and Amalgams - ICCC'15, 2015. [All Versions]. Analogy-preserving Semantic Embedding for Visual Object Categorization - ICML'13, 2013. [All Versions]. The first application of analogy to machine learning. VISALOGY: Answering Visual Analogy Questions - NeurIPS'15, 2015. [All Versions]. Detecting Unseen Visual Relations Using Analogies - CVPR'19, 2019. [All Versions]. Analogy between concepts - Artificial Intelligence, 2019. [All Versions]. A mathematical account on analogy. Learning to Make Analogies by Contrasting Abstract Relational Structure - ICLR'19, 2019. [All Versions]. Sky + Fire = Sunset. Exploring Parallels between Visually Grounded Metaphors and Image Classifiers - ACL'20, 2020. [All Versions]. Analogy as Nonparametric Bayesian Inference over Relational Systems - CogSci'20, 2020. [All Versions]. Visual Analogy: Deep Learning Versus Compositional Models - CogSci'21, 2021. [All Versions]. A human-deep-learning comparison on similarity judgement. Preschoolers and adults make inferences from novel metaphors - CogSci'22, 2022. [All Versions]. A piece of evidence that understanding metaphors is capable for different cognitive development phases. Similarity involving attributes and relations: Judgments of similarity and difference are not inverses - Psychological Science, 1990. [All Versions]. *Back to Top Causality Causality - Wikipedia. Wikipedia on causality, which is influence by which one event, process, state, or object (a cause) contributes to the production of another event, process, state, or object (an effect) where the cause is partly responsible for the effect, and the effect is partly dependent on the cause. Causal Models - Plato Stanford. A computational philosophy account on Causal models, which are mathematical models representing causal relationships within an individual system or population. Causal Theories of Mental Content - Plato Stanford. A computational philosophy account on causal theories of mental content, which attempts to explain how thoughts can be about things. Identification of Causal Effects Using Instrumental Variables - Journal of the American Statistical Association, 1996. [All Versions]. Predictive and Diagnostic Learning Within Causal Models: Asymmetries in Cue Competition - Journal of Experimental Psychology, 1992. [All Versions]. Experimental evidences for distincting causality and association. Causal Reasoning - The Oxford Handbook of Cognitive Psychology, 2013. [All Versions]. Reasoning with cause and effect - 1998. Judea Pearl's tutorials on causal reasoning with operations on Bayesian networks. The Seven Tools of Causal Inference, with Reflections on Machine Learning - Communications of the ACM, 2019. [All Versions]. Judea Pearl's review on causal inference in probabilistic graph models. Toward Causal Representation Learning - Proceedings of the IEEE, 2021. [All Versions]. Yoshua Bengio's review on the perspective of treating causal inference as a representation learning problem. Theory-Based Causal Induction - Psychological Review, 2009. [All Versions]. Thomas Griffiths' review on causal Bayesian theory induction. Theory-Based Causal Transfer: Integrating Instance-Level Induction and Abstract-Level Structure Learning - AAAI'20, 2020. [All Versions]. A computatinoal account on causal transfer. Inferring causal networks from observations and interventions - Cognitive Science, 2010. [All Versions]. Constraints on Hypothesis Selection in Causal Learning - CogSci'15, 2015. [All Versions]. Eye-tracking causality - Psychological Science, 2017. [All Versions]. What happened? Reconstructing the past through vision and sound - 2021. [All Versions]. How do people generalize causal relations over objects? A non-parametric Bayesian account - Computational Brain & Behavior, 2022. [All Versions]. [Preprint]. How do people decide how general a causal relationship is, in terms of the entities or situations it applies to? What features do people use to decide whether a new situation is governed by a new causal law or an old one? How can people make these difficult judgments in a fast, efficient way? This paper addresses these questions in two experiments that ask participants to generalize from one (Experiment 1) or several (Experiment 2) causal interactions between pairs of objects. In each case, participants see an agent object act on a recipient object, causing some changes to the recipient. Causal Reasoning in Rats - Science, 2006. [All Versions]. A piece of evidence for the capability of causal reasoning in intelligent animals. Do New Caledonian crows solve physical problems through causal reasoning? - Proceedings of the Royal Society B: Biological Sciences, 2009. [All Versions]. A piece of evidence for the capability of causal reasoning in intelligent animals. Do six-month-old infants perceive causality? - Cognition, 1987. [All Versions]. *Back to Top Commonsense Intuitive Physics Intuitive Physics Reading List - GitHub. A reading list on intuitive physics, maintained actively by Shiqian Li. Intuitive Physics: Current Research and Controversies - Trends in Cognitive Sciences, 2018. [All Versions]. Hongjing Lu's review on intuitive physics. Simulation as an engine of physical scene understanding - Proceedings of the National Academy of Sciences, 2013. [All Versions]. [Appendix]. The first attempt to computationally simulate intuitive physics. Functional neuroanatomy of intuitive physical inference - Proceedings of the National Academy of Sciences, 2016. [All Versions]. A piece of evidence for the functional part of intuitive physics in human brain. Mind Games: Game Engines as an Architecture for Intuitive Physics - Trends in Cognitive Sciences, 2017. [All Versions]. Tomer Ullman's review on simulation-based intuitive physics. Learning physical parameters from dynamic scenes - Cognitive Psychology, 2017. [All Versions]. Limits on Simulation Approaches in Intuitive Physics - Cognitive Psychology, 2021. [All Versions]. Ernest Davis's perspective against intuitive physics, that physcial reasoning is logical reasoning instead of intuition. Partial Mental Simulation Explains Fallacies in Physical Reasoning - Cognitive Neuropsychology, 2022. [All Versions]. Intuitive physics learning in a deep-learning model inspired by developmental psychology - Nature Human Behavior, 2022. [All Versions]. A machine-learning dataset designed to evaluate conceptual understanding of intuitive physics, adopting the violation-of-expectation (VoE) paradigm from developmental psychology; a deep-learning system that learns intuitive physics directly from visual data, inspired by studies of visual cognition in children. PHYRE: A New Benchmark for Physical Reasoning - NeurIPS'19, 2019. [All Versions]. A benchmark for AI physical reasoning. Phy-Q as a measure for physical reasoning intelligence - Nature Machine Intelligence, 2023. [NMI Challenge]. An interactive benchmark for AI physical reasoning. *Back to Top AI Commonsense Reasoning Representations of Commonsense Knowledge - Morgan Kaufmann, 1990. [All Versions]. A classic book on commonsense knowledge. Towards a theory of commonsense visual reasoning - FSTTCS, 1990. [All Versions]. The original paper on visual commonsense. Commonsense reasoning and commonsense knowledge in artificial intelligence - Communications of the ACM, 2015. [All Versions]. Gary Marcus's review on commonsense knowledge in AI. From Recognition to Cognition: Visual Commonsense Reasoning - CVPR'19, 2019. [All Versions]. [Project]. PIQA: Reasoning about Physical Commonsense in Natural Language - AAAI'20, 2020. [All Versions]. Visual Commonsense R-CNN - CVPR'20, 2020. [All Versions]. Abductive Commonsense Reasoning - ICLR'20, 2020. [All Versions]. Abductive commonsense reasoning on large language models. VisualCOMET: Reasoning About the Dynamic Context of a Still Image - ECCV'20, 2020. [All Versions]. The Abduction of Sherlock Holmes: A Dataset for Visual Abductive Reasoning - ECCV'22, 2022. [All Versions]. [Preprint]. This paper presents Sherlock, an annotated corpus of 103K images for testing machine capacity for abductive reasoning beyond literal image contents. The corpus construction process adopts a free-viewing paradigm: participants first observe and identify salient clues within images (e.g., objects, actions) and then provide a plausible inference about the scene, given the clue. UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations - NAACL'24, 2024. [All Versions]. This paper explores the task of uncommonsense abductive reasoning. Given a piece of context with an unexpected outcome, this task requires reasoning abductively to generate an explanation that makes the unexpected outcome more likely in the context. Experience Grounds Language - EMNLP'20, 2020. [All Versions]. A perspective on the furture of computational linguistics research---commonsense-driven and embodied language. Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning - EMNLP'21, 2021. [All Versions]. Human-like property induction is a challenge for large language models - CogSci'22, 2022. SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks - NeurIPS'23, 2023. [All Versions]. [Project]. *Back to Top Commonsense Knowledgebase wikiHow - wikiHow.com. wikiHow is on website hosting step-by-step "How-to" procedural instructions across various domains and topics. The World Avatar - The World Avatar™. A large-scale dynamic knowledge graph connecting concepts with relations to digitalize molecules, buildings, cities, and countries. CYC: A Large-Scale Investment in Knowledge Infrastructure - Communications of the ACM, 1995. [All Versions]. The first attempt to build large-scale commonse knoweldgebase from human knowledge. ConceptNet 5.5: An Open Multilingual Graph of General Knowledge - AAAI'17, 2017. [All Versions]. Latest version of ConceptNet. The Public Acquisition of Commonsense Knowledge - Proceedings of AAAI Spring Symposium on Acquiring (and Using) Linguistic (and World) Knowledge for Information Access, 2002. [All Versions]. The first attempt for acquring commonsense knowlege from humans' activities on the internet. Open Mind Common Sense: Knowledge Acquisition from the General Public - OTM Confederated International Conferences'02, 2002. [All Versions].. Verbosity: A Game for Collecting Common-Sense Facts - CHI'06, 2006. [All Versions]. Designing games with a purpose - Communications of the ACM, 2008. [All Versions]. Acquiring Comparative Commonsense Knowledge from the Web - AAAI'14, 2014. [All Versions]. Visual Concept Programming: A Visual Analytics Approach to Injecting Human Intelligence at Scale - IEEE Transactions on Visualization and Computer Graphics, 2023. [All Versions]. This paper presents Visual Concept Programming, a first-of-its-kind visual analytics approach of using visual concepts to program image data at scale while requiring a few human efforts. *Back to Top Inductive Logic & Program Synthesis Inductive Logic - Plato Stanford. A computational philosophy account on Inductive Logic, which is a logic of evidential support. First-order Model Theory - Plato Stanford. A computational philosophy account on First-order Model Theory, which is a branch of mathematics that deals with the relationships between descriptions in first-order languages and the structures that satisfy these descriptions. Paraconsistent Logic - Plato Stanford. A computational philosophy account on Paraconsistent Logic, where any logic is paraconsistent as long as it is not explosive. Logical Consequence - Plato Stanford. A computational philosophy account on Logical Consequence, which is about the relation between premises and conclusions in valid arguments. Logic Pluralism - Plato Stanford. A computational philosophy account on Logic Pluralism, which is the view that there is more than one correct logic. The Emergence of First-Order Logic - Plato Stanford. A computational philosophy account on the emergence of first-order logic, mainly about first-order logic is natural retrospect. Second-order and Higher-order Logic - Plato Stanford. Program Synthesis - Foundations and Trends in Programming Languages, 2017. [All Versions]. Sumit Gulwani's comprehensive review on program synthesis. The Discovery of the Equator or Concept Driven Learning - IJCAI'83, 1983. [All Versions]. The original paper on second-order metarules. Towards combining inductive logic programming with Bayesian networks - ILP'01, 2001. [All Versions]. Meta-interpretive learning: application to grammatical inference - Machine Learning, 2014. [All Versions]. Stephen Muggleton's original paper on Meta-Interpretive Learning (MIL). Learning Efficient Logical Robot Strategies Involving Composable Objects - IJCAI'15, 2015. [All Versions]. Learning Higher-Order Logic Programs through Abstraction and Invention - IJCAI'16, 2016. [All Versions]. How Much Can Experimental Cost Be Reduced in Active Learning of Agent Strategies? - ILP'18, 2018. [All Versions]. Meta-Interpretive Learning from noisy images - Machine Learning, 2018. [All Versions]. Learning efficient logic programs - Machine Learning, 2018. [All Versions]. Learning higher-order logic programs - Machine Learning, 2019. [All Versions]. Logical reduction of metarules - Machine Learning, 2019. [All Versions]. Playgol: Learning Programs Through Play - IJCAI'19, 2019. [All Versions]. Machine Discovery of Comprehensible Strategies for Simple Games Using Meta-interpretive Learning - New Generation Computing, 2019. [All Versions]. Forgetting to Learn Logic Programs - AAAI'20, 2020. [All Versions]. Turning 30: New Ideas in Inductive Logic Programming - IJCAI'20, 2020. [All Versions]. Inductive logic programming at 30: a new introduction - Journal of Artificial Intelligence Research, 2020. [All Versions]. A 30-year comprehensive review on Inductive Logic Programming. Learning programs by learning from failures - Machine Learning, 2020. [All Versions]. Complete Bottom-Up Predicate Invention in Meta-Interpretive Learning - IJCAI'20, 2020. [All Versions]. Meta-Interpretive Learning as Metarule Specialisation - Machine Learning, 2021. [All Versions]. Qualitative choice logic - Artificial Intelligence, 2004. [All Versions]. Derivative-free optimization of high-dimensional non-convex functions by sequential random embeddings - IJCAI'16, 2016. [All Versions]. Finitely Generated Groups and First-Order Logic - Journal of The London Mathematical Society-second Series, 2005. [All Versions]. Leveraging Language for Abstraction and Program Search - ICML'20, 2020. [All Versions]. Program Synthesis Guided Reinforcement Learning - NeurIPS'21, 2021. [All Versions]. Learning Part-Based Abstractions for Visual Object Concepts - CogSci'21, 2021. [All Versions]. Program Synthesis with Large Language Models - 2021. [All Versions]. This paper explores the limits of the current generation of large language models for program synthesis in general purpose programming languages. Combining Functional and Automata Synthesis to Discover Causal Reactive Programs - POPL'23, 2023. [All Versions]. A new algorithm that synthesizes functional reactive programs from observation data, which iterates between a functional synthesis step, which attempts to generate a transition function over observed states, and an automata synthesis step, which adds any additional latent state necessary to fully account for the observations. Synthesizing theories of human language with Bayesian program induction - Nature Communications, 2022. [All Versions]. From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought - 2023. [All Versions]. Rational meaning construction, a computational framework for language-informed thinking that combines neural language models with probabilistic models for rational inference. Linguistic meaning is framed as a context-sensitive mapping from natural language into a probabilistic language of thought (PLoT)--a general-purpose symbolic substrate for generative world modeling. Latent Programmer: Discrete Latent Codes for Program Synthesis - ICML'21, 2021. [All Versions]. Paper introducing the Latent Programmer, a two-level program synthesis method that first predicts a discrete latent code from input/output examples, and then generates the program in the target language. PAL: Program-aided Language Models - ICML'23, 2023. [All Versions]. Paper presenting an approach that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter. With PAL, decomposing the natural language problem into runnable steps remains the only learning task for the LLM, while solving is delegated to the interpreter. Large Language Models Meet NL2Code: A Survey - ACL'23, 2023. [All Versions]. [NL2Code Website]. A paper presenting a comprehensive survey of 27 existing large language models for NL2Code, and also review benchmarks and metrics, suggesting that the key factors contributing to the success of large language models for NL2Code are “Large Size, Premium Data, Expert Tuning”. A Large-Scale Survey on the Usability of AI Programming Assistants: Successes and Challenges - ICSE'24, 2024. [All Versions]. A survey finding that developers are most motivated to use AI programming assistants because they help developers reduce key-strokes, finish programming tasks quickly, and recall syntax, but resonate less with using them to help brainstorm potential solutions. Large Language Models for Software Engineering: A Systematic Literature Review - 2023. [All Versions]. A systematic literature review on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. *Back to Top Knowledge Representation Handbook of Knowledge Representation - Elsevier, 2008. [All Versions]. A pragmatical handbook for all kinds of knowledge representation modes. Logic and Ontology - Plato Stanford. A computational philosophy account on logic and ontology, mainly about the intersections of logic and ontology in many significant philosophy problems. The Language of Thought Hypothesis - Plato Stanford. A computational philosophy account on the laugnage of though hypothesis, which proposes that thinking occurs in a mental language. The Analysis of Knowledge - Plato Stanford. Scientific Representation - Plato Stanford. A computational philosophy account on scientific representation, focusing on how scientific models represent their target systems. Self-Knowledge - Plato Stanford. A computational philosophy account on self-knowledge, which standardly refers to knowledge of one's own mental states—that is, of what one is feeling or thinking, or what one believes or desires. Common Knowledge - Plato Stanford. Sense-Data - Plato Stanford. Supervenience - Plato Stanford. A computational philosophy account on supervenience, where a set of properties A supervenes upon another set B just in case no two things can differ with respect to A-properties without also differing with respect to their B-properties. Dialogical Logic - Plato Stanford. A computational philosophy account on dialogical logic, which is a dialogue-based approach to logic and argumentation rooted in a research tradition that goes back to dialectics in Greek Antiquity, when problems were approached through dialogues in which opposing parties discussed a thesis through questions and answers. Temporal Logic - Plato Stanford. Modal Logic - Plato Stanford. A computational philosophy account on Modal Logic, which is the study of the deductive behavior of the expressions 'it is necessary that' and 'it is possible that'. Epistemic Logic - Plato Stanford. A computational philosophy account on Epistemic Logic, which is a subfield of epistemology concerned with logical approaches to knowledge, belief and related notions. Epistemic Modal Logic - Wikipedia. The Perception of Relations - Trends in Cognitive Sciences, 2021. [All Versions]. Chaz Firestone's review on the perception of relation, in constrast to the conventional reasoning view. Commonsense reasoning about causality: Deriving behavior from structure - Artificial Intelligence, 1984. [All Versions]. Logics for Epistemic Programs - Synthese, 2004. [All Versions]. A Translation Approach to Portable Ontology Specifications - Knowledge Acquisition, 1993. [All Versions]. The Symbolic Grounding Problem - Physica D: Nonlinear Phenomena, 1990. [All Versions]. Learning overhypotheses with hierarchical Bayesian models - Developmental Science, 2007. [All Versions]. Learning Causal Schemata - CogSci'07, 2007, [All Versions]. The discovery of structural form - Proceedings of the National Academy of Sciences, 2008. [All Versions]. Chales Kemp's review on theory induction. A Rational Analysis of Rule-Based Concept Learning - Cognitive Science, 2008. [All Versions]. Modeling semantic cognition as logical dimensionality reduction - CogSci'08, 2008. [All Versions]. Theory Acquisition and the Language of Thought - CogSci'08, 2008. [All Versions]. Theory Acquisition as Stochastic Search - CogSci'10, 2010. [All Versions]. A probabilistic model of theory formation - Cognition, 2010. [All Versions]. Bootstrapping in a language of thought: A formal model of numerical concept learning - Cognition, 2012. [All Versions]. Concepts in a Probabilistic Language of Thought - Center for Brains, Minds, and Machines MEMO No.010, 2014. [All Versions]. Exploring the Conceptual Universe - Psychological Review, 2012. [All Versions]. A taxonomy of inductive problems - Psychonomic Bulletin & Review, 2014. [All Versions]. The Logical Primitives of Thought: Empirical Foundations for Compositional Cognitive Models - Psychological Review, 2016. [All Versions]. The Emergence of Organizing Structure in Conceptual Representation - Cognitive Science, 2018. [All Versions]. Theory Acquisition as Constraint-Based Program Synthesis - CogSci'21, 2021. [All Versions]. Connecting perceptual and procedural abstractions in physical construction - CogSci'21, 2021. [All Versions]. Invariant representation of physical stability in the human brain - 2021. [All Versions]. Introduction to The Fluent Calculus - Linkoeping University Electronic Press, 1998. [All Versions]. From situation calculus to fluent calculus: State update axioms as a solution to the inferential frame problem - Artificial Intelligence, 1999. [All Versions]. Unsupervised Structure Learning of Stochastic And-Or Grammars - NeurIPS'13, 2013. [All Versions]. Algorithms of Adaptation in Inductive Inference - Cognitive Psychology, 2021. [All Versions]. A representational analysis of numeration systems - Cognition, 1995. [All Versions]. Learning Program Representations for Food Images and Cooking Recipes - CVPR'22, 2022. [All Versions]. Reasoning about Procedures with Natural Language Processing: A Tutorial - 2023. [All Versions]. *Back to Top Cognitive Development Machine Common Sense Concept Paper - DARPA, 2018. [All Versions]. DARPA's perspective on integrating core knowledge from development psychology into machine intelligence systems. Cognitive Development - Wikipedia. Cognitive development: An information processing approach - B.Blackwell, 1991. [All Versions]. Reconstructing constructivism: Causal models, Bayesian learning mechanisms, and the theory theory - Psychological Bulletin, 2012. [All Versions]. Alison Gopnik's review on the constructivism idea of developmental research. Towards a rational constructivist theory of cognitive development - Psychological Review, 2019. [All Versions]. Fei Xu's review extending Gopnik's view of constructivism, with the rationality as constraint. The origins of inquiry: inductive inference and exploration in early childhood - Trends in Cognitive Sciences, 2012. [All Versions]. Laura Schulz's review on children's exploratory play. Play, Curiosity, and Cognition - Annual Review of Developmental Psychology, 2020. [All Versions]. Laura Schulz's review on children's exploratory play, which proposes a new perspective on exploratory play to explain the emergence of irrational behaviors in play. From exploration to play: A cross-sectional study of infant free play behavior - Developmental Psychology, 1981. [All Versions]. Detecting Blickets: How Young Children Use Information about Novel Causal Powers in Categorization and Induction - Children Development, 2003. [All Versions]. Serious fun: Preschoolers engage in more exploratory play when evidence is confounded - Developmental Psychology, 2007. [All Versions]. Observing the unexpected enhances infants' learning and exploration - Science, 2015. [All Versions]. Word, thought, and deed: the role of object categories in children's inductive inferences and exploratory play - Developmental Psychology, 2009. [All Versions]. Where science starts: Spontaneous experiments in preschoolers' exploratory play - Cognition, 2011. [All Versions]. Scientific thinking in young children: Theoretical advances, empirical research, and policy implications - Science, 2012. [All Versions]. Finding New Facts; Thinking New Thoughts - Advances in Child Development and Behavior, 2012. [All Versions]. Theory learning as stochastic search in the language of thought - Cognitive Development, 2012. [All Versions]. Infants make more attempts to achieve a goal when they see adults persist - Science, 2017. [All Versions]. Knowing when to quit: Children consider access to solutions when deciding whether to persist - CogSci'20, 2020. [All Versions]. Bayesian Models of Conceptual Development: Learning as Building Models of the World - Annual Review of Developmental Psychology, 2020. [All Versions]. Sticking to the Evidence? A Behavioral and Computational Case Study of Micro-Theory Change in the Domain of Magnetism - Cognitive Science, 2019. [All Versions]. Cognitive pragmatism: Children flexibly choose between facts and conjectures - CogSci'18, 2018. [All Versions]. Exploratory play, rational action, and efficient search - CogSci'20, 2020. [All Versions]. Children selectively endorse speculative conjectures - Child Development, 2021. [All Versions]. Learning higher-order generalizations through free play: Evidence from 2- and 3-year-old children - Developmental Psychology, 2017. [All Versions]. Childhood as a solution to explore–exploit tensions - Philosophical Transactions of the Royal Society B: Biological Sciences, 2020. [All Versions]. Children's exploratory play tracks the discriminability of hypotheses - Nature Communications, 2021. [All Versions]. A Developmental Perspective on Executive Function - Child Development, 2010. [All Versions]. Rethinking Executive Function and Its Development - Psychological Science, 2020. [All Versions]. Perception of partly occluded objects in infancy - Cognitive Psychology, 1983. [All Versions]. Age-of-acquisition ratings for 30,000 English words - Behavior Research Methods, 2012. [All Versions]. [Project]. A database for age-of-acquisition ratings for over 30k English words. *Back to Top Learning in the Open World Online learning of symbolic concepts - Journal of Mathematical Psychology, 2017. [All Versions]. Zero-Shot Learning—A Comprehensive Evaluation of the Good, the Bad and the Ugly - IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018. [All Versions]. A comprehensive review on zero-shot learning. Generalizing from a few examples: A survey on few-shot learning - ACM Computing Survey, 2020. [All Versions]. Towards Open World Recognition - CVPR'15, 2015. [All Versions]. The first paper introducing the problem of open-world recognition. Towards Open Set Deep Networks - CVPR'16, 2016. [All Versions]. In the Wild: From ML Models to Pragmatic ML Systems - ICLR'20, 2020. [All Versions]. A comprehensive review on incremental machine learning. Adversarial Filters of Dataset Biases - ICML'20, 2020. [All Versions]. A Wholistic View of Continual Learning with Deep Neural Networks: Forgotten Lessons and the Bridge to Active and Open World Learning - 2020. [All Versions]. Energy-Based Models for Continual Learning - NeurIPS'20, 2020. [All Versions]. [Project]. Learning to Learn Image Classifiers with Visual Analogy - CVPR'18, 2018. [All Versions]. Zero-Shot Object Detection - ECCV'18, 2018. [All Versions]. Towards Open World Object Detection - CVPR'21, 2021. [All Versions]. [Project]. Learning to Recognise Unseen Classes by A Few Similes - MM'17, 2017. [All Versions]. Ontology-guided Semantic Composition for Zero-Shot Learning - KR'20, 2020. [All Versions]. OntoZSL: Ontology-enhanced Zero-shot Learning - WWW'21, 2021. [All Versions]. Knowledge-aware Zero-Shot Learning: Survey and Perspective - IJCAI'21 2021. [All Versions]. From Red Wine to Red Tomato: Composition with Context - CVPR'17, 2017. [All Versions]. Attributes as Operators: Factorizing Unseen Attribute-Object Compositions - ECCV'18, 2018. [All Versions]. Learning Compositional Representations for Few-Shot Recognition - CVPR'19, 2019. [All Versions]. Symmetry and Group in Attribute-Object Compositions - CVPR'20, 2020. [All Versions]. A causal view of compositional zero-shot recognition - NeurIPS'20, 2020. [All Versions]. Compositional Few-Shot Recognition with Primitive Discovery and Enhancing - MM'20, 2020. [All Versions]. Learning Unseen Concepts via Hierarchical Decomposition and Composition - CVPR'20, 2020. [All Versions]. *Back to Top Learning with Cognitive Plausibility Accuracy and Precision - Wikipedia. Wikipedia on the distinctions and the trade-off between accuracy and precision. Cognitive Science: Definition, Status, and Questions - Annual Review of Psychology, 1989. [All Versions]. Recognition-by-Components: A Theory of Human Image Understanding - Psychological Review, 1987. [All Versions]. The original paper on the recognition-by-components theory. Machine Behaviour - Nature, 2019. [All Versions]. Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike Common Sense - Engineering, 2020. [All Versions]. Yixin Zhu and Song-Chun Zhu's review on visual commonsense. Self-supervised Learning Through the eyes of a Child - NeurIPS'20, 2020. [All Versions]. Concept learning through near-natural co-occurrence frequency estimation. CLEVRER: CoLlision Events for Video REpresentation and Reasoning - ICLR'20, 2020. [All Versions]. BONGARD-LOGO: A New Benchmark for Human-Level Concept Learning and Reasoning - NeurIPS'20, 2020. [All Versions]. The relationship between Precision-Recall and ROC curves - ICML'06, 2006. [All Versions]. Distributional Generalization: A New Kind of Generalization - 2020. [All Versions]. Learning and development in networks: The importance of starting small. - Cognition, 1993. [All Versions]. The original paper on the idea of curriculum learning. Language acquisition in the absence of explicit negative evidence: how important is starting small? - Cognition, 1999. [All Versions]. Curriculum Learning - ICML'09, 2009. [All Versions]. The original paper applying the idea of curriculum learning to machine learning. Parsing video events with goal inference and intent prediction - ICCV'11, 2011. [All Versions]. Inferring "Dark Matter" and "Dark Energy" from Videos - ICCV'13, 2013. [All Versions]. The original paper on latent state discovery from videos. Explainable and Explicit Visual Reasoning over Scene Graphs - CVPR'19, 2019. [All Versions]. Attention over Learned Object Embeddings Enables Complex Visual Reasoning - NeurIPS'21, 2021. [All Versions]. Distributed Representations of Words and Phrases and their Compositionality - NeurIPS'13, 2013. [All Versions]. Motion Reasoning for Goal-Based Imitation Learning - ICRA'20, 2020. [All Versions]. Action Genome: Actions as Compositions of Spatio-temporal Scene Graphs - CVPR'20, 2020. [All Versions]. Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals - NeurIPS'20, 2020. [All Versions]. Something-Else: Compositional Action Recognition with Spatial-Temporal Interaction Networks - CVPR'20, 2020. [All Versions]. Putting visual object recognition in context - CVPR'20, 2020. [All Versions]. Multimodal Few-Shot Learning with Frozen Language Models - 2021. [All Versions]. Describing Objects by their Attributes - CVPR'09, 2009. [All Versions]. Panoramic Learning with A Standardized Machine Learning Formalism - 2021. [All Versions]. Graininess of judgment under uncertainty: An accuracy-informativeness trade-off - Journal of Experimental Psychology, 1995. [All Versions]. Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms - ICLR'20, 2020. [All Versions]. Interplay between rule learning and rule switching in a perceptual categorization task - 2022. [All Versions]. *Back to Top Academic Tools Courses Computational Cognitive Science Courses - MIT. Courses on computational cognitive science from MIT, Harvard, and Stanford. Introduction to Program Synthesis - MIT. Armando Solar-Lezama's elementary course on program synthesis. Structure and Interpretation of Computer Programs - MIT. [Book: SICP]. [All Versions]. Classic course on applying structural, procedural, and meta-linguistic abstraction to solve computational problems. Discrete Mathematics and Its Applications. Classic course on basic discrete mathematics, including matheatical logic, set theory, graph theory, formal language (and automata), basic number theory (e.g., counting), and other related topics. *Back to Top Programming Probabilistic Models of Cognition - MIT. The probabilistic approach to cognitive science, which models learning and reasoning as inference in complex probabilistic models. *Back to Top Paper Writing LaTex Configuration - LaTex. LaTex template for configuration file with elegant reference style (gray-colored reference, page backward reference). BibTex Template - BibTex. BibTex template for including abbreviations of journals and conferences in AI, Mathematics, and Cognitive Sciences. bioRender - bioRender. Create professional science figures in minutes by browsing thousands of pre-made icons and templates from more than 30 fields of life sciences. How to construct a Nature summary paragraph - Nature. Nature official guidelines for composing abstracts. How to write a superb literature review - Nature, 2020. Nature speaks to old hands and first timers about the work they did to make their reviews sing. Scientific Papers - Nature. Nature guidance on writing scientific papers. The Machine Learning Reproducibility Checklist - McGill University. Guidelines for introducing a machine learning algorithm with guarantee of reproducibility. *Back to Top Paper Reading How to Read a Paper - ACM SIGCOMM Computer Communication Review, 2007. [All Versions]. A comprehensive tutorial on reading scientific papers. How to (seriously) read a scientific paper - Science, 2016. [All Versions]. Science interview on reading scientific papers. It's not just you: science papers are getting harder to read - Nature, 2017. [All Versions]. Nature perspective on reading scientific papers. How to navigate a scientific paper with time constraints: a graphics approach - MIT. MIT guidance on strategies for reading papers given different time constraints. Text Visualization Browser - ISOVIS group, 2015. [Paper]. [All Versions]. A Hub of Text Visualization Techniques. *Back to Top Literature Management How to keep up with the scientific literature - Science, 2016. Science interview on organizing scientific papers. Scientific literature: Information overload - Nature, 2016. [All Versions]. Perspective on handling overloaded information from scientific literature. Microsoft Academic Graph - Microsoft Research. Heterogeneous graph containing scientific publication records, citation relationships between those publications, as well as authors, institutions, journals, conferences, and fields of study. An Overview of Microsoft Academic Service (MAS) and Applications - WWW'15, 2015. [All Versios]. Original paper on Microsoft Academic Graph. Goodbye, Microsoft Academic – Hello, open research infrastructure? - LSE Impact Blog, 2021. An interpretation of Microsoft's strategy on research infrastructure. Semantic Scholar - Allen Institute for AI Research. AI-powered scientific literature research tool. Construction of the Literature Graph in Semantic Scholar - NAACL'18, 2018. [All Versions]. Semantic Scholar with extracting feature and metadata from raw paper data. S2ORC: The Semantic Scholar Open Research Corpus - ACL'20, 2020. [All Versions]. An open corpus of academic papers released by Semantic Scholar. Litmaps - Litmap Ltd. For interactive literature map construction and linked document management. VOSviewer - Leiden University. For constructing and visualizing bibliometric networks. StateOfTheArt.AI - StateOfTheArtAI. For tracking, collecting and visualizing the development of AI research. *Back to Top Knowledge Management Library of Congress Classification - Library of Congress. Classification system of USA (PDF only). Chinese Library Classification - National Library of China. Classification system of P. R. China (online user interface in Chinese). [English introduction at ISKO]. [Wikipedia-EN]. DDC at German National Library - Deutsche National Bibliothek. Deway Decimal Classification (DDC) based classification system of Germany (online user interface). [DNB Website]. National Dite Library Classification - National Diet Library of Japan. Classification system of Japan (PDF only). DDC at OCLC (Wikipedia) - Online Computer Library Center (OCLC). [OCLC Website]. [Introduction to DDC]. [DDC Manual]. Dewey Decimal Classification (DDC) system for worldwide library resouce construction. [DDC Class 000 (PDF only)]. [DDC Class 100 (PDF only)]. [DDC Class 200 (PDF only)]. [DDC Class 300 (PDF only)]. [DDC Class 400 (PDF only)]. [DDC Class 500 (PDF only)]. [DDC Class 600 (PDF only)]. [DDC Class 700 (PDF only)]. [DDC Class 800 (PDF only)]. [DDC Class 900 (PDF only)]. Knowledge organization - Wikipedia. Wikipedia on knowledge organization methods. The Zettelkasten Method - Bielefeld University. Relating ideas in graphs and multi-labels. Zettelkasten - Wikipedia. Wikipedia on the Zettelkasten method. Roam Research - Roam Research. For linked document management, visualization, and sharing. Foam - Foambubble. For linked document management, visualization, and sharing, opensourced softward built on VSCode. Building a Second Brain - Forte Labs, LLC. Connecting ideas in graphs. Zotero - Digital Scholar. For reference management to manage bibliographic data and research related materials. Niklas Luhmann's Card Index: Thinking Tool, Communication Partner, Publication Machine - Forgetting Machines: Knowledge Management Evolution in Early Modern Europe, Brill, 2016. [All Versions]. The card index as creativity machine - Culture Machine, 2010. [All Versions]. Where Does Niklas Luhmann's Card Index Come From? - Erudition and the Republic of Letters, 2018. [All Versions]. A simplified introduction on Luhmann's Zettelkasten. Niklas Luhmann's Card Index: The Fabrication of Serendipity - Sociologica, 2018. [All Versions]. Communicating with Slip Boxes - 2019. [All Versions]. *Back to Top Institute & Researcher MIT Center for Brains, Minds and Machines (CBMM) - MIT. Josh Tenenbaum - Department of Brain and Cognitive Sciences, CSAIL, MIT, Computational Cognitive Science Group (CoCoSci Group) - MIT. Rebecca Saxe - Department of Brain and Cognitive Sciences, MIT, Social Cognitive Neuroscience Laboratory (SaxeLab) - MIT. Laura Schulz - Department of Brain and Cognitive Sciences, MIT, Early Childhood Cognition Lab - MIT. Leslie Kaelbling - Department of Electrical Engineering and Computer Science, CSAIL, MIT, The Learning & Intelligent Systems Group - MIT. Armando Solar-Lezama - Department of Electrical Engineering and Computer Science, CSAIL, MIT, Computer-Aided Programming Group - MIT. *Back to Top Stanford Li Fei-Fei - Computer Science Department, Human-Centered AI Institute, Stanford, Stanford Vision and Learning Lab - Stanford. Noah Goodman - Department of Psychology, Computer Science Department, Stanford, Computation & Cognition Lab (CoCoLab) - Stanford. Michael Frank - Department of Psychology, Stanford, The Stanford Language and Cognition Lab - Stanford. Tobias Gerstenberg - Department of Psychology, Stanford, Causality in Cognition Lab (CICL) - Stanford. Chelsea Finn - Computer Science Department, Stanford, Intelligence through Robotic Interaction at Scale (IRIS Group) - Stanford. Jeremy Bailenson - Department of Communication, Stanford, Virtual Human Interaction Lab (VHIL) - Stanford. Jiajun Wu - Computer Science Department, Stanford. Judith Fan - Department of Psychology, Stanford, Cognitive Tools Lab - Stanford. *Back to Top Princeton Tania Lombrozo - Department of Psychology, Princeton, Concepts & Cognition Lab - Princeton. Thomas Griffiths - Department of Psychology, Department of Computer Science, Princeton, Computational Cognitive Science Lab - Princeton. *Back to Top Harvard Elizabeth Spelke - Department of Psychology, Harvard, Harvard Laboratory for Developmental Studies - Harvard. Tomer Ullman - Department of Psychology, Harvard, Computation, Cognition, and Development Lab (CoCoDev) - Harvard. Samuel Gershman - Department of Psychology, Harvard, Computational Cognitive Neuroscience Lab (CCN Lab) - Harvard. Fiery Cushman - Department of Psychology, Harvard, Moral Psychology Research Lab - Harvard. *Back to Top UCLA Center for Vision, Cognition, Learning and Autonomy (VCLA) - Department of Statistics, UCLA. Ying Nian Wu - Department of Statistics, UCLA. Tao Gao - Department of Statistics, Department of Psychology, UCLA, Visual Intelligence Lab - UCLA. Hongjing Lu - Department of Psychology, Department of Statistics, UCLA, Computational Vision and Learning Lab (CVL) - UCLA. Guy Van den Broeck - Department of Computer Science, UCLA, StarAI Lab - UCLA. *Back to Top UC Berkeley Anca Dragan - Department of Electrical Engineering and Computer Science, UC Berkeley, Interactive Autonomy and Collaborative Technologies Laboratory (InterACT) - UC Berkeley. Fei Xu - Department of Psychology, UC Berkeley, Berkeley Early Learning Lab (Xu Lab) - UC Berkeley. Alison Gopnik - Department of Psychology, UC Berkeley, Cognitive Development & Learning Lab (Gopnik Lab) - UC Berkeley. Steve Piantadosi - Department of Psychology, UC Berkeley, The computation and language lab (colala) - UC Berkeley. Celeste Kidd - Department of Psychology, UC Berkeley, Kidd Lab - UC Berkeley. *Back to Top BNU Yanchao Bi - IDG/McGovern Institute for Brain Research and the State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University (BNU), Yanchao Bi's Concept Lab (Bi Lab) - BNU. *Back to Top PKU Song-Chun Zhu - School of AI and Institute for AI, Peking University (PKU). Yixin Zhu - School of AI and Institute for AI, Peking University (PKU), Cognitive Reasoning Lab (CoRe Lab) - PKU. *Back to Top UCSD Zhuowen Tu - Department of Computer Science, UCSD, Machine Learning, Perception, and Cognition Lab (mlPC) - UCSD. Ed Vul - Department of Psychology, UCSD, Computational Cognition Lab - UCSD. *Back to Top NYU Ernest Davis - Department of Computer Science, Courant Institute of Mathematical Sciences, NYU. Gary Marcus - Department of Psychology, NYU. Brenden Lake - Department of Psychology, NYU, Human & Machine Learning Lab (Lake Lab) - NYU. Todd Gureckis - Department of Psychology, NYU, Computation & Cognition Lab - NYU. Wei Ji Ma - Department of Psychology, Center for Neural Science, NYU, Wei Ji Ma Lab - NYU. *Back to Top JHU Chaz Firestone - Department of Psychological and Brain Sciences, Johns Hopkins University (JHU), Hopkins Perception & Mind Lab - JHU. *Back to Top SIT Mark Ho - Department of Computer Science, Stevens Institute of Technology (SIT), Computation and Decision-Making Lab - SIT. *Back to Top People & Book John Hopcroft Theoretical computer scientist. Introduction to Automata Theory, Languages, and Computation - Pearson, 2007. [All Versions]. Foundations of Data Science - Cambridge University Press. [All Versions]. *Back to Top Ulf Grenander Applied mathematician, the founder of General Pattern Theory. A Calculus of Ideas: A Mathematical Study of Thinking - World Scientific Publishing Company, 2012. [All Versions]. General Pattern Theory: A Mathematical Study of Regular Structures - Oxford University Press, 1993. [All Versions]. *Back to Top David Marr Computational Cognitive Neuroscientist, the establisher of the Levels of Analysis. Vision: A Computational Investigation into the Human Representation and Processing of Visual Information - MIT Press, 1982. [All Versions]. *Back to Top Michael Tomasello Cognitive scientist, set up the foundations of studying human communications. Origins of human communication - MIT Press, 2010. [All Versions]. The cultural origins of human cognition - Havard University Press, 2000. [All Versions]. *Back to Top Judea Pearl Applied mathematician, proposed causal intervention on siamese bayesian networks. The Book of Why: The New Science of Cause and Effect - Basic Books, 2018. [All Versions]. Causality: Models, Reasoning and Inference - Cambridge University Press, 2009. [All Versions]. *Back to Top Susan Carey Developmental psychologist, proposed object as a core knowledge of human intelligence. The Origin of Concepts - Oxford University Press, 2009. [All Versions]. Conceptual Change in Childhood - MIT Press, 1985. [All Versions]. *Back to Top Daniel Kahneman Computational cognitive scientist and Economist, set up the foundations for Decision Theory. Thinking, fast and slow - Farrar Straus Giroux, 2011. [All Versions]. *Back to Top Karl Popper Scientific philosophor, the founder of scientific verification theories. The logic of scientific discovery - Routledge, 2005. [All Versions]. All Life is Problem Solving - Routledge, 2001. [All Versions]. *Back to Top About The initiator of this repo has been struggling to taxonomize related topics, since there are so many perspectives to follow, such as task-oriented, technique-oriented, and metaphysics-oriented. Finally he decided to focus on the perspective of The Sciences of Intelligence---each topic describes a phenomenon of intelligence, or an intelligent behavior---they show the objectives of reverse-engineering human intelligence for computational methods. These topics are never restricted to specific technical methods or tasks, but are trying to organize the nature of intelligence---from both the software perspective and the hardware perspective. Obviously, this reading list is far from covering the every aspect of AGI and CoCoSci. Since the list is a by-product of the literature reviews when the initiator is working on Abduction and Bayesian modeling, other topics are also collected with biases, more or less. Abduction may be the way humans explain the world with the known, and discover the unknown, requiring much more investigations into its computational basis, cognitive underpinnings, and applications to AI. Please feel free to reach out! *Back to Top About An awesome & curated list for Artificial General Intelligence, an emerging inter-discipline field that combines artificial intelligence and computational cognitive sciences. Topics awesome planning artificial-general-intelligence awesome-list bayesian logic-programming analogy commonsense language-of-thought pragmatics computational-cognitive-science abduction explainable-ai developmental-psychology intuitive-physics theory-of-mind scientific-discovery hybrid-system general-pattern-theory mind-simulation Resources Readme License CC0-1.0 license Code of conduct Code of conduct Activity Stars 317 stars Watchers 12 watching Forks 23 forks Report repository Releases No releases published Packages 0 No packages published Contributors 3 Languages TeX 100.0% Footer © 2025 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact Manage cookies Do not share my personal information You can’t perform that action at this time.